{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"RL-IDS Adaptive System Documentation","text":""},{"location":"#overview","title":"Overview","text":"<p>The RL-IDS Adaptive System is a cutting-edge Reinforcement Learning-driven Adaptive Intrusion Detection System designed to detect network intrusions using Deep Q-Network (DQN) agents. This system combines advanced machine learning techniques with real-time network traffic analysis to provide adaptive and accurate threat detection.</p> <p>Built on the CICIDS2017 dataset, the system employs sophisticated DQN algorithms including Double DQN, Dueling DQN, and prioritized experience replay to achieve state-of-the-art performance in network intrusion detection. The system provides both training capabilities and production-ready API services for real-time threat detection.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>\ud83e\udd16 Advanced DQN Agent: Deep Q-Network with Double DQN, Dueling architecture, and prioritized replay</li> <li>\ud83c\udf10 Real-time API: FastAPI-based REST service for live predictions with async processing</li> <li>\ud83d\udcca Comprehensive Analytics: Detailed visualization and reporting tools with confusion matrices and performance metrics</li> <li>\ud83d\udd04 Adaptive Learning: Continuous improvement through reinforcement learning with curriculum learning</li> <li>\ud83d\ude80 Production Ready: Docker containerization, health monitoring, and scalable deployment</li> <li>\ud83d\udcc8 Advanced Monitoring: MLflow integration for experiment tracking and model versioning</li> <li>\ud83c\udfaf Multi-class Detection: Supports 15 different attack types from CICIDS2017 dataset</li> <li>\u26a1 High Performance: Optimized for low-latency predictions with batch processing support</li> </ul>"},{"location":"#architecture-components","title":"Architecture Components","text":""},{"location":"#core-modules","title":"Core Modules","text":"<ul> <li><code>rl_ids.agents</code> - Enhanced DQN agent with advanced features</li> <li><code>rl_ids.environments</code> - Custom Gymnasium environment for IDS training</li> <li><code>rl_ids.modeling</code> - Training and evaluation pipelines with advanced optimizations</li> <li><code>api</code> - FastAPI service for real-time predictions and monitoring</li> </ul>"},{"location":"#data-pipeline","title":"Data Pipeline","text":"<ul> <li>Raw Data Processing - CICIDS2017 dataset preprocessing and cleaning</li> <li>Feature Engineering - Network traffic feature extraction and normalization</li> <li>Data Balancing - SMOTE and advanced sampling techniques for class imbalance</li> <li>Train/Validation/Test Split - Stratified splitting for robust evaluation</li> </ul>"},{"location":"#machine-learning-pipeline","title":"Machine Learning Pipeline","text":"<ul> <li>Reinforcement Learning - DQN-based adaptive learning from network traffic patterns</li> <li>Experience Replay - Prioritized replay buffer for efficient learning</li> <li>Curriculum Learning - Progressive difficulty adjustment during training</li> <li>Model Evaluation - Comprehensive performance analysis with detailed metrics</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<pre><code># Clone the repository\ngit clone &lt;repository-url&gt;\ncd rl_ids\n\n# Install dependencies\npip install -r requirements.txt\npip install -e .\n</code></pre>"},{"location":"#basic-usage","title":"Basic Usage","text":"<pre><code># Process CICIDS2017 data\npython -m rl_ids.make_dataset\n\n# Train DQN model with advanced features\npython -m rl_ids.modeling.train --double_dqn --dueling --prioritized_replay\n\n# Evaluate model performance\npython -m rl_ids.modeling.evaluate\n\n# Start FastAPI service\npython -m api.main\n</code></pre>"},{"location":"#docker-deployment","title":"Docker Deployment","text":"<pre><code># Build and run with Docker\ndocker build -t rl-ids-api .\ndocker run -p 8000:8000 rl-ids-api\n\n# Or use Docker Compose\ndocker-compose up -d\n</code></pre>"},{"location":"#project-structure","title":"Project Structure","text":"<pre><code>rl_ids/\n\u251c\u2500\u2500 api/                    # FastAPI service for real-time predictions\n\u2502   \u251c\u2500\u2500 main.py            # FastAPI application and endpoints\n\u2502   \u251c\u2500\u2500 models.py          # Pydantic models for API schemas\n\u2502   \u251c\u2500\u2500 services.py        # Prediction service implementation\n\u2502   \u2514\u2500\u2500 client.py          # API client for testing and integration\n\u251c\u2500\u2500 rl_ids/\n\u2502   \u251c\u2500\u2500 agents/            # DQN agent implementation\n\u2502   \u2502   \u2514\u2500\u2500 dqn_agent.py   # Enhanced DQN with advanced features\n\u2502   \u251c\u2500\u2500 environments/      # Custom Gymnasium environment\n\u2502   \u2502   \u2514\u2500\u2500 ids_env.py     # IDS detection environment\n\u2502   \u251c\u2500\u2500 modeling/          # Training and evaluation pipelines\n\u2502   \u2502   \u251c\u2500\u2500 train.py       # Advanced training with curriculum learning\n\u2502   \u2502   \u2514\u2500\u2500 evaluate.py    # Comprehensive model evaluation\n\u2502   \u251c\u2500\u2500 config.py          # Configuration and path management\n\u2502   \u251c\u2500\u2500 make_dataset.py    # Data preprocessing pipeline\n\u2502   \u2514\u2500\u2500 plots.py           # Advanced visualization tools\n\u251c\u2500\u2500 data/                  # Dataset storage and processing\n\u2502   \u251c\u2500\u2500 raw/              # Original CICIDS2017 dataset files\n\u2502   \u251c\u2500\u2500 processed/        # Preprocessed and split datasets\n\u2502   \u2514\u2500\u2500 external/         # External data sources\n\u251c\u2500\u2500 models/               # Trained model storage\n\u2502   \u251c\u2500\u2500 dqn_model_best.pt # Best performing model\n\u2502   \u2514\u2500\u2500 episodes/         # Episode-wise model checkpoints\n\u251c\u2500\u2500 reports/              # Analysis reports and visualizations\n\u2502   \u251c\u2500\u2500 figures/          # Generated plots and charts\n\u2502   \u2514\u2500\u2500 *.csv            # Performance metrics and detailed results\n\u2514\u2500\u2500 docs/                 # Comprehensive documentation\n    \u251c\u2500\u2500 docs/             # Documentation source files\n    \u2514\u2500\u2500 mkdocs.yml        # Documentation configuration\n</code></pre>"},{"location":"#dataset-information","title":"Dataset Information","text":"<p>The system is designed to work with the CICIDS2017 dataset, which contains: - 2.8M+ network traffic samples from realistic network environments - 15 different attack types including DDoS, PortScan, Brute Force, XSS, SQL Injection - 79 network traffic features extracted using CICFlowMeter - Realistic attack scenarios generated in a controlled environment</p>"},{"location":"#performance-highlights","title":"Performance Highlights","text":"<ul> <li>High Accuracy: Achieves &gt;95% accuracy on CICIDS2017 test set</li> <li>Low Latency: &lt;10ms average prediction time for real-time detection</li> <li>Scalable: Handles batch predictions efficiently with async processing</li> <li>Robust: Comprehensive error handling and confidence-based predictions</li> <li>Adaptive: Continuous learning capabilities through reinforcement learning</li> </ul>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>Getting Started Guide - Complete setup and first training</li> <li>API Reference - REST API documentation and usage</li> <li>Module Documentation - Detailed component reference</li> <li>Tutorials - Step-by-step guides and examples</li> <li>FAQ &amp; Troubleshooting - Common issues and solutions</li> </ul>"},{"location":"faq/","title":"FAQ &amp; Troubleshooting","text":""},{"location":"faq/#frequently-asked-questions","title":"Frequently Asked Questions","text":""},{"location":"faq/#general-questions","title":"General Questions","text":""},{"location":"faq/#q-what-is-rl-ids-and-how-does-it-work","title":"Q: What is RL-IDS and how does it work?","text":"<p>A: RL-IDS is a Reinforcement Learning-driven Adaptive Intrusion Detection System that uses Deep Q-Network (DQN) agents to detect network intrusions. Unlike traditional signature-based systems, RL-IDS learns to identify attack patterns through trial and error, making it adaptive to new and evolving threats.</p> <p>The system works by: 1. Training Phase: The DQN agent learns from the CICIDS2017 dataset, receiving rewards for correct classifications 2. Adaptation: The agent continuously improves its detection strategy through reinforcement learning 3. Inference: Trained models classify real-time network traffic with confidence scores</p>"},{"location":"faq/#q-what-makes-rl-ids-different-from-traditional-ids-systems","title":"Q: What makes RL-IDS different from traditional IDS systems?","text":"<p>A: Key differences include:</p> Traditional IDS RL-IDS Rule/signature-based detection Learning-based adaptive detection Manual rule updates Automatic learning from new data Binary decisions Confidence-based predictions Static thresholds Dynamic decision boundaries Limited to known attacks Can detect novel attack patterns"},{"location":"faq/#q-what-types-of-attacks-can-rl-ids-detect","title":"Q: What types of attacks can RL-IDS detect?","text":"<p>A: The system can detect 15 different attack types from the CICIDS2017 dataset:</p> <ol> <li>BENIGN - Normal network traffic</li> <li>Web Attack \u2013 Brute Force - Password brute force attacks</li> <li>Web Attack \u2013 XSS - Cross-site scripting attacks</li> <li>Web Attack \u2013 SQL Injection - Database injection attacks</li> <li>FTP-Patator - FTP brute force attacks</li> <li>SSH-Patator - SSH brute force attacks</li> <li>DoS slowloris - Slow HTTP denial of service</li> <li>DoS Slowhttptest - Slow HTTP test attacks</li> <li>DoS Hulk - HTTP Unbearable Load King attacks</li> <li>DoS GoldenEye - HTTP DoS attacks</li> <li>Heartbleed - OpenSSL vulnerability exploitation</li> <li>Infiltration - Network infiltration attempts</li> <li>PortScan - Network port scanning</li> <li>DDoS - Distributed denial of service</li> <li>Bot - Botnet traffic</li> </ol>"},{"location":"faq/#q-how-accurate-is-the-rl-ids-system","title":"Q: How accurate is the RL-IDS system?","text":"<p>A: The system typically achieves: - Overall Accuracy: &gt;95% on CICIDS2017 test set - Precision: &gt;94% across all attack types - Recall: &gt;93% for most attack categories - F1-Score: &gt;94% weighted average - False Positive Rate: &lt;2% for normal traffic</p> <p>Performance varies by attack type, with some rare attacks having lower recall due to limited training data.</p>"},{"location":"faq/#installation-setup","title":"Installation &amp; Setup","text":""},{"location":"faq/#q-what-are-the-system-requirements","title":"Q: What are the system requirements?","text":"<p>A: Minimum requirements: - Python: 3.13+ (required) - RAM: 8GB (16GB recommended) - Storage: 2GB for datasets and models - OS: Linux, macOS, or Windows</p> <p>Recommended for training: - GPU: CUDA-compatible with 4GB+ VRAM - CPU: Multi-core processor (8+ cores) - RAM: 16GB+</p>"},{"location":"faq/#q-im-getting-cuda-out-of-memory-errors-during-training-what-should-i-do","title":"Q: I'm getting CUDA out of memory errors during training. What should I do?","text":"<p>A: Try these solutions in order:</p> <ol> <li> <p>Reduce batch size:    <pre><code>python -m rl_ids.modeling.train --batch_size 16\n</code></pre></p> </li> <li> <p>Force CPU training:    <pre><code>CUDA_VISIBLE_DEVICES=\"\" python -m rl_ids.modeling.train\n</code></pre></p> </li> <li> <p>Reduce model size:    <pre><code>python -m rl_ids.modeling.train --hidden_dims \"256,128\"\n</code></pre></p> </li> <li> <p>Use gradient checkpointing (if available in future versions)</p> </li> </ol>"},{"location":"faq/#q-the-data-preprocessing-is-failing-whats-wrong","title":"Q: The data preprocessing is failing. What's wrong?","text":"<p>A: Common causes and solutions:</p> <ol> <li> <p>Missing raw data files:    <pre><code>ls data/raw/\n# Should show 8 CICIDS2017 CSV files\n</code></pre></p> </li> <li> <p>Incorrect file names: Ensure files match exactly:</p> </li> <li><code>Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv</code></li> <li><code>Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv</code></li> <li> <p>etc.</p> </li> <li> <p>Corrupted files: Re-download from the official CICIDS2017 source</p> </li> <li> <p>Insufficient disk space: Ensure 5GB+ free space</p> </li> <li> <p>Memory issues: Close other applications or increase swap space</p> </li> </ol>"},{"location":"faq/#q-how-do-i-verify-my-installation-is-correct","title":"Q: How do I verify my installation is correct?","text":"<p>A: Run these verification steps:</p> <pre><code># 1. Check Python version\npython --version  # Should be 3.13+\n\n# 2. Test RL-IDS import\npython -c \"import rl_ids; print('\u2705 RL-IDS installed')\"\n\n# 3. Check dependencies\npython -c \"import torch; print('\u2705 PyTorch installed')\"\npython -c \"import sklearn; print('\u2705 Scikit-learn installed')\"\n\n# 4. Test CLI commands\npython -m rl_ids.modeling.train --help\n\n# 5. Check GPU availability (optional)\npython -c \"import torch; print(f'CUDA available: {torch.cuda.is_available()}')\"\n</code></pre>"},{"location":"faq/#training-model-issues","title":"Training &amp; Model Issues","text":""},{"location":"faq/#q-training-is-very-slow-how-can-i-speed-it-up","title":"Q: Training is very slow. How can I speed it up?","text":"<p>A: Optimization strategies:</p> <ol> <li> <p>Use GPU acceleration:    <pre><code># Check GPU availability\nnvidia-smi\n# Train with CUDA\npython -m rl_ids.modeling.train --device cuda\n</code></pre></p> </li> <li> <p>Increase batch size (if GPU memory allows):    <pre><code>python -m rl_ids.modeling.train --batch_size 128\n</code></pre></p> </li> <li> <p>Reduce training episodes for testing:    <pre><code>python -m rl_ids.modeling.train --episodes 50\n</code></pre></p> </li> <li> <p>Use curriculum learning:    <pre><code>python -m rl_ids.modeling.train --curriculum_learning\n</code></pre></p> </li> <li> <p>Optimize data loading (ensure data is on SSD)</p> </li> </ol>"},{"location":"faq/#q-my-model-isnt-converging-what-can-i-do","title":"Q: My model isn't converging. What can I do?","text":"<p>A: Training troubleshooting steps:</p> <ol> <li> <p>Check learning rate:    <pre><code># Try lower learning rate\npython -m rl_ids.modeling.train --lr 1e-5\n</code></pre></p> </li> <li> <p>Enable advanced features:    <pre><code>python -m rl_ids.modeling.train --double_dqn --dueling --prioritized_replay\n</code></pre></p> </li> <li> <p>Increase model capacity:    <pre><code>python -m rl_ids.modeling.train --hidden_dims \"1024,512,256,128\"\n</code></pre></p> </li> <li> <p>Use curriculum learning:    <pre><code>python -m rl_ids.modeling.train --curriculum_learning --curriculum_stages 5\n</code></pre></p> </li> <li> <p>Check data quality: Ensure preprocessing completed successfully</p> </li> </ol>"},{"location":"faq/#q-how-do-i-know-if-my-training-is-working-properly","title":"Q: How do I know if my training is working properly?","text":"<p>A: Monitor these training indicators:</p> <ol> <li>Reward trends: Should generally increase over episodes</li> <li>Accuracy: Should improve and stabilize above 80%</li> <li>Epsilon decay: Should decrease from 1.0 to minimum value</li> <li>Loss convergence: Should decrease and stabilize</li> </ol> <p>Good training output example: <pre><code>Episode 50/250: Reward=65.2, Accuracy=0.834, Confidence=0.892, Epsilon=0.61\nEpisode 100/250: Reward=78.5, Accuracy=0.901, Confidence=0.923, Epsilon=0.37\nEpisode 150/250: Reward=89.3, Accuracy=0.934, Confidence=0.945, Epsilon=0.22\n</code></pre></p>"},{"location":"faq/#q-whats-the-difference-between-the-various-model-files","title":"Q: What's the difference between the various model files?","text":"<p>A: Model file explanations:</p> <ul> <li><code>dqn_model_best.pt</code>: Best performing model (highest validation accuracy)</li> <li><code>dqn_model_final.pt</code>: Final model from training completion</li> <li><code>episodes/dqn_model_episode_X.pt</code>: Checkpoint from episode X</li> <li>Models contain: weights, optimizer state, configuration, metadata</li> </ul>"},{"location":"faq/#api-deployment","title":"API &amp; Deployment","text":""},{"location":"faq/#q-the-api-server-wont-start-whats-the-issue","title":"Q: The API server won't start. What's the issue?","text":"<p>A: Common API startup issues:</p> <ol> <li> <p>Port already in use:    <pre><code># Check what's using port 8000\nlsof -i :8000\n# Use different port\npython -m api.main --port 8001\n</code></pre></p> </li> <li> <p>Model file missing:    <pre><code>ls models/dqn_model_*.pt\n# Train a model if none exist\npython -m rl_ids.modeling.train\n</code></pre></p> </li> <li> <p>Dependencies missing:    <pre><code>pip install fastapi uvicorn\n</code></pre></p> </li> <li> <p>Permission issues: Check file permissions and user access</p> </li> </ol>"},{"location":"faq/#q-api-predictions-are-returning-errors-how-do-i-fix-this","title":"Q: API predictions are returning errors. How do I fix this?","text":"<p>A: API troubleshooting:</p> <ol> <li> <p>Check input format:    <pre><code># Correct format: exactly 77 features\ncurl -X POST \"http://localhost:8000/predict\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"features\": [/* 77 numeric values */]}'\n</code></pre></p> </li> <li> <p>Validate feature count:    <pre><code>import requests\nfeatures = [0.1] * 77  # Exactly 77 features\nresponse = requests.post(\"http://localhost:8000/predict\", \n                        json={\"features\": features})\n</code></pre></p> </li> <li> <p>Check model loading:    <pre><code>curl http://localhost:8000/health\n# Should show \"model_loaded\": true\n</code></pre></p> </li> </ol>"},{"location":"faq/#q-how-do-i-deploy-rl-ids-in-production","title":"Q: How do I deploy RL-IDS in production?","text":"<p>A: Production deployment checklist:</p> <ol> <li> <p>Docker deployment:    <pre><code>docker build -t rl-ids-api .\ndocker run -d -p 8000:8000 --name rl-ids rl-ids-api\n</code></pre></p> </li> <li> <p>Environment configuration:    <pre><code># Create .env file\nRLIDS_HOST=0.0.0.0\nRLIDS_PORT=8000\nRLIDS_LOG_LEVEL=INFO\nRLIDS_MODEL_PATH=models/dqn_model_best.pt\n</code></pre></p> </li> <li> <p>Security measures:</p> </li> <li>Add authentication (API keys)</li> <li>Enable HTTPS/TLS</li> <li>Configure firewall rules</li> <li> <p>Set up monitoring</p> </li> <li> <p>Performance optimization:</p> </li> <li>Use multiple workers: <code>uvicorn --workers 4</code></li> <li>Enable batch processing</li> <li>Configure load balancing</li> <li>Set up caching</li> </ol>"},{"location":"faq/#q-how-do-i-monitor-the-api-performance","title":"Q: How do I monitor the API performance?","text":"<p>A: Monitoring strategies:</p> <ol> <li> <p>Health endpoint:    <pre><code>curl http://localhost:8000/health\n</code></pre></p> </li> <li> <p>Metrics collection:</p> </li> <li>Response times</li> <li>Request rates</li> <li>Error rates</li> <li> <p>System resources</p> </li> <li> <p>Logging analysis:    <pre><code># Check application logs\ntail -f logs/api.log\n</code></pre></p> </li> <li> <p>Performance testing:    <pre><code>from api.client import benchmark_api_performance\nimport asyncio\n\nasyncio.run(benchmark_api_performance(100))\n</code></pre></p> </li> </ol>"},{"location":"faq/#data-features","title":"Data &amp; Features","text":""},{"location":"faq/#q-can-i-use-my-own-dataset-instead-of-cicids2017","title":"Q: Can I use my own dataset instead of CICIDS2017?","text":"<p>A: Yes, but you'll need to:</p> <ol> <li>Format compatibility: Ensure your data has:</li> <li>Numeric features (77+ columns)</li> <li>Label column with attack types</li> <li> <p>CSV format</p> </li> <li> <p>Data preprocessing: Modify <code>rl_ids/make_dataset.py</code> for your schema</p> </li> <li> <p>Class mapping: Update class names in the configuration</p> </li> <li> <p>Feature engineering: Ensure features are network traffic related</p> </li> </ol>"},{"location":"faq/#q-what-do-the-77-features-represent","title":"Q: What do the 77 features represent?","text":"<p>A: The features are network traffic characteristics extracted using CICFlowMeter:</p> <p>Flow-based features: - Flow duration, packet counts, byte counts - Forward/backward packet statistics - Inter-arrival time statistics</p> <p>Packet-level features: - Packet length statistics (mean, max, min, std) - Header information and flags - Window size and urgent pointer</p> <p>Time-based features: - Flow inter-arrival times - Active and idle time statistics - Subflow characteristics</p> <p>Statistical features: - Flow rate and packet rate - Bulk transfer characteristics - Protocol-specific features</p>"},{"location":"faq/#q-how-do-i-add-new-attack-types","title":"Q: How do I add new attack types?","text":"<p>A: To extend the system for new attacks:</p> <ol> <li> <p>Data collection: Gather labeled samples of new attack type</p> </li> <li> <p>Data integration: Add to training dataset with proper labels</p> </li> <li> <p>Model retraining: Retrain with updated class count:    <pre><code>python -m rl_ids.modeling.train --action_dim 16  # If adding 1 new class\n</code></pre></p> </li> <li> <p>Configuration update: Update class names in API service</p> </li> <li> <p>Validation: Test detection performance on new attack type</p> </li> </ol>"},{"location":"faq/#performance-optimization","title":"Performance &amp; Optimization","text":""},{"location":"faq/#q-why-is-inference-slow-on-my-deployment","title":"Q: Why is inference slow on my deployment?","text":"<p>A: Performance optimization checklist:</p> <ol> <li> <p>Model size: Use smaller architectures for production:    <pre><code>config = DQNConfig(hidden_dims=[256, 128])  # Smaller model\n</code></pre></p> </li> <li> <p>Batch processing: Process multiple samples together:    <pre><code># Use batch prediction endpoint\nPOST /predict/batch\n</code></pre></p> </li> <li> <p>GPU inference: Use GPU if available:    <pre><code># Load model on GPU\nagent.load_model(\"model.pt\", map_location=\"cuda\")\n</code></pre></p> </li> <li> <p>Caching: Implement result caching for repeated requests</p> </li> <li> <p>Async processing: Use FastAPI's async capabilities</p> </li> </ol>"},{"location":"faq/#q-how-can-i-improve-detection-accuracy","title":"Q: How can I improve detection accuracy?","text":"<p>A: Accuracy improvement strategies:</p> <ol> <li> <p>Advanced training features:    <pre><code>python -m rl_ids.modeling.train \\\n    --double_dqn --dueling --prioritized_replay \\\n    --curriculum_learning\n</code></pre></p> </li> <li> <p>Hyperparameter tuning:</p> </li> <li>Lower learning rate: <code>--lr 5e-5</code></li> <li>Larger model: <code>--hidden_dims \"2048,1024,512,256\"</code></li> <li> <p>More training: <code>--episodes 500</code></p> </li> <li> <p>Data augmentation:</p> </li> <li>Balance dataset with SMOTE</li> <li>Add noise for robustness</li> <li> <p>Feature scaling/normalization</p> </li> <li> <p>Ensemble methods: Train multiple models and combine predictions</p> </li> </ol>"},{"location":"faq/#q-whats-the-expected-memory-usage","title":"Q: What's the expected memory usage?","text":"<p>A: Typical memory requirements:</p> <p>Training: - Model: ~8-15 MB - Replay buffer: ~100-500 MB - Data loading: ~2-4 GB - GPU memory: ~2-4 GB - Total system: ~8-16 GB</p> <p>Inference: - Model: ~8-15 MB - API service: ~100-200 MB - Total system: ~500 MB - 1 GB</p> <p>Optimization tips: - Use smaller replay buffers - Enable memory mapping for large datasets - Use gradient checkpointing - Process data in chunks</p>"},{"location":"faq/#error-messages-solutions","title":"Error Messages &amp; Solutions","text":""},{"location":"faq/#error-modulenotfounderror-no-module-named-rl_ids","title":"Error: <code>ModuleNotFoundError: No module named 'rl_ids'</code>","text":"<p>Solution: <pre><code># Install in development mode\npip install -e .\n\n# Or add to Python path\nexport PYTHONPATH=\"${PYTHONPATH}:/path/to/rl_ids\"\n</code></pre></p>"},{"location":"faq/#error-cuda-out-of-memory","title":"Error: <code>CUDA out of memory</code>","text":"<p>Solution: <pre><code># Option 1: Reduce batch size\npython -m rl_ids.modeling.train --batch_size 16\n\n# Option 2: Use CPU\nCUDA_VISIBLE_DEVICES=\"\" python -m rl_ids.modeling.train\n\n# Option 3: Clear GPU memory\npython -c \"import torch; torch.cuda.empty_cache()\"\n</code></pre></p>"},{"location":"faq/#error-filenotfounderror-no-such-file-or-directory-dataprocessedtraincsv","title":"Error: <code>FileNotFoundError: No such file or directory: 'data/processed/train.csv'</code>","text":"<p>Solution: <pre><code># Run data preprocessing first\npython -m rl_ids.make_dataset\n\n# Check if raw data exists\nls data/raw/\n</code></pre></p>"},{"location":"faq/#error-validationerror-features-list-cannot-be-empty","title":"Error: <code>ValidationError: Features list cannot be empty</code>","text":"<p>Solution: <pre><code># Ensure exactly 77 features in API request\ncurl -X POST \"http://localhost:8000/predict\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"features\": [/* exactly 77 numeric values */]}'\n</code></pre></p>"},{"location":"faq/#error-runtimeerror-expected-tensor-for-argument","title":"Error: <code>RuntimeError: Expected tensor for argument</code>","text":"<p>Solution: <pre><code># Check PyTorch compatibility\npip install torch torchvision --index-url https://download.pytorch.org/whl/cpu\n\n# For CUDA\npip install torch torchvision --index-url https://download.pytorch.org/whl/cu118\n</code></pre></p>"},{"location":"faq/#best-practices","title":"Best Practices","text":""},{"location":"faq/#training-best-practices","title":"Training Best Practices","text":"<ol> <li>Start small: Begin with 50-100 episodes to test setup</li> <li>Monitor progress: Watch accuracy and reward trends</li> <li>Use validation: Enable validation dataset for early stopping</li> <li>Save checkpoints: Regular model saving during training</li> <li>Experiment tracking: Use MLflow for experiment management</li> </ol>"},{"location":"faq/#production-best-practices","title":"Production Best Practices","text":"<ol> <li>Model validation: Thoroughly test before deployment</li> <li>Monitoring: Set up comprehensive health monitoring</li> <li>Backup strategies: Keep model backpoints and rollback plans</li> <li>Security: Implement authentication and input validation</li> <li>Performance testing: Load test API endpoints</li> <li>Documentation: Maintain deployment and operational docs</li> </ol>"},{"location":"faq/#development-best-practices","title":"Development Best Practices","text":"<ol> <li>Version control: Use Git for code and model versioning</li> <li>Testing: Write unit tests for critical components</li> <li>Code quality: Use linting and formatting tools</li> <li>Documentation: Keep documentation updated</li> <li>Reproducibility: Use seeds and configuration files</li> </ol>"},{"location":"faq/#getting-additional-help","title":"Getting Additional Help","text":""},{"location":"faq/#community-resources","title":"Community Resources","text":"<ul> <li>GitHub Issues: Report bugs and request features</li> <li>Discussions: Join community discussions</li> <li>Documentation: Comprehensive guides and tutorials</li> </ul>"},{"location":"faq/#professional-support","title":"Professional Support","text":"<ul> <li>Consulting: Custom implementation and optimization</li> <li>Training: Team training and workshops</li> <li>Integration: Help with enterprise integration</li> </ul>"},{"location":"faq/#contributing","title":"Contributing","text":"<ul> <li>Bug Reports: Submit detailed bug reports</li> <li>Feature Requests: Suggest new features</li> <li>Code Contributions: Submit pull requests</li> <li>Documentation: Improve documentation and examples</li> </ul> <p>For specific issues not covered here, please create a detailed issue report including: - Error messages and stack traces - System information and environment - Steps to reproduce the problem - Expected vs. actual behavior</p>"},{"location":"getting-started/","title":"Getting Started Guide","text":""},{"location":"getting-started/#overview","title":"Overview","text":"<p>This guide will walk you through setting up the RL-IDS Adaptive System, from installation to running your first intrusion detection model. By the end of this tutorial, you'll have a fully functional system capable of detecting network intrusions using reinforcement learning.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":""},{"location":"getting-started/#system-requirements","title":"System Requirements","text":"<ul> <li>Python 3.13+ (required for optimal performance)</li> <li>8GB+ RAM (16GB recommended for large datasets)</li> <li>2GB+ disk space for datasets and models</li> <li>CUDA-compatible GPU (optional, but recommended for faster training)</li> </ul>"},{"location":"getting-started/#knowledge-prerequisites","title":"Knowledge Prerequisites","text":"<ul> <li>Basic understanding of Python programming</li> <li>Familiarity with command-line interfaces</li> <li>Basic concepts of machine learning (helpful but not required)</li> </ul>"},{"location":"getting-started/#installation","title":"Installation","text":""},{"location":"getting-started/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone &lt;repository-url&gt;\ncd rl_ids\n</code></pre>"},{"location":"getting-started/#2-create-virtual-environment","title":"2. Create Virtual Environment","text":"<pre><code># Using venv\npython -m venv rl_ids_env\nsource rl_ids_env/bin/activate  # On Windows: rl_ids_env\\Scripts\\activate\n\n# Using conda (alternative)\nconda create -n rl_ids python=3.13\nconda activate rl_ids\n</code></pre>"},{"location":"getting-started/#3-install-dependencies","title":"3. Install Dependencies","text":"<pre><code># Install all required packages\npip install -r requirements.txt\n\n# Install the package in development mode\npip install -e .\n</code></pre>"},{"location":"getting-started/#4-verify-installation","title":"4. Verify Installation","text":"<pre><code># Test the installation\npython -c \"import rl_ids; print('RL-IDS installed successfully!')\"\n\n# Check available commands\npython -m rl_ids.modeling.train --help\n</code></pre>"},{"location":"getting-started/#data-preparation","title":"Data Preparation","text":""},{"location":"getting-started/#1-obtain-cicids2017-dataset","title":"1. Obtain CICIDS2017 Dataset","text":"<p>The system is designed to work with the CICIDS2017 dataset. You can download it from: - Canadian Institute for Cybersecurity</p>"},{"location":"getting-started/#2-dataset-structure","title":"2. Dataset Structure","text":"<p>Place the downloaded CSV files in the <code>data/raw/</code> directory:</p> <pre><code>data/raw/\n\u251c\u2500\u2500 Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n\u251c\u2500\u2500 Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\n\u251c\u2500\u2500 Friday-WorkingHours-Morning.pcap_ISCX.csv\n\u251c\u2500\u2500 Monday-WorkingHours.pcap_ISCX.csv\n\u251c\u2500\u2500 Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\n\u251c\u2500\u2500 Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\n\u251c\u2500\u2500 Tuesday-WorkingHours.pcap_ISCX.csv\n\u2514\u2500\u2500 Wednesday-workingHours.pcap_ISCX.csv\n</code></pre>"},{"location":"getting-started/#3-process-the-data","title":"3. Process the Data","text":"<pre><code># Run the data preprocessing pipeline\npython -m rl_ids.make_dataset\n\n# This will create processed files in data/processed/\n# - train.csv (training set)\n# - val.csv (validation set)  \n# - test.csv (test set)\n</code></pre> <p>Expected Output: <pre><code>\ud83d\uddc2\ufe0f  Starting data loading from directory: data/raw\n\ud83d\udcc4 Found 8 CSV files to process\n\ud83d\udd17 Concatenating data frames...\n\ud83e\uddf9 Starting data preprocessing...\n\u2705 Data loading and preprocessing complete! Final shape: (2830743, 79)\n</code></pre></p>"},{"location":"getting-started/#first-training-run","title":"First Training Run","text":""},{"location":"getting-started/#1-basic-training","title":"1. Basic Training","text":"<p>Start with a simple training run to verify everything works:</p> <pre><code>python -m rl_ids.modeling.train \\\n    --episodes 50 \\\n    --lr 0.001 \\\n    --batch_size 32\n</code></pre>"},{"location":"getting-started/#2-advanced-training","title":"2. Advanced Training","text":"<p>For better performance, use advanced features:</p> <pre><code>python -m rl_ids.modeling.train \\\n    --episodes 250 \\\n    --lr 0.0001 \\\n    --batch_size 64 \\\n    --double_dqn \\\n    --dueling \\\n    --prioritized_replay \\\n    --curriculum_learning\n</code></pre> <p>Training Parameters Explained: - <code>--episodes</code>: Number of training episodes (more = better performance) - <code>--lr</code>: Learning rate (lower = more stable learning) - <code>--batch_size</code>: Training batch size (higher = more stable gradients) - <code>--double_dqn</code>: Reduces overestimation bias - <code>--dueling</code>: Separates value and advantage estimation - <code>--prioritized_replay</code>: Focuses on important experiences - <code>--curriculum_learning</code>: Progressive difficulty increase</p>"},{"location":"getting-started/#3-monitor-training-progress","title":"3. Monitor Training Progress","text":"<p>The training process will display real-time metrics:</p> <pre><code>\ud83d\ude80 Starting Enhanced DQN training for IDS Detection\n===============================================\nEpisode 10/250: Reward=45.2, Accuracy=0.834, Confidence=0.892, Epsilon=0.85\nEpisode 20/250: Reward=52.1, Accuracy=0.867, Confidence=0.901, Epsilon=0.72\n...\n</code></pre>"},{"location":"getting-started/#model-evaluation","title":"Model Evaluation","text":""},{"location":"getting-started/#1-evaluate-trained-model","title":"1. Evaluate Trained Model","text":"<pre><code>python -m rl_ids.modeling.evaluate \\\n    --model_path models/dqn_model_best.pt \\\n    --test_episodes 10\n</code></pre>"},{"location":"getting-started/#2-generate-detailed-reports","title":"2. Generate Detailed Reports","text":"<p>The evaluation will create comprehensive reports in <code>reports/</code>:</p> <ul> <li><code>evaluation_summary_enhanced.csv</code> - Overall performance metrics</li> <li><code>evaluation_detailed_predictions_enhanced.csv</code> - Per-prediction results</li> <li><code>evaluation_classification_report.csv</code> - Class-wise performance</li> <li><code>figures/</code> - Visualization plots</li> </ul>"},{"location":"getting-started/#3-view-results","title":"3. View Results","text":"<p>Check the generated visualizations:</p> <pre><code># View the results in the reports/figures/ directory\nls reports/figures/\n# evaluation_overview.png\n# class_analysis.png\n# error_analysis.png\n# confusion_matrix.png\n</code></pre>"},{"location":"getting-started/#api-service-setup","title":"API Service Setup","text":""},{"location":"getting-started/#1-start-the-api-server","title":"1. Start the API Server","text":"<pre><code>python -m api.main\n</code></pre> <p>The API will start on <code>http://localhost:8000</code> with: - Swagger UI: <code>http://localhost:8000/docs</code> - ReDoc: <code>http://localhost:8000/redoc</code> - Health Check: <code>http://localhost:8000/health</code></p>"},{"location":"getting-started/#2-test-the-api","title":"2. Test the API","text":"<pre><code># Using curl\ncurl -X POST \"http://localhost:8000/predict\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"features\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}'\n\n# Using the provided client\npython -m api.client\n</code></pre>"},{"location":"getting-started/#3-api-response-format","title":"3. API Response Format","text":"<pre><code>{\n  \"prediction\": 1,\n  \"confidence\": 0.95,\n  \"class_probabilities\": [0.05, 0.95],\n  \"predicted_class\": \"Attack\",\n  \"is_attack\": true,\n  \"processing_time_ms\": 2.3,\n  \"timestamp\": \"2025-06-21T10:30:00\"\n}\n</code></pre>"},{"location":"getting-started/#docker-deployment","title":"Docker Deployment","text":""},{"location":"getting-started/#1-build-docker-image","title":"1. Build Docker Image","text":"<pre><code>docker build -t rl-ids-api .\n</code></pre>"},{"location":"getting-started/#2-run-container","title":"2. Run Container","text":"<pre><code>docker run -p 8000:8000 rl-ids-api\n</code></pre>"},{"location":"getting-started/#3-use-docker-compose","title":"3. Use Docker Compose","text":"<pre><code># Basic deployment\ndocker-compose up -d\n\n# With monitoring\ndocker-compose --profile monitoring up -d\n</code></pre>"},{"location":"getting-started/#configuration","title":"Configuration","text":""},{"location":"getting-started/#environment-variables","title":"Environment Variables","text":"<p>Create a <code>.env</code> file for custom configuration:</p> <pre><code># Server Configuration\nRLIDS_HOST=0.0.0.0\nRLIDS_PORT=8000\nRLIDS_DEBUG=false\n\n# Model Configuration\nRLIDS_MODEL_PATH=models/dqn_model_best.pt\nRLIDS_MAX_BATCH_SIZE=100\n\n# Logging\nRLIDS_LOG_LEVEL=INFO\n</code></pre>"},{"location":"getting-started/#advanced-configuration","title":"Advanced Configuration","text":"<p>Modify configuration in <code>rl_ids/config.py</code> for: - Data paths - Model directories - Logging settings - Performance tuning</p>"},{"location":"getting-started/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/#common-issues","title":"Common Issues","text":"<p>1. CUDA Out of Memory <pre><code># Reduce batch size\npython -m rl_ids.modeling.train --batch_size 16\n\n# Or force CPU usage\nCUDA_VISIBLE_DEVICES=\"\" python -m rl_ids.modeling.train\n</code></pre></p> <p>2. Data Loading Errors <pre><code># Check data directory structure\nls data/raw/\n# Ensure all 8 CICIDS2017 CSV files are present\n</code></pre></p> <p>3. Model Loading Errors <pre><code># Check if model file exists\nls models/\n# Retrain if necessary\npython -m rl_ids.modeling.train\n</code></pre></p>"},{"location":"getting-started/#performance-optimization","title":"Performance Optimization","text":"<p>For Training: - Use GPU if available (<code>CUDA_VISIBLE_DEVICES=0</code>) - Increase batch size (32, 64, 128) - Use multiple workers for data loading - Enable mixed precision training</p> <p>For API: - Use multiple workers (<code>uvicorn --workers 4</code>) - Enable async processing - Configure proper batch sizes - Use Redis for caching (in production)</p>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<p>Now that you have a working system:</p> <ol> <li>Explore Advanced Features: Check out advanced training techniques</li> <li>API Integration: Learn about API usage patterns</li> <li>Production Deployment: Follow the deployment guide</li> <li>Custom Models: Create custom environments</li> <li>Monitoring: Set up comprehensive monitoring</li> </ol>"},{"location":"getting-started/#getting-help","title":"Getting Help","text":"<ul> <li>Documentation: Check the API reference and module docs</li> <li>Examples: Browse the tutorials section</li> <li>Issues: Create an issue on the project repository</li> <li>Community: Join discussions and share experiences</li> </ul>"},{"location":"getting-started/#quick-reference","title":"Quick Reference","text":""},{"location":"getting-started/#essential-commands","title":"Essential Commands","text":"<pre><code># Data processing\npython -m rl_ids.make_dataset\n\n# Training\npython -m rl_ids.modeling.train --episodes 100\n\n# Evaluation  \npython -m rl_ids.modeling.evaluate\n\n# API server\npython -m api.main\n\n# Health check\ncurl http://localhost:8000/health\n</code></pre>"},{"location":"getting-started/#key-file-locations","title":"Key File Locations","text":"<ul> <li>Models: <code>models/dqn_model_best.pt</code></li> <li>Data: <code>data/processed/{train,val,test}.csv</code></li> <li>Reports: <code>reports/evaluation_*.csv</code></li> <li>Figures: <code>reports/figures/*.png</code></li> <li>Logs: Console output with loguru formatting</li> </ul>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#overview","title":"Overview","text":"<p>The RL-IDS FastAPI service provides a RESTful API for real-time network intrusion detection using trained DQN models. The API is designed for high-performance, scalable deployment with comprehensive monitoring and health checks.</p> <p>The service offers both single prediction and batch processing capabilities, with detailed response schemas including confidence scores, class probabilities, and performance metrics.</p>"},{"location":"api/#base-url","title":"Base URL","text":"<pre><code>http://localhost:8000\n</code></pre>"},{"location":"api/#authentication","title":"Authentication","text":"<p>Currently, the API does not require authentication. For production deployment, consider implementing: - API key authentication - OAuth 2.0 - JWT tokens</p>"},{"location":"api/#endpoints","title":"Endpoints","text":""},{"location":"api/#health-check","title":"Health Check","text":""},{"location":"api/#get-health","title":"<code>GET /health</code>","text":"<p>Check the health status of the API service and model availability.</p> <p>Response Schema: <pre><code>{\n  \"status\": \"healthy\",\n  \"timestamp\": \"2025-06-21T10:30:00.123456\",\n  \"model_loaded\": true,\n  \"system_info\": {\n    \"cpu_percent\": 25.5,\n    \"memory_percent\": 67.2,\n    \"disk_usage_percent\": 45.1\n  },\n  \"service_info\": {\n    \"uptime_seconds\": 3600.5,\n    \"predictions_served\": 1250,\n    \"version\": \"1.0.0\"\n  }\n}\n</code></pre></p> <p>Response Fields: - <code>status</code>: Service health status (<code>healthy</code>, <code>degraded</code>, <code>unhealthy</code>) - <code>timestamp</code>: Current server timestamp - <code>model_loaded</code>: Whether the DQN model is successfully loaded - <code>system_info</code>: System resource utilization metrics - <code>service_info</code>: Service-specific metrics and information</p> <p>Status Codes: - <code>200 OK</code>: Service is healthy - <code>503 Service Unavailable</code>: Service is unhealthy or model not loaded</p> <p>Example: <pre><code>curl -X GET \"http://localhost:8000/health\"\n</code></pre></p>"},{"location":"api/#model-information","title":"Model Information","text":""},{"location":"api/#get-modelinfo","title":"<code>GET /model/info</code>","text":"<p>Retrieve detailed information about the loaded DQN model.</p> <p>Response Schema: <pre><code>{\n  \"model_type\": \"Enhanced DQN Agent\",\n  \"architecture\": \"Dueling Double DQN\",\n  \"state_dim\": 78,\n  \"action_dim\": 15,\n  \"hidden_layers\": [1024, 512, 256, 128],\n  \"model_size_mb\": 8.5,\n  \"device\": \"cuda:0\",\n  \"training_info\": {\n    \"episodes_trained\": 250,\n    \"learning_rate\": 0.0001,\n    \"gamma\": 0.99,\n    \"epsilon\": 0.01\n  },\n  \"performance_metrics\": {\n    \"accuracy\": 0.9534,\n    \"precision\": 0.9421,\n    \"recall\": 0.9398,\n    \"f1_score\": 0.9409\n  },\n  \"class_names\": [\n    \"BENIGN\",\n    \"Web Attack \u2013 Brute Force\",\n    \"Web Attack \u2013 XSS\",\n    \"Web Attack \u2013 Sql Injection\",\n    \"FTP-Patator\",\n    \"SSH-Patator\",\n    \"DoS slowloris\",\n    \"DoS Slowhttptest\",\n    \"DoS Hulk\",\n    \"DoS GoldenEye\",\n    \"Heartbleed\",\n    \"Infiltration\",\n    \"PortScan\",\n    \"DDoS\",\n    \"Bot\"\n  ]\n}\n</code></pre></p> <p>Response Fields: - <code>model_type</code>: Type of the loaded model - <code>architecture</code>: Specific DQN architecture used - <code>state_dim</code>: Input feature dimension - <code>action_dim</code>: Number of output classes - <code>hidden_layers</code>: Neural network architecture - <code>model_size_mb</code>: Model size in memory - <code>device</code>: Computation device (CPU/GPU) - <code>training_info</code>: Training configuration and parameters - <code>performance_metrics</code>: Model performance on validation set - <code>class_names</code>: List of all attack types the model can detect</p> <p>Status Codes: - <code>200 OK</code>: Model information retrieved successfully - <code>503 Service Unavailable</code>: Model not loaded</p> <p>Example: <pre><code>curl -X GET \"http://localhost:8000/model/info\"\n</code></pre></p>"},{"location":"api/#single-prediction","title":"Single Prediction","text":""},{"location":"api/#post-predict","title":"<code>POST /predict</code>","text":"<p>Predict network intrusion for given network traffic features.</p> <p>Request Schema: <pre><code>{\n  \"features\": [\n    0.123, 0.456, 0.789, 0.321, 0.654,\n    0.987, 0.147, 0.258, 0.369, 0.741,\n    // ... 78 total features\n  ]\n}\n</code></pre></p> <p>Request Fields: - <code>features</code>: Array of 78 numeric features representing network traffic characteristics</p> <p>Response Schema: <pre><code>{\n  \"prediction\": 1,\n  \"confidence\": 0.9534,\n  \"class_probabilities\": [\n    0.0123, 0.9534, 0.0098, 0.0087, 0.0076,\n    0.0034, 0.0023, 0.0021, 0.0002, 0.0001,\n    0.0001, 0.0000, 0.0000, 0.0000, 0.0000\n  ],\n  \"predicted_class\": \"Web Attack \u2013 Brute Force\",\n  \"is_attack\": true,\n  \"processing_time_ms\": 2.3,\n  \"timestamp\": \"2025-06-21T10:30:00.123456\"\n}\n</code></pre></p> <p>Response Fields: - <code>prediction</code>: Predicted class index (0-14) - <code>confidence</code>: Confidence score of the prediction (0.0-1.0) - <code>class_probabilities</code>: Probability scores for all 15 classes - <code>predicted_class</code>: Human-readable class name - <code>is_attack</code>: Boolean indicating if traffic is malicious - <code>processing_time_ms</code>: Prediction processing time in milliseconds - <code>timestamp</code>: Prediction timestamp</p> <p>Status Codes: - <code>200 OK</code>: Prediction successful - <code>422 Unprocessable Entity</code>: Invalid input data - <code>503 Service Unavailable</code>: Prediction service not available</p> <p>Example: <pre><code>curl -X POST \"http://localhost:8000/predict\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"features\": [\n         0.0, 0.0, 0.0, 80.0, 80.0, 6.0, 0.0, 0.0, 0.0, 0.0,\n         0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n         0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n         0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n         0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n         0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n         0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n         0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n       ]\n     }'\n</code></pre></p>"},{"location":"api/#batch-prediction","title":"Batch Prediction","text":""},{"location":"api/#post-predictbatch","title":"<code>POST /predict/batch</code>","text":"<p>Process multiple network traffic samples in a single request for improved efficiency.</p> <p>Request Schema: <pre><code>{\n  \"features_batch\": [\n    [0.123, 0.456, /* ... 78 features */],\n    [0.789, 0.321, /* ... 78 features */],\n    [0.654, 0.987, /* ... 78 features */]\n  ],\n  \"batch_id\": \"optional_batch_identifier\"\n}\n</code></pre></p> <p>Request Fields: - <code>features_batch</code>: Array of feature arrays, each containing 78 features - <code>batch_id</code>: Optional identifier for tracking batch requests</p> <p>Response Schema: <pre><code>{\n  \"predictions\": [\n    {\n      \"prediction\": 0,\n      \"confidence\": 0.9821,\n      \"predicted_class\": \"BENIGN\",\n      \"is_attack\": false\n    },\n    {\n      \"prediction\": 5,\n      \"confidence\": 0.8967,\n      \"predicted_class\": \"SSH-Patator\", \n      \"is_attack\": true\n    }\n  ],\n  \"batch_summary\": {\n    \"total_samples\": 2,\n    \"attack_count\": 1,\n    \"benign_count\": 1,\n    \"avg_confidence\": 0.9394,\n    \"processing_time_ms\": 5.7\n  },\n  \"batch_id\": \"optional_batch_identifier\",\n  \"timestamp\": \"2025-06-21T10:30:00.123456\"\n}\n</code></pre></p> <p>Response Fields: - <code>predictions</code>: Array of individual prediction results - <code>batch_summary</code>: Aggregated statistics for the batch - <code>batch_id</code>: Echo of the request batch identifier - <code>timestamp</code>: Batch processing timestamp</p> <p>Status Codes: - <code>200 OK</code>: Batch prediction successful - <code>413 Payload Too Large</code>: Batch size exceeds maximum limit - <code>422 Unprocessable Entity</code>: Invalid input data - <code>503 Service Unavailable</code>: Prediction service not available</p> <p>Example: <pre><code>curl -X POST \"http://localhost:8000/predict/batch\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"features_batch\": [\n         [/* 78 features for sample 1 */],\n         [/* 78 features for sample 2 */]\n       ],\n       \"batch_id\": \"batch_001\"\n     }'\n</code></pre></p>"},{"location":"api/#error-handling","title":"Error Handling","text":"<p>The API uses standard HTTP status codes and provides detailed error information.</p>"},{"location":"api/#error-response-schema","title":"Error Response Schema","text":"<pre><code>{\n  \"detail\": \"Error description\",\n  \"error_type\": \"ValidationError\",\n  \"timestamp\": \"2025-06-21T10:30:00.123456\",\n  \"request_id\": \"req_123456789\"\n}\n</code></pre>"},{"location":"api/#common-error-codes","title":"Common Error Codes","text":"Status Code Error Type Description <code>400 Bad Request</code> <code>ValidationError</code> Invalid request format or parameters <code>422 Unprocessable Entity</code> <code>ValidationError</code> Invalid feature data or schema violations <code>413 Payload Too Large</code> <code>PayloadError</code> Batch size exceeds maximum limit <code>429 Too Many Requests</code> <code>RateLimitError</code> Rate limit exceeded <code>500 Internal Server Error</code> <code>PredictionError</code> Model prediction failed <code>503 Service Unavailable</code> <code>ServiceError</code> Model not loaded or service unavailable"},{"location":"api/#validation-rules","title":"Validation Rules","text":"<p>Feature Validation: - Must be numeric values (int or float) - Array length must be exactly 78 features - No null or missing values allowed - Infinite values are rejected</p> <p>Batch Validation: - Maximum batch size: 100 samples (configurable) - All samples must have consistent feature count - Empty batches are rejected</p>"},{"location":"api/#rate-limiting","title":"Rate Limiting","text":"<p>The API implements rate limiting to ensure fair usage and system stability.</p> <p>Default Limits: - Per IP: 100 requests per minute - Batch Requests: 10 requests per minute - Global: 1000 requests per minute</p> <p>Headers: - <code>X-RateLimit-Limit</code>: Request limit per window - <code>X-RateLimit-Remaining</code>: Requests remaining in current window - <code>X-RateLimit-Reset</code>: Time when the current window resets</p>"},{"location":"api/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"api/#latency","title":"Latency","text":"<ul> <li>Single Prediction: &lt; 10ms average</li> <li>Batch Prediction (10 samples): &lt; 25ms average</li> <li>Model Loading: &lt; 5 seconds</li> </ul>"},{"location":"api/#throughput","title":"Throughput","text":"<ul> <li>Single Predictions: ~200 requests/second</li> <li>Batch Processing: ~500 samples/second</li> <li>Concurrent Requests: Supports async processing</li> </ul>"},{"location":"api/#resource-usage","title":"Resource Usage","text":"<ul> <li>Memory: ~1GB base + 100MB per model</li> <li>CPU: Optimized for multi-core processing</li> <li>GPU: Optional CUDA acceleration</li> </ul>"},{"location":"api/#client-libraries","title":"Client Libraries","text":""},{"location":"api/#python-client","title":"Python Client","text":"<pre><code>from api.client import IDSAPIClient\nimport asyncio\n\nasync def main():\n    client = IDSAPIClient(\"http://localhost:8000\")\n\n    # Health check\n    health = await client.health_check()\n    print(f\"Service status: {health['status']}\")\n\n    # Single prediction\n    features = [0.1] * 78  # Example features\n    result = await client.predict(features)\n    print(f\"Prediction: {result['predicted_class']}\")\n\n    # Batch prediction\n    batch_features = [[0.1] * 78, [0.2] * 78]\n    batch_result = await client.predict_batch(batch_features)\n    print(f\"Batch processed: {len(batch_result['predictions'])} samples\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"api/#javascript-client","title":"JavaScript Client","text":"<pre><code>class IDSAPIClient {\n  constructor(baseUrl = 'http://localhost:8000') {\n    this.baseUrl = baseUrl;\n  }\n\n  async predict(features) {\n    const response = await fetch(`${this.baseUrl}/predict`, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({ features })\n    });\n    return response.json();\n  }\n\n  async healthCheck() {\n    const response = await fetch(`${this.baseUrl}/health`);\n    return response.json();\n  }\n}\n\n// Usage\nconst client = new IDSAPIClient();\nconst result = await client.predict([0.1, 0.2, /* ... 78 features */]);\nconsole.log('Prediction:', result.predicted_class);\n</code></pre>"},{"location":"api/#openapi-documentation","title":"OpenAPI Documentation","text":"<p>The API provides interactive documentation through:</p> <ul> <li>Swagger UI: <code>http://localhost:8000/docs</code></li> <li>ReDoc: <code>http://localhost:8000/redoc</code></li> <li>OpenAPI Schema: <code>http://localhost:8000/openapi.json</code></li> </ul> <p>These interfaces allow you to: - Explore all available endpoints - Test API calls directly in the browser - View detailed request/response schemas - Download the OpenAPI specification</p>"},{"location":"api/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"api/#health-metrics","title":"Health Metrics","text":"<p>The <code>/health</code> endpoint provides comprehensive system metrics:</p> <pre><code>{\n  \"system_info\": {\n    \"cpu_percent\": 25.5,\n    \"memory_percent\": 67.2,\n    \"memory_available_gb\": 8.2,\n    \"disk_usage_percent\": 45.1,\n    \"gpu_utilization\": 12.3\n  },\n  \"service_info\": {\n    \"uptime_seconds\": 3600.5,\n    \"predictions_served\": 1250,\n    \"requests_per_minute\": 45.2,\n    \"avg_response_time_ms\": 8.5,\n    \"error_rate_percent\": 0.1\n  }\n}\n</code></pre>"},{"location":"api/#logging","title":"Logging","text":"<p>The API provides structured logging for monitoring and debugging:</p> <ul> <li>Access Logs: All API requests with timing and status</li> <li>Error Logs: Detailed error information and stack traces</li> <li>Performance Logs: Request processing times and resource usage</li> <li>Model Logs: Model loading, prediction metrics, and health status</li> </ul>"},{"location":"api/#metrics-integration","title":"Metrics Integration","text":"<p>The service exposes metrics compatible with: - Prometheus: <code>/metrics</code> endpoint (when enabled) - Grafana: Pre-built dashboards available - ELK Stack: Structured JSON logging - Custom Monitoring: Health check endpoint for status monitoring</p>"},{"location":"api/#security-considerations","title":"Security Considerations","text":""},{"location":"api/#production-deployment","title":"Production Deployment","text":"<p>For production environments, implement these security measures:</p> <ol> <li>Authentication: Add API key or JWT authentication</li> <li>Rate Limiting: Configure appropriate request limits</li> <li>Input Validation: Strict validation and sanitization</li> <li>HTTPS: Use TLS/SSL encryption</li> <li>CORS: Configure Cross-Origin Resource Sharing</li> <li>Firewall: Restrict network access to authorized sources</li> <li>Monitoring: Implement security monitoring and alerting</li> </ol>"},{"location":"api/#example-security-configuration","title":"Example Security Configuration","text":"<pre><code># Add to API configuration\nSECURITY_CONFIG = {\n    \"enable_auth\": True,\n    \"api_key_header\": \"X-API-Key\", \n    \"rate_limit\": \"100/minute\",\n    \"cors_origins\": [\"https://yourdomain.com\"],\n    \"https_only\": True\n}\n</code></pre>"},{"location":"api/#next-steps","title":"Next Steps","text":"<ul> <li>Getting Started Guide - Set up your first API service</li> <li>Tutorials - Learn advanced API usage patterns</li> <li>Deployment Guide - Production deployment strategies</li> <li>Module Reference - Detailed code documentation</li> </ul>"},{"location":"api/#endpoints_1","title":"Endpoints","text":""},{"location":"api/#health-check_1","title":"Health Check","text":""},{"location":"api/#get-health_1","title":"<code>GET /health</code>","text":"<p>Check API service health and status.</p> <p>Response Model: <code>HealthResponse</code></p> <p>Response</p> <pre><code>{\n  \"status\": \"healthy\",\n  \"timestamp\": \"2024-06-21T10:30:45.123456\",\n  \"version\": \"1.0.0\",\n  \"uptime_seconds\": 3661.5,\n  \"model_loaded\": true,\n  \"predictions_served\": 1245,\n  \"system_info\": {\n    \"cpu_percent\": 15.2,\n    \"memory_percent\": 32.8,\n    \"disk_percent\": 45.1\n  }\n}\n</code></pre> <p>Status Codes - <code>200</code>: Service is healthy - <code>503</code>: Service unavailable</p>"},{"location":"api/#model-information_1","title":"Model Information","text":""},{"location":"api/#get-modelinfo_1","title":"<code>GET /model/info</code>","text":"<p>Get detailed information about the loaded model.</p> <p>Response Model: <code>ModelInfoResponse</code></p> <p>Response</p> <pre><code>{\n  \"model_name\": \"DQN_IDS_Model\",\n  \"model_version\": \"1.0.0\",\n  \"input_features\": 78,\n  \"output_classes\": 15,\n  \"model_size_mb\": 12.34,\n  \"training_info\": {\n    \"episodes\": 1000,\n    \"best_accuracy\": 0.9876,\n    \"training_time_hours\": 4.5\n  },\n  \"class_names\": [\n    \"BENIGN\",\n    \"Web Attack \u2013 Brute Force\",\n    \"Web Attack \u2013 XSS\",\n    \"Web Attack \u2013 Sql Injection\",\n    \"FTP-Patator\",\n    \"SSH-Patator\",\n    \"PortScan\",\n    \"DoS slowloris\",\n    \"DoS Slowhttptest\",\n    \"DoS Hulk\",\n    \"DoS GoldenEye\",\n    \"Heartbleed\",\n    \"Bot\",\n    \"DDoS\",\n    \"Infiltration\"\n  ],\n  \"feature_names\": [...],\n  \"loaded_at\": \"2024-06-21T10:25:30.123456\"\n}\n</code></pre> <p>Status Codes - <code>200</code>: Model information retrieved successfully - <code>503</code>: Model not loaded</p>"},{"location":"api/#single-prediction_1","title":"Single Prediction","text":""},{"location":"api/#post-predict_1","title":"<code>POST /predict</code>","text":"<p>Predict network intrusion for given features.</p> <p>Request Model: <code>IDSPredictionRequest</code></p> <p>Request Body</p> <pre><code>{\n  \"features\": [\n    0.123, 0.456, 0.789, 0.321, 0.654,\n    0.987, 0.147, 0.258, 0.369, 0.741,\n    0.852, 0.963, 0.159, 0.357, 0.468,\n    // ... 78 total features\n  ]\n}\n</code></pre> <p>Response Model: <code>IDSPredictionResponse</code></p> <p>Response</p> <pre><code>{\n  \"prediction\": 0,\n  \"confidence\": 0.9234,\n  \"class_probabilities\": [0.9234, 0.0543, 0.0123, ...],\n  \"predicted_class\": \"BENIGN\",\n  \"is_attack\": false,\n  \"processing_time_ms\": 2.34,\n  \"timestamp\": \"2024-06-21T10:30:45.123456\"\n}\n</code></pre> <p>Status Codes - <code>200</code>: Prediction successful - <code>422</code>: Invalid input data - <code>503</code>: Service unavailable</p>"},{"location":"api/#batch-prediction_1","title":"Batch Prediction","text":""},{"location":"api/#post-predictbatch_1","title":"<code>POST /predict/batch</code>","text":"<p>Predict multiple network samples at once.</p> <p>Request Model: <code>List[IDSPredictionRequest]</code></p> <p>Request Body</p> <pre><code>[\n  {\n    \"features\": [0.123, 0.456, ...]\n  },\n  {\n    \"features\": [0.789, 0.321, ...]\n  }\n]\n</code></pre> <p>Response Model: <code>List[IDSPredictionResponse]</code></p> <p>Response</p> <pre><code>[\n  {\n    \"prediction\": 0,\n    \"confidence\": 0.9234,\n    \"predicted_class\": \"BENIGN\",\n    \"is_attack\": false,\n    \"processing_time_ms\": 1.23,\n    \"timestamp\": \"2024-06-21T10:30:45.123456\"\n  },\n  {\n    \"prediction\": 6,\n    \"confidence\": 0.8765,\n    \"predicted_class\": \"PortScan\",\n    \"is_attack\": true,\n    \"processing_time_ms\": 1.45,\n    \"timestamp\": \"2024-06-21T10:30:45.134567\"\n  }\n]\n</code></pre> <p>Status Codes - <code>200</code>: Batch prediction successful - <code>422</code>: Invalid input data - <code>413</code>: Request too large (batch size limit exceeded) - <code>503</code>: Service unavailable</p>"},{"location":"api/#data-models","title":"Data Models","text":""},{"location":"api/#request-models","title":"Request Models","text":""},{"location":"api/#idspredictionrequest","title":"<code>IDSPredictionRequest</code>","text":"<p>Single prediction request model.</p> <p>Fields</p> Field Type Required Description <code>features</code> <code>List[float]</code> Yes Network traffic features (78 values) <p>Validation - Features list cannot be empty - All features must be numeric (int or float) - Typically 78 features expected</p> <p>Example</p> <pre><code>{\n  \"features\": [\n    0.123, 0.456, 0.789, 0.321, 0.654,\n    0.987, 0.147, 0.258, 0.369, 0.741,\n    // ... remaining 68 features\n  ]\n}\n</code></pre>"},{"location":"api/#response-models","title":"Response Models","text":""},{"location":"api/#idspredictionresponse","title":"<code>IDSPredictionResponse</code>","text":"<p>Single prediction response model.</p> <p>Fields</p> Field Type Description <code>prediction</code> <code>int</code> Predicted class index (0-14) <code>confidence</code> <code>float</code> Prediction confidence (0.0-1.0) <code>class_probabilities</code> <code>List[float]</code> Probabilities for all classes <code>predicted_class</code> <code>str</code> Human-readable class name <code>is_attack</code> <code>bool</code> Whether prediction indicates attack <code>processing_time_ms</code> <code>float</code> Processing time in milliseconds <code>timestamp</code> <code>str</code> Prediction timestamp (ISO format)"},{"location":"api/#healthresponse","title":"<code>HealthResponse</code>","text":"<p>Health check response model.</p> <p>Fields</p> Field Type Description <code>status</code> <code>str</code> Service status (\"healthy\", \"degraded\", \"unhealthy\") <code>timestamp</code> <code>str</code> Check timestamp <code>version</code> <code>str</code> API version <code>uptime_seconds</code> <code>float</code> Service uptime <code>model_loaded</code> <code>bool</code> Whether model is loaded <code>predictions_served</code> <code>int</code> Total predictions served <code>system_info</code> <code>dict</code> System resource usage"},{"location":"api/#modelinforesponse","title":"<code>ModelInfoResponse</code>","text":"<p>Model information response model.</p> <p>Fields</p> Field Type Description <code>model_name</code> <code>str</code> Model name <code>model_version</code> <code>str</code> Model version <code>input_features</code> <code>int</code> Number of input features <code>output_classes</code> <code>int</code> Number of output classes <code>model_size_mb</code> <code>float</code> Model size in megabytes <code>training_info</code> <code>dict</code> Training metadata <code>class_names</code> <code>List[str]</code> Class names <code>feature_names</code> <code>List[str]</code> Feature names <code>loaded_at</code> <code>str</code> Model load timestamp"},{"location":"api/#usage-examples","title":"Usage Examples","text":""},{"location":"api/#python-client_1","title":"Python Client","text":"<pre><code>import requests\nimport json\n\n# API base URL\nBASE_URL = \"http://localhost:8000\"\n\n# Health check\nresponse = requests.get(f\"{BASE_URL}/health\")\nprint(f\"Service status: {response.json()['status']}\")\n\n# Model information\nresponse = requests.get(f\"{BASE_URL}/model/info\")\nmodel_info = response.json()\nprint(f\"Model: {model_info['model_name']} v{model_info['model_version']}\")\nprint(f\"Classes: {len(model_info['class_names'])}\")\n\n# Single prediction\nfeatures = [0.123, 0.456, 0.789] + [0.0] * 75  # 78 features total\nprediction_request = {\"features\": features}\n\nresponse = requests.post(\n    f\"{BASE_URL}/predict\",\n    json=prediction_request\n)\n\nresult = response.json()\nprint(f\"Prediction: {result['predicted_class']}\")\nprint(f\"Confidence: {result['confidence']:.2%}\")\nprint(f\"Is Attack: {result['is_attack']}\")\n\n# Batch prediction\nbatch_request = [\n    {\"features\": features},\n    {\"features\": [0.987, 0.654, 0.321] + [0.0] * 75}\n]\n\nresponse = requests.post(\n    f\"{BASE_URL}/predict/batch\",\n    json=batch_request\n)\n\nresults = response.json()\nfor i, result in enumerate(results):\n    print(f\"Sample {i+1}: {result['predicted_class']} \"\n          f\"({result['confidence']:.2%})\")\n</code></pre>"},{"location":"api/#javascript-client_1","title":"JavaScript Client","text":"<pre><code>// Health check\nasync function checkHealth() {\n    const response = await fetch('http://localhost:8000/health');\n    const health = await response.json();\n    console.log(`Service status: ${health.status}`);\n    return health;\n}\n\n// Single prediction\nasync function predictIntrusion(features) {\n    const response = await fetch('http://localhost:8000/predict', {\n        method: 'POST',\n        headers: {\n            'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({ features: features })\n    });\n\n    if (!response.ok) {\n        throw new Error(`HTTP error! status: ${response.status}`);\n    }\n\n    const result = await response.json();\n    console.log(`Prediction: ${result.predicted_class}`);\n    console.log(`Confidence: ${(result.confidence * 100).toFixed(1)}%`);\n\n    return result;\n}\n\n// Usage\nconst features = [0.123, 0.456, 0.789, ...Array(75).fill(0)];\npredictIntrusion(features)\n    .then(result =&gt; console.log('Prediction successful:', result))\n    .catch(error =&gt; console.error('Prediction failed:', error));\n</code></pre>"},{"location":"api/#curl-examples","title":"cURL Examples","text":"<pre><code># Health check\ncurl -X GET \"http://localhost:8000/health\"\n\n# Model information\ncurl -X GET \"http://localhost:8000/model/info\"\n\n# Single prediction\ncurl -X POST \"http://localhost:8000/predict\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"features\": [0.123, 0.456, 0.789, 0.321, 0.654, 0.987, 0.147, 0.258, 0.369, 0.741, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n     }'\n\n# Batch prediction\ncurl -X POST \"http://localhost:8000/predict/batch\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '[\n       {\"features\": [0.123, 0.456, ...]},\n       {\"features\": [0.789, 0.321, ...]}\n     ]'\n</code></pre>"},{"location":"api/#error-handling_1","title":"Error Handling","text":""},{"location":"api/#error-response-format","title":"Error Response Format","text":"<pre><code>{\n  \"detail\": \"Error description\",\n  \"error_code\": \"VALIDATION_ERROR\",\n  \"timestamp\": \"2024-06-21T10:30:45.123456\"\n}\n</code></pre>"},{"location":"api/#common-error-codes_1","title":"Common Error Codes","text":"Code Status Description <code>VALIDATION_ERROR</code> 422 Invalid input data <code>MODEL_NOT_LOADED</code> 503 Model not available <code>PREDICTION_FAILED</code> 500 Internal prediction error <code>BATCH_TOO_LARGE</code> 413 Batch size exceeds limit <code>RATE_LIMITED</code> 429 Too many requests"},{"location":"api/#error-examples","title":"Error Examples","text":"<pre><code>// Invalid features\n{\n  \"detail\": \"Features list cannot be empty\",\n  \"error_code\": \"VALIDATION_ERROR\"\n}\n\n// Model not loaded\n{\n  \"detail\": \"Prediction service not initialized\",\n  \"error_code\": \"MODEL_NOT_LOADED\"\n}\n\n// Batch too large\n{\n  \"detail\": \"Batch size exceeds maximum limit of 100\",\n  \"error_code\": \"BATCH_TOO_LARGE\"\n}\n</code></pre>"},{"location":"api/#performance","title":"Performance","text":""},{"location":"api/#response-times","title":"Response Times","text":"Endpoint Typical Response Time <code>/health</code> &lt; 5ms <code>/model/info</code> &lt; 10ms <code>/predict</code> 2-5ms <code>/predict/batch</code> (10 samples) 5-15ms"},{"location":"api/#rate-limits","title":"Rate Limits","text":"<ul> <li>Default: 1000 requests/minute per IP</li> <li>Burst: Up to 100 requests in 10 seconds</li> <li>Configurable via environment variables</li> </ul>"},{"location":"api/#scaling","title":"Scaling","text":"<ul> <li>Horizontal: Deploy multiple instances behind load balancer</li> <li>Vertical: Increase CPU/memory for better throughput</li> <li>GPU: Use CUDA for faster inference</li> </ul>"},{"location":"api/#monitoring","title":"Monitoring","text":""},{"location":"api/#metrics-available","title":"Metrics Available","text":"<ul> <li>Request count by endpoint</li> <li>Response time percentiles</li> <li>Error rates</li> <li>Model prediction accuracy</li> <li>System resource usage</li> </ul>"},{"location":"api/#health-check-details","title":"Health Check Details","text":"<p>The <code>/health</code> endpoint provides comprehensive status:</p> <pre><code>{\n  \"status\": \"healthy\",\n  \"checks\": {\n    \"model_loaded\": true,\n    \"memory_usage\": \"normal\",\n    \"cpu_usage\": \"normal\",\n    \"disk_space\": \"normal\"\n  },\n  \"metrics\": {\n    \"requests_per_minute\": 45,\n    \"avg_response_time_ms\": 3.2,\n    \"error_rate\": 0.001\n  }\n}\n</code></pre>"},{"location":"api/#see-also","title":"See Also","text":"<ul> <li>Getting Started Guide - API setup and usage</li> <li>Service Module - Implementation details</li> <li>Deployment Guide - Production deployment</li> </ul>"},{"location":"modules/","title":"Module Reference","text":""},{"location":"modules/#overview","title":"Overview","text":"<p>The RL-IDS system is organized into several key modules, each handling specific aspects of the reinforcement learning-based intrusion detection system. This reference provides comprehensive documentation for all major components, classes, and functions.</p>"},{"location":"modules/#core-modules","title":"Core Modules","text":"Module Description Key Components <code>rl_ids.agents</code> Enhanced DQN agent implementation <code>DQNAgent</code>, <code>DQNConfig</code>, <code>DQN</code> <code>rl_ids.environments</code> Custom Gymnasium environment <code>IDSDetectionEnv</code> <code>rl_ids.modeling</code> Training and evaluation pipelines <code>train</code>, <code>evaluate</code> <code>api</code> FastAPI service for predictions <code>IDSPredictionService</code>, <code>main</code>"},{"location":"modules/#utility-modules","title":"Utility Modules","text":"Module Description Key Components <code>rl_ids.config</code> Configuration and path management Paths, logging setup, environment variables <code>rl_ids.make_dataset</code> Data preprocessing pipeline <code>DataGenerator</code>, <code>DataPreprocessor</code> <code>rl_ids.plots</code> Advanced visualization tools <code>IDSPlotter</code>"},{"location":"modules/#architecture-overview","title":"Architecture Overview","text":""},{"location":"modules/#data-flow","title":"Data Flow","text":"<pre><code>Raw CICIDS2017 Data \u2192 Data Preprocessing \u2192 Feature Engineering \u2192 Train/Val/Test Split\n                                            \u2193\nTraining Environment \u2190 Custom Gym Environment \u2190 Processed Data\n        \u2193\nDQN Agent Training \u2192 Model Checkpoints \u2192 Best Model Selection\n        \u2193\nModel Evaluation \u2192 Performance Reports \u2192 Visualization\n        \u2193\nProduction API \u2192 Real-time Predictions \u2192 Monitoring\n</code></pre>"},{"location":"modules/#component-interactions","title":"Component Interactions","text":"<p>Training Pipeline: 1. Data Module (<code>make_dataset</code>) processes raw CICIDS2017 data 2. Environment Module (<code>environments</code>) provides Gym interface for RL training 3. Agent Module (<code>agents</code>) implements DQN algorithm with advanced features 4. Modeling Module (<code>modeling</code>) orchestrates training and evaluation 5. Plotting Module (<code>plots</code>) generates comprehensive visualizations</p> <p>Inference Pipeline: 1. API Module (<code>api</code>) provides REST interface for predictions 2. Service Layer (<code>api.services</code>) handles model loading and predictions 3. Models (<code>api.models</code>) define request/response schemas 4. Client (<code>api.client</code>) provides programmatic API access</p>"},{"location":"modules/#module-dependencies","title":"Module Dependencies","text":"<pre><code>rl_ids/\n\u251c\u2500\u2500 config.py              # Base configuration (imported by all modules)\n\u251c\u2500\u2500 make_dataset.py         # Data preprocessing (depends on: config)\n\u251c\u2500\u2500 agents/\n\u2502   \u2514\u2500\u2500 dqn_agent.py       # DQN implementation (depends on: config)\n\u251c\u2500\u2500 environments/\n\u2502   \u2514\u2500\u2500 ids_env.py         # Gym environment (depends on: config)\n\u251c\u2500\u2500 modeling/\n\u2502   \u251c\u2500\u2500 train.py           # Training pipeline (depends on: agents, environments, config)\n\u2502   \u2514\u2500\u2500 evaluate.py        # Evaluation pipeline (depends on: agents, environments, plots)\n\u2514\u2500\u2500 plots.py               # Visualization (depends on: config)\n\napi/\n\u251c\u2500\u2500 main.py                # FastAPI app (depends on: services, models)\n\u251c\u2500\u2500 services.py            # Prediction service (depends on: rl_ids.agents, config)\n\u251c\u2500\u2500 models.py              # Pydantic schemas (standalone)\n\u2514\u2500\u2500 client.py              # API client (depends on: models)\n</code></pre>"},{"location":"modules/#quick-reference","title":"Quick Reference","text":""},{"location":"modules/#essential-classes","title":"Essential Classes","text":"Class Module Purpose <code>DQNAgent</code> <code>rl_ids.agents</code> Main reinforcement learning agent <code>DQNConfig</code> <code>rl_ids.agents</code> Agent configuration and hyperparameters <code>IDSDetectionEnv</code> <code>rl_ids.environments</code> Custom Gym environment for training <code>IDSPredictionService</code> <code>api.services</code> Production prediction service <code>IDSPlotter</code> <code>rl_ids.plots</code> Comprehensive visualization tools"},{"location":"modules/#key-functions","title":"Key Functions","text":"Function Module Purpose <code>main()</code> <code>rl_ids.modeling.train</code> Training pipeline entry point <code>main()</code> <code>rl_ids.modeling.evaluate</code> Evaluation pipeline entry point <code>load_and_process_data()</code> <code>rl_ids.make_dataset</code> Data preprocessing function <code>predict()</code> <code>api.services</code> Single prediction function <code>predict_batch()</code> <code>api.services</code> Batch prediction function"},{"location":"modules/#configuration-classes","title":"Configuration Classes","text":"Config Class Module Purpose <code>DQNConfig</code> <code>rl_ids.agents</code> DQN agent hyperparameters <code>IDSPredictionRequest</code> <code>api.models</code> API request schema <code>IDSPredictionResponse</code> <code>api.models</code> API response schema"},{"location":"modules/#usage-patterns","title":"Usage Patterns","text":""},{"location":"modules/#training-workflow","title":"Training Workflow","text":"<pre><code>from rl_ids.agents.dqn_agent import DQNAgent, DQNConfig\nfrom rl_ids.environments.ids_env import IDSDetectionEnv\nfrom rl_ids.config import TRAIN_DATA_FILE\n\n# Configure agent\nconfig = DQNConfig(state_dim=77, action_dim=15)\nagent = DQNAgent(config)\n\n# Setup environment\nenv = IDSDetectionEnv(data_path=TRAIN_DATA_FILE, \n                      feature_cols=feature_columns)\n\n# Training loop\nfor episode in range(episodes):\n    state, _ = env.reset()\n    while True:\n        action = agent.act(state)\n        next_state, reward, done, _, info = env.step(action)\n        agent.remember(state, action, reward, next_state, done)\n\n        if len(agent.memory) &gt; batch_size:\n            agent.replay()\n\n        if done:\n            break\n        state = next_state\n</code></pre>"},{"location":"modules/#api-usage","title":"API Usage","text":"<pre><code>from api.client import IDSAPIClient\nimport asyncio\n\nasync def predict_sample():\n    client = IDSAPIClient(\"http://localhost:8000\")\n\n    # Single prediction\n    features = [0.1] * 77  # Network traffic features\n    result = await client.predict(features)\n\n    print(f\"Prediction: {result['predicted_class']}\")\n    print(f\"Confidence: {result['confidence']:.3f}\")\n    print(f\"Is Attack: {result['is_attack']}\")\n\nasyncio.run(predict_sample())\n</code></pre>"},{"location":"modules/#visualization","title":"Visualization","text":"<pre><code>from rl_ids.plots import IDSPlotter\nfrom rl_ids.config import REPORTS_DIR, FIGURES_DIR\n\nplotter = IDSPlotter(figures_dir=FIGURES_DIR, dpi=300)\n\n# Generate comprehensive evaluation plots\nplotter.plot_evaluation_overview(REPORTS_DIR)\nplotter.plot_class_analysis(REPORTS_DIR)\nplotter.plot_error_analysis(REPORTS_DIR)\n</code></pre>"},{"location":"modules/#see-also","title":"See Also","text":"<ul> <li>Getting Started Guide - Setup and first steps</li> <li>API Reference - REST API documentation</li> <li>Tutorials - Hands-on guides and examples</li> <li>FAQ &amp; Troubleshooting - Common issues and solutions</li> </ul> <p>rl_ids/ \u251c\u2500\u2500 agents/ \u2502   \u2514\u2500\u2500 dqn_agent.py \u2192 torch, gymnasium \u251c\u2500\u2500 environments/ \u2502   \u2514\u2500\u2500 ids_env.py   \u2192 gymnasium, pandas \u251c\u2500\u2500 modeling/ \u2502   \u251c\u2500\u2500 train.py     \u2192 agents, environments \u2502   \u2514\u2500\u2500 evaluate.py  \u2192 agents, environments \u2514\u2500\u2500 plots.py         \u2192 matplotlib, seaborn ```</p>"},{"location":"modules/#quick-navigation","title":"Quick Navigation","text":"<ul> <li>DQN Agent Documentation</li> <li>Environment Documentation </li> <li>Training &amp; Evaluation</li> <li>API Service</li> <li>Configuration</li> <li>Data Processing</li> <li>Visualization</li> </ul>"},{"location":"modules/agents/","title":"DQN Agent Module","text":""},{"location":"modules/agents/#overview","title":"Overview","text":"<p>The <code>rl_ids.agents.dqn_agent</code> module implements a state-of-the-art Deep Q-Network (DQN) agent for reinforcement learning-based intrusion detection. It features advanced techniques including Double DQN, Dueling DQN, prioritized experience replay, and sophisticated neural network architectures optimized for network traffic pattern recognition.</p> <p>The agent is designed to learn adaptive intrusion detection policies from network traffic data, continuously improving its detection capabilities through reinforcement learning principles.</p>"},{"location":"modules/agents/#classes","title":"Classes","text":""},{"location":"modules/agents/#dqnconfig","title":"<code>DQNConfig</code>","text":"<p>Configuration class for DQN Agent parameters using Pydantic for validation.</p> <p>Signature: <pre><code>class DQNConfig(BaseModel):\n    \"\"\"Configuration for DQN Agent.\"\"\"\n</code></pre></p> <p>Description: A comprehensive configuration class that defines all hyperparameters and settings for the DQN agent. Uses Pydantic for automatic validation and type checking.</p> <p>Attributes:</p> Attribute Type Default Description <code>state_dim</code> <code>int</code> Required Dimension of the state space (number of input features) <code>action_dim</code> <code>int</code> Required Number of possible actions (attack classes) <code>lr</code> <code>float</code> <code>1e-4</code> Learning rate for the optimizer <code>gamma</code> <code>float</code> <code>0.99</code> Discount factor for future rewards <code>epsilon</code> <code>float</code> <code>1.0</code> Initial exploration rate for \u03b5-greedy policy <code>eps_decay</code> <code>float</code> <code>0.995</code> Exponential decay rate for epsilon <code>eps_min</code> <code>float</code> <code>0.01</code> Minimum epsilon value <code>memory_size</code> <code>int</code> <code>100000</code> Size of the experience replay buffer <code>batch_size</code> <code>int</code> <code>32</code> Training batch size <code>hidden_dims</code> <code>List[int]</code> <code>[512, 256]</code> Hidden layer dimensions <code>device</code> <code>str</code> <code>\"auto\"</code> Computing device (\"cpu\", \"cuda\", or \"auto\") <code>dropout_rate</code> <code>float</code> <code>0.2</code> Dropout rate for regularization <code>use_layer_norm</code> <code>bool</code> <code>True</code> Whether to use layer normalization <code>weight_decay</code> <code>float</code> <code>1e-5</code> L2 regularization strength <code>double_dqn</code> <code>bool</code> <code>True</code> Enable Double DQN algorithm <code>dueling</code> <code>bool</code> <code>True</code> Enable Dueling DQN architecture <code>prioritized_replay</code> <code>bool</code> <code>False</code> Enable prioritized experience replay <p>Example: <pre><code>from rl_ids.agents.dqn_agent import DQNConfig\n\nconfig = DQNConfig(\n    state_dim=77,\n    action_dim=15,\n    lr=1e-4,\n    hidden_dims=[1024, 512, 256, 128],\n    double_dqn=True,\n    dueling=True,\n    prioritized_replay=True\n)\n</code></pre></p>"},{"location":"modules/agents/#dqn","title":"<code>DQN</code>","text":"<p>Deep Q-Network neural network model.</p> <p>Inherits: <code>torch.nn.Module</code></p> <p>Parameters</p> Name Type Description <code>input_dim</code> <code>int</code> Input feature dimension <code>output_dim</code> <code>int</code> Output action dimension <code>hidden_dims</code> <code>List[int]</code> Hidden layer dimensions <p>Methods</p>"},{"location":"modules/agents/#forwardx-torchtensor-torchtensor","title":"<code>forward(x: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Forward pass through the network.</p> <p>Parameters - <code>x</code>: Input tensor of shape <code>(batch_size, input_dim)</code></p> <p>Returns - <code>torch.Tensor</code>: Q-values for each action, shape <code>(batch_size, output_dim)</code></p> <p>Examples</p> <pre><code>import torch\nfrom rl_ids.agents.dqn_agent import DQN\n\n# Create network\nmodel = DQN(\n    input_dim=78,\n    output_dim=15,\n    hidden_dims=[512, 256, 128]\n)\n\n# Forward pass\nstate = torch.randn(32, 78)  # batch_size=32\nq_values = model(state)      # shape: (32, 15)\n</code></pre>"},{"location":"modules/agents/#dqnagent","title":"<code>DQNAgent</code>","text":"<p>Main DQN agent class implementing the Deep Q-Network algorithm.</p> <p>Parameters</p> Name Type Description <code>config</code> <code>DQNConfig</code> Agent configuration <p>Attributes</p> Name Type Description <code>model</code> <code>DQN</code> Main Q-network <code>target_model</code> <code>DQN</code> Target Q-network <code>optimizer</code> <code>torch.optim.Adam</code> Model optimizer <code>memory</code> <code>deque</code> Experience replay buffer <code>epsilon</code> <code>float</code> Current exploration rate <code>device</code> <code>torch.device</code> Computing device (CPU/CUDA) <p>Methods</p>"},{"location":"modules/agents/#actstate-npndarray-training-bool-true-int","title":"<code>act(state: np.ndarray, training: bool = True) -&gt; int</code>","text":"<p>Choose action using epsilon-greedy policy.</p> <p>Parameters - <code>state</code>: Current environment state - <code>training</code>: Whether in training mode (enables exploration)</p> <p>Returns - <code>int</code>: Selected action</p> <p>Examples</p> <pre><code>import numpy as np\nfrom rl_ids.agents.dqn_agent import DQNAgent, DQNConfig\n\n# Initialize agent\nconfig = DQNConfig(state_dim=78, action_dim=15)\nagent = DQNAgent(config)\n\n# Select action\nstate = np.random.randn(78)\naction = agent.act(state, training=True)  # Exploration enabled\naction = agent.act(state, training=False) # Pure greedy\n</code></pre>"},{"location":"modules/agents/#rememberstate-npndarray-action-int-reward-float-next_state-npndarray-done-bool-none","title":"<code>remember(state: np.ndarray, action: int, reward: float, next_state: np.ndarray, done: bool) -&gt; None</code>","text":"<p>Store experience in replay buffer.</p> <p>Parameters - <code>state</code>: Current state - <code>action</code>: Action taken - <code>reward</code>: Reward received - <code>next_state</code>: Next state - <code>done</code>: Whether episode ended</p> <p>Examples</p> <pre><code># Store experience\nagent.remember(\n    state=current_state,\n    action=action,\n    reward=1.0,\n    next_state=next_state,\n    done=False\n)\n</code></pre>"},{"location":"modules/agents/#replay-optionalfloat","title":"<code>replay() -&gt; Optional[float]</code>","text":"<p>Train the model on a batch of experiences.</p> <p>Returns - <code>Optional[float]</code>: Training loss if training occurred, None otherwise</p> <p>Examples</p> <pre><code># Training step\nloss = agent.replay()\nif loss is not None:\n    print(f\"Training loss: {loss:.4f}\")\n</code></pre>"},{"location":"modules/agents/#update_target-none","title":"<code>update_target() -&gt; None</code>","text":"<p>Update target network with current network weights.</p> <p>Examples</p> <pre><code># Update target network (typically done every N episodes)\nagent.update_target()\n</code></pre>"},{"location":"modules/agents/#save_modelfilepath-unionstr-path-none","title":"<code>save_model(filepath: Union[str, Path]) -&gt; None</code>","text":"<p>Save model state to file.</p> <p>Parameters - <code>filepath</code>: Path to save the model</p> <p>Examples</p> <pre><code>from pathlib import Path\n\n# Save model\nagent.save_model(\"models/dqn_model.pt\")\nagent.save_model(Path(\"models/episode_100.pt\"))\n</code></pre>"},{"location":"modules/agents/#load_modelfilepath-path-map_location-optionaltorchdevice-none-none","title":"<code>load_model(filepath: Path, map_location: Optional[torch.device] = None) -&gt; None</code>","text":"<p>Load a saved model.</p> <p>Parameters - <code>filepath</code>: Path to model file - <code>map_location</code>: Device to load model on</p> <p>Raises - <code>FileNotFoundError</code>: If model file doesn't exist - <code>RuntimeError</code>: If model loading fails</p> <p>Examples</p> <pre><code># Load model\nagent.load_model(Path(\"models/dqn_model_best.pt\"))\n\n# Load on specific device\nagent.load_model(\n    Path(\"models/dqn_model.pt\"),\n    map_location=torch.device('cpu')\n)\n</code></pre>"},{"location":"modules/agents/#usage-examples","title":"Usage Examples","text":""},{"location":"modules/agents/#basic-training-loop","title":"Basic Training Loop","text":"<pre><code>import numpy as np\nfrom rl_ids.agents.dqn_agent import DQNAgent, DQNConfig\nfrom rl_ids.environments.ids_env import IDSDetectionEnv\n\n# Initialize environment and agent\nenv = IDSDetectionEnv(data_path=\"data/train.csv\", feature_cols=features)\nconfig = DQNConfig(\n    state_dim=len(features),\n    action_dim=env.action_space.n\n)\nagent = DQNAgent(config)\n\n# Training loop\nfor episode in range(1000):\n    state, _ = env.reset()\n    total_reward = 0\n\n    while True:\n        # Select action\n        action = agent.act(state, training=True)\n\n        # Environment step\n        next_state, reward, done, truncated, _ = env.step(action)\n\n        # Store experience\n        agent.remember(state, action, reward, next_state, done)\n\n        # Train agent\n        loss = agent.replay()\n\n        state = next_state\n        total_reward += reward\n\n        if done or truncated:\n            break\n\n    # Update target network periodically\n    if episode % 10 == 0:\n        agent.update_target()\n\n    print(f\"Episode {episode}: Reward = {total_reward}\")\n</code></pre>"},{"location":"modules/agents/#model-evaluation","title":"Model Evaluation","text":"<pre><code># Load trained model\nagent.load_model(\"models/dqn_model_best.pt\")\nagent.epsilon = 0.0  # Disable exploration\n\n# Evaluation\nstate, _ = env.reset()\ntotal_reward = 0\n\nwhile True:\n    action = agent.act(state, training=False)\n    state, reward, done, truncated, _ = env.step(action)\n    total_reward += reward\n\n    if done or truncated:\n        break\n\nprint(f\"Evaluation reward: {total_reward}\")\n</code></pre>"},{"location":"modules/agents/#see-also","title":"See Also","text":"<ul> <li>Environment Module - Custom Gym environment</li> <li>Training Module - Training and evaluation pipelines</li> <li>Configuration - System configuration</li> </ul>"},{"location":"modules/config/","title":"Configuration Module","text":""},{"location":"modules/config/#overview","title":"Overview","text":"<p>The configuration module (<code>rl_ids.config</code>) provides centralized configuration management for the RL-IDS system. It defines project paths, data file locations, logging configuration, and environment variable handling.</p>"},{"location":"modules/config/#key-features","title":"Key Features","text":"<ul> <li>Centralized Path Management - All project paths defined in one place</li> <li>Environment Variable Support - Configuration via <code>.env</code> files</li> <li>Advanced Logging Setup - Integrated with loguru and tqdm</li> <li>Debug Mode Support - Enhanced logging for development</li> <li>Cross-Platform Compatibility - Path handling works on all operating systems</li> </ul>"},{"location":"modules/config/#configuration-variables","title":"Configuration Variables","text":""},{"location":"modules/config/#project-structure","title":"Project Structure","text":"Variable Type Description <code>PROJ_ROOT</code> <code>Path</code> Project root directory <code>DATA_DIR</code> <code>Path</code> Main data directory <code>RAW_DATA_DIR</code> <code>Path</code> Raw CICIDS2017 data location <code>INTERIM_DATA_DIR</code> <code>Path</code> Intermediate processing results <code>PROCESSED_DATA_DIR</code> <code>Path</code> Final processed data <code>EXTERNAL_DATA_DIR</code> <code>Path</code> External datasets"},{"location":"modules/config/#data-files","title":"Data Files","text":"Variable Type Description <code>PROCESSED_DATA_FILE</code> <code>Path</code> Main processed dataset <code>NORMALISED_DATA_FILE</code> <code>Path</code> Normalized feature dataset <code>BALANCED_DATA_FILE</code> <code>Path</code> Class-balanced dataset <code>TRAIN_DATA_FILE</code> <code>Path</code> Training split <code>VAL_DATA_FILE</code> <code>Path</code> Validation split <code>TEST_DATA_FILE</code> <code>Path</code> Test split"},{"location":"modules/config/#model-storage","title":"Model Storage","text":"Variable Type Description <code>MODELS_DIR</code> <code>Path</code> Model storage directory <code>EPISODES_DIR</code> <code>Path</code> Episode checkpoint storage"},{"location":"modules/config/#reports-and-figures","title":"Reports and Figures","text":"Variable Type Description <code>REPORTS_DIR</code> <code>Path</code> Evaluation reports directory <code>FIGURES_DIR</code> <code>Path</code> Generated plots and visualizations"},{"location":"modules/config/#environment-variables","title":"Environment Variables","text":""},{"location":"modules/config/#core-settings","title":"Core Settings","text":"Variable Default Description <code>RLIDS_LOG_LEVEL</code> <code>\"INFO\"</code> Logging level (DEBUG, INFO, WARNING, ERROR) <code>RLIDS_DEBUG</code> <code>\"false\"</code> Enable debug mode for detailed logging"},{"location":"modules/config/#usage","title":"Usage","text":"<p>Create a <code>.env</code> file in the project root:</p> <pre><code># .env file\nRLIDS_LOG_LEVEL=DEBUG\nRLIDS_DEBUG=true\n\n# Optional: Override default paths\nRLIDS_DATA_PATH=/custom/data/path\nRLIDS_MODELS_PATH=/custom/models/path\n</code></pre>"},{"location":"modules/config/#logging-configuration","title":"Logging Configuration","text":"<p>The module automatically configures the loguru logger with:</p> <ul> <li>Color-coded output for different log levels</li> <li>Timestamp formatting with millisecond precision</li> <li>Module/function/line information for debugging</li> <li>tqdm integration for progress bar compatibility</li> <li>Fallback configuration when tqdm is not available</li> </ul>"},{"location":"modules/config/#log-format","title":"Log Format","text":"<pre><code>2024-01-15 14:30:25 | INFO     | rl_ids.agents:train:123 - Training completed successfully\n2024-01-15 14:30:26 | DEBUG    | rl_ids.environments:step:45 - Action 2 resulted in reward 0.85\n2024-01-15 14:30:27 | WARNING  | api.services:predict:78 - Model confidence below threshold: 0.65\n</code></pre>"},{"location":"modules/config/#usage-examples","title":"Usage Examples","text":""},{"location":"modules/config/#basic-configuration-access","title":"Basic Configuration Access","text":"<pre><code>from rl_ids.config import (\n    PROJ_ROOT, MODELS_DIR, TRAIN_DATA_FILE,\n    LOG_LEVEL, DEBUG_MODE\n)\nfrom loguru import logger\n\n# Check if data file exists\nif TRAIN_DATA_FILE.exists():\n    logger.info(f\"Training data found at: {TRAIN_DATA_FILE}\")\nelse:\n    logger.warning(f\"Training data missing: {TRAIN_DATA_FILE}\")\n\n# Load model from standard location\nmodel_path = MODELS_DIR / \"dqn_model_best.pt\"\nif model_path.exists():\n    logger.info(f\"Loading model from: {model_path}\")\n</code></pre>"},{"location":"modules/config/#custom-path-configuration","title":"Custom Path Configuration","text":"<pre><code>from rl_ids.config import PROJ_ROOT\nfrom pathlib import Path\n\n# Create custom data paths\ncustom_data_dir = PROJ_ROOT / \"experiments\" / \"run_001\"\ncustom_data_dir.mkdir(parents=True, exist_ok=True)\n\n# Save experiment results\nresults_file = custom_data_dir / \"training_results.json\"\nlogger.info(f\"Saving results to: {results_file}\")\n</code></pre>"},{"location":"modules/config/#environment-specific-configuration","title":"Environment-Specific Configuration","text":"<pre><code>import os\nfrom rl_ids.config import DEBUG_MODE, LOG_LEVEL\n\n# Conditional behavior based on debug mode\nif DEBUG_MODE:\n    logger.debug(\"Debug mode enabled - verbose logging active\")\n    # Enable additional debug features\n    torch.autograd.set_detect_anomaly(True)\nelse:\n    logger.info(f\"Production mode - log level: {LOG_LEVEL}\")\n</code></pre>"},{"location":"modules/config/#directory-structure-validation","title":"Directory Structure Validation","text":"<p>The configuration module automatically validates the project structure:</p> <pre><code>from rl_ids.config import DATA_DIR, MODELS_DIR, REPORTS_DIR\n\n# Ensure required directories exist\nfor directory in [DATA_DIR, MODELS_DIR, REPORTS_DIR]:\n    directory.mkdir(parents=True, exist_ok=True)\n    logger.debug(f\"Directory validated: {directory}\")\n</code></pre>"},{"location":"modules/config/#integration-with-other-modules","title":"Integration with Other Modules","text":""},{"location":"modules/config/#with-data-processing","title":"With Data Processing","text":"<pre><code>from rl_ids.config import RAW_DATA_DIR, PROCESSED_DATA_DIR\nfrom rl_ids.make_dataset import DataPreprocessor\n\npreprocessor = DataPreprocessor(\n    input_dir=RAW_DATA_DIR,\n    output_dir=PROCESSED_DATA_DIR\n)\n</code></pre>"},{"location":"modules/config/#with-model-training","title":"With Model Training","text":"<pre><code>from rl_ids.config import TRAIN_DATA_FILE, MODELS_DIR\nfrom rl_ids.modeling.train import main as train_model\n\n# Training uses configured paths automatically\ntrain_model()\n\n# Models are saved to MODELS_DIR automatically\n</code></pre>"},{"location":"modules/config/#with-api-service","title":"With API Service","text":"<pre><code>from rl_ids.config import MODELS_DIR\nfrom api.config import APISettings\n\n# API configuration inherits from base config\napi_settings = APISettings(\n    model_path=MODELS_DIR / \"dqn_model_final.pt\"\n)\n</code></pre>"},{"location":"modules/config/#best-practices","title":"Best Practices","text":""},{"location":"modules/config/#1-path-handling","title":"1. Path Handling","text":"<pre><code># \u2705 Correct - Use configured paths\nfrom rl_ids.config import PROCESSED_DATA_DIR\ndata_file = PROCESSED_DATA_DIR / \"my_data.csv\"\n\n# \u274c Avoid - Hardcoded paths\ndata_file = Path(\"data/processed/my_data.csv\")\n</code></pre>"},{"location":"modules/config/#2-environment-variables","title":"2. Environment Variables","text":"<pre><code># \u2705 Correct - Use environment variables for deployment\nimport os\nfrom rl_ids.config import MODELS_DIR\n\n# Allow override in production\nmodel_path = os.getenv(\"RLIDS_MODEL_PATH\", MODELS_DIR / \"default_model.pt\")\n\n# \u274c Avoid - Hardcoded production values\nmodel_path = \"/production/models/model.pt\"\n</code></pre>"},{"location":"modules/config/#3-logging-integration","title":"3. Logging Integration","text":"<pre><code># \u2705 Correct - Use configured logger\nfrom loguru import logger\nfrom rl_ids.config import DEBUG_MODE\n\nlogger.info(\"Starting process...\")\nif DEBUG_MODE:\n    logger.debug(\"Debug information...\")\n\n# \u274c Avoid - Creating new loggers\nimport logging\ncustom_logger = logging.getLogger(__name__)\n</code></pre>"},{"location":"modules/config/#troubleshooting","title":"Troubleshooting","text":""},{"location":"modules/config/#common-issues","title":"Common Issues","text":"<ol> <li> <p>Path Not Found Errors <pre><code># Check if required directories exist\nfrom rl_ids.config import DATA_DIR\nif not DATA_DIR.exists():\n    DATA_DIR.mkdir(parents=True, exist_ok=True)\n</code></pre></p> </li> <li> <p>Environment Variable Not Loaded <pre><code># Ensure .env file is in project root\nfrom rl_ids.config import PROJ_ROOT\nenv_file = PROJ_ROOT / \".env\"\nprint(f\"Looking for .env at: {env_file}\")\nprint(f\"Exists: {env_file.exists()}\")\n</code></pre></p> </li> <li> <p>Logging Issues <pre><code># Check logging configuration\nfrom loguru import logger\nlogger.info(\"Test log message\")\n\n# Verify debug mode\nfrom rl_ids.config import DEBUG_MODE, LOG_LEVEL\nprint(f\"Debug: {DEBUG_MODE}, Level: {LOG_LEVEL}\")\n</code></pre></p> </li> </ol>"},{"location":"modules/config/#see-also","title":"See Also","text":"<ul> <li>Getting Started Guide - Initial setup and configuration</li> <li>Module Reference - Overview of all modules</li> <li>API Configuration - API-specific configuration</li> <li>Training Configuration - Training-specific settings</li> </ul>"},{"location":"modules/environments/","title":"Environment Module","text":""},{"location":"modules/environments/#overview","title":"Overview","text":"<p>The <code>rl_ids.environments.ids_env</code> module provides a custom Gymnasium environment specifically designed for intrusion detection system training using reinforcement learning. It creates a standardized interface between network traffic data and RL agents, enabling seamless training and evaluation of DQN models on cybersecurity datasets.</p> <p>The environment transforms the intrusion detection problem into a sequential decision-making task where agents learn to classify network traffic samples as either benign or one of 14 different attack types.</p>"},{"location":"modules/environments/#classes","title":"Classes","text":""},{"location":"modules/environments/#idsdetectionenv","title":"<code>IDSDetectionEnv</code>","text":"<p>A custom Gymnasium environment for RL-based intrusion detection training.</p> <p>Signature: <pre><code>class IDSDetectionEnv(gym.Env):\n    \"\"\"Custom Environment for RL-Based IDS Detection\"\"\"\n\n    def __init__(self, data_path: Path, feature_cols: List, label_col: str = \"Label\"):\n        \"\"\"Initialize the IDS Detection Environment.\"\"\"\n</code></pre></p> <p>Description: A Gym-compatible environment that loads network traffic data and provides a sequential interface for training reinforcement learning agents. Each step corresponds to classifying one network traffic sample, with rewards based on classification accuracy.</p> <p>Parameters: - <code>data_path</code> (<code>Path</code>): Path to the CSV file containing network traffic data - <code>feature_cols</code> (<code>List</code>): List of column names to use as features - <code>label_col</code> (<code>str</code>): Name of the column containing true labels (default: \"Label\")</p> <p>Attributes: - <code>df</code> (<code>pd.DataFrame</code>): Loaded network traffic dataset - <code>x</code> (<code>np.ndarray</code>): Feature matrix (samples \u00d7 features) - <code>y</code> (<code>np.ndarray</code>): Label vector (true classifications) - <code>current_step</code> (<code>int</code>): Current position in the dataset - <code>total_steps</code> (<code>int</code>): Total number of samples in dataset - <code>num_classes</code> (<code>int</code>): Number of unique attack classes - <code>action_space</code> (<code>spaces.Discrete</code>): Discrete action space for classifications - <code>observation_space</code> (<code>spaces.Box</code>): Continuous observation space for features</p> <p>Spaces: - Action Space: <code>Discrete(num_classes)</code> - Agent selects classification (0 to num_classes-1) - Observation Space: <code>Box(shape=(num_features,), dtype=float32)</code> - Network traffic features</p> <p>Example: <pre><code>from pathlib import Path\nfrom rl_ids.environments.ids_env import IDSDetectionEnv\n\n# Define feature columns (77 network traffic features)\nfeature_cols = [\n    'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets',\n    'Total Length of Fwd Packets', 'Total Length of Bwd Packets',\n    # ... (72 more features)\n]\n\n# Initialize environment\nenv = IDSDetectionEnv(\n    data_path=Path(\"data/processed/train.csv\"),\n    feature_cols=feature_cols,\n    label_col=\"Label\"\n)\n\nprint(f\"Environment initialized:\")\nprint(f\"  Samples: {env.total_steps:,}\")\nprint(f\"  Features: {env.observation_space.shape[0]}\")\nprint(f\"  Classes: {env.num_classes}\")\nprint(f\"  Action space: {env.action_space}\")\n</code></pre></p> <p>Output: <pre><code>Environment initialized:\n  Samples: 1,048,575\n  Features: 77\n  Classes: 15\n  Action space: Discrete(15)\n</code></pre></p>"},{"location":"modules/environments/#methods","title":"Methods","text":""},{"location":"modules/environments/#resetseed-optionalint-none-options-optionaldict-none-tuplenpndarray-dict","title":"<code>reset(seed: Optional[int] = None, options: Optional[dict] = None) -&gt; Tuple[np.ndarray, dict]</code>","text":"<p>Reset the environment to the initial state and return the first observation.</p> <p>Parameters: - <code>seed</code> (<code>Optional[int]</code>): Random seed for reproducibility - <code>options</code> (<code>Optional[dict]</code>): Additional reset options (currently unused)</p> <p>Returns: - <code>tuple</code>: A tuple containing:   - <code>observation</code> (<code>np.ndarray</code>): Initial state (first network traffic sample)   - <code>info</code> (<code>dict</code>): Additional information (empty dict)</p> <p>Description: Resets the environment to the beginning of the dataset. This method is called at the start of each training episode and sets <code>current_step</code> to 0.</p> <p>Example: <pre><code># Reset environment for new episode\nobservation, info = env.reset(seed=42)\n\nprint(f\"Initial observation shape: {observation.shape}\")\nprint(f\"Initial observation: {observation[:5]}...\")  # First 5 features\nprint(f\"Info: {info}\")\n</code></pre></p> <p>Output: <pre><code>Initial observation shape: (77,)\nInitial observation: [0.    0.    0.    80.   80. ]...\nInfo: {}\n</code></pre></p>"},{"location":"modules/environments/#stepaction-int-tuplenpndarray-float-bool-bool-dict","title":"<code>step(action: int) -&gt; Tuple[np.ndarray, float, bool, bool, dict]</code>","text":"<p>Execute an action in the environment and return the result.</p> <p>Parameters: - <code>action</code> (<code>int</code>): Predicted class/attack type (0 to num_classes-1)</p> <p>Returns: - <code>tuple</code>: A tuple containing:   - <code>observation</code> (<code>np.ndarray</code>): Next state (next network traffic sample)   - <code>reward</code> (<code>float</code>): Reward for the action (+1 for correct, -1 for incorrect)   - <code>terminated</code> (<code>bool</code>): Whether the episode has ended   - <code>truncated</code> (<code>bool</code>): Whether the episode was truncated (always False)   - <code>info</code> (<code>dict</code>): Additional information about the step</p> <p>Description: Processes one step in the environment by comparing the agent's predicted classification with the true label. Advances to the next sample in the dataset.</p> <p>Reward Structure: - Correct Classification: <code>+1.0</code> - Incorrect Classification: <code>-1.0</code></p> <p>Episode Termination: - Episodes end when all samples in the dataset have been processed - No early termination based on performance</p> <p>Example: <pre><code>observation, info = env.reset()\n\n# Agent makes a prediction\naction = 0  # Predict \"BENIGN\" class\n\n# Execute action\nnext_obs, reward, terminated, truncated, info = env.step(action)\n\nprint(f\"Action taken: {action}\")\nprint(f\"Reward received: {reward}\")\nprint(f\"Actual label: {info['actual_label']}\")\nprint(f\"Predicted action: {info['predicted_action']}\")\nprint(f\"Episode terminated: {terminated}\")\n</code></pre></p> <p>Output: <pre><code>Action taken: 0\nReward received: 1.0\nActual label: 0\nPredicted action: 0\nEpisode terminated: False\n</code></pre></p>"},{"location":"modules/environments/#rendermode-str-human-none","title":"<code>render(mode: str = \"human\") -&gt; None</code>","text":"<p>Render the current state of the environment.</p> <p>Parameters: - <code>mode</code> (<code>str</code>): Rendering mode (currently only supports \"human\")</p> <p>Description: Prints the current step and true label for debugging and monitoring purposes. Useful during training to track agent progress.</p> <p>Example: <pre><code># During training loop\nenv.render()\n</code></pre></p> <p>Output: <pre><code>Step: 1250, True: 5\n</code></pre></p>"},{"location":"modules/environments/#usage-patterns","title":"Usage Patterns","text":""},{"location":"modules/environments/#basic-training-loop","title":"Basic Training Loop","text":"<pre><code>from rl_ids.environments.ids_env import IDSDetectionEnv\nfrom rl_ids.agents.dqn_agent import DQNAgent, DQNConfig\nimport numpy as np\n\n# Initialize environment\nenv = IDSDetectionEnv(\n    data_path=\"data/processed/train.csv\",\n    feature_cols=feature_columns\n)\n\n# Initialize DQN agent\nconfig = DQNConfig(\n    state_dim=env.observation_space.shape[0],\n    action_dim=env.action_space.n\n)\nagent = DQNAgent(config)\n\n# Training loop\nfor episode in range(num_episodes):\n    observation, info = env.reset()\n    episode_reward = 0\n    step_count = 0\n\n    while True:\n        # Agent selects action\n        action = agent.act(observation, training=True)\n\n        # Environment processes action\n        next_observation, reward, terminated, truncated, info = env.step(action)\n\n        # Store experience for training\n        agent.remember(observation, action, reward, next_observation, terminated)\n\n        # Train agent periodically\n        if len(agent.memory) &gt; agent.config.batch_size:\n            agent.replay()\n\n        episode_reward += reward\n        step_count += 1\n        observation = next_observation\n\n        if terminated:\n            break\n\n    # Episode statistics\n    accuracy = (episode_reward + step_count) / (2 * step_count)  # Convert to accuracy\n    print(f\"Episode {episode}: Steps={step_count}, Reward={episode_reward}, Accuracy={accuracy:.3f}\")\n</code></pre>"},{"location":"modules/environments/#evaluation-loop","title":"Evaluation Loop","text":"<pre><code># Evaluation with trained agent\nagent.epsilon = 0.0  # Disable exploration\ntotal_correct = 0\ntotal_samples = 0\npredictions = []\n\nobservation, info = env.reset()\n\nwhile True:\n    action = agent.act(observation, training=False)\n    next_observation, reward, terminated, truncated, info = env.step(action)\n\n    # Collect prediction statistics\n    correct = reward &gt; 0\n    total_correct += correct\n    total_samples += 1\n\n    predictions.append({\n        'predicted': action,\n        'actual': info['actual_label'],\n        'correct': correct,\n        'confidence': agent.get_confidence(observation)\n    })\n\n    observation = next_observation\n    if terminated:\n        break\n\naccuracy = total_correct / total_samples\nprint(f\"Evaluation Accuracy: {accuracy:.4f}\")\n</code></pre>"},{"location":"modules/environments/#see-also","title":"See Also","text":"<ul> <li><code>rl_ids.agents</code> - DQN agent implementation for training</li> <li><code>rl_ids.modeling.train</code> - Training pipeline using this environment</li> <li>Training Tutorial - Step-by-step training guide</li> <li>Getting Started - Environment setup and first usage</li> <li><code>done</code>: Whether episode is finished</li> <li><code>truncated</code>: Whether episode was truncated</li> <li><code>info</code>: Additional information including actual label</li> </ul> <p>Examples</p> <pre><code># Environment step\naction = 0  # Predict class 0\nobservation, reward, done, truncated, info = env.step(action)\n\nprint(f\"Action: {action}\")\nprint(f\"Actual label: {info['actual_label']}\")\nprint(f\"Reward: {reward}\")\nprint(f\"Done: {done}\")\n\n# Continue until episode ends\nwhile not (done or truncated):\n    action = env.action_space.sample()  # Random action\n    observation, reward, done, truncated, info = env.step(action)\n</code></pre>"},{"location":"modules/environments/#rendermode-str-human-none_1","title":"<code>render(mode: str = \"human\") -&gt; None</code>","text":"<p>Render the current environment state.</p> <p>Parameters - <code>mode</code>: Rendering mode (only \"human\" supported)</p> <p>Examples</p> <pre><code># Render current state\nenv.render()\n# Output: Step: 150, True: 2\n</code></pre>"},{"location":"modules/environments/#usage-examples","title":"Usage Examples","text":""},{"location":"modules/environments/#basic-environment-usage","title":"Basic Environment Usage","text":"<pre><code>from pathlib import Path\nfrom rl_ids.environments.ids_env import IDSDetectionEnv\nimport pandas as pd\n\n# Load dataset to get feature columns\ndf = pd.read_csv(\"data/processed/train.csv\")\nfeature_cols = [col for col in df.columns if col != \"Label\"]\n\n# Initialize environment\nenv = IDSDetectionEnv(\n    data_path=Path(\"data/processed/train.csv\"),\n    feature_cols=feature_cols,\n    label_col=\"Label\"\n)\n\n# Single episode\nobservation, info = env.reset()\ntotal_reward = 0\nstep_count = 0\n\nwhile True:\n    # Take random action\n    action = env.action_space.sample()\n\n    # Environment step\n    next_observation, reward, done, truncated, info = env.step(action)\n\n    total_reward += reward\n    step_count += 1\n\n    # Optional: render state\n    if step_count % 1000 == 0:\n        env.render()\n\n    observation = next_observation\n\n    if done or truncated:\n        break\n\nprint(f\"Episode finished after {step_count} steps\")\nprint(f\"Total reward: {total_reward}\")\nprint(f\"Accuracy: {(total_reward + step_count) / (2 * step_count):.2%}\")\n</code></pre>"},{"location":"modules/environments/#agent-training-integration","title":"Agent Training Integration","text":"<pre><code>from rl_ids.agents.dqn_agent import DQNAgent, DQNConfig\nfrom rl_ids.environments.ids_env import IDSDetectionEnv\n\n# Initialize environment\nenv = IDSDetectionEnv(\n    data_path=Path(\"data/processed/train.csv\"),\n    feature_cols=feature_cols\n)\n\n# Initialize agent\nconfig = DQNConfig(\n    state_dim=env.observation_space.shape[0],\n    action_dim=env.action_space.n\n)\nagent = DQNAgent(config)\n\n# Training loop\nnum_episodes = 1000\n\nfor episode in range(num_episodes):\n    state, _ = env.reset()\n    episode_reward = 0\n    episode_steps = 0\n\n    while True:\n        # Agent selects action\n        action = agent.act(state, training=True)\n\n        # Environment step\n        next_state, reward, done, truncated, info = env.step(action)\n\n        # Store experience for agent learning\n        agent.remember(state, action, reward, next_state, done)\n\n        # Train agent\n        if len(agent.memory) &gt; agent.batch_size:\n            loss = agent.replay()\n\n        state = next_state\n        episode_reward += reward\n        episode_steps += 1\n\n        if done or truncated:\n            break\n\n    # Log progress\n    accuracy = (episode_reward + episode_steps) / (2 * episode_steps)\n    print(f\"Episode {episode}: Steps={episode_steps}, \"\n          f\"Reward={episode_reward}, Accuracy={accuracy:.2%}\")\n</code></pre>"},{"location":"modules/environments/#multi-episode-evaluation","title":"Multi-Episode Evaluation","text":"<pre><code>def evaluate_agent(agent, env, num_episodes=10):\n    \"\"\"Evaluate agent performance over multiple episodes.\"\"\"\n    total_rewards = []\n    total_accuracies = []\n\n    # Disable exploration for evaluation\n    original_epsilon = agent.epsilon\n    agent.epsilon = 0.0\n\n    for episode in range(num_episodes):\n        state, _ = env.reset()\n        episode_reward = 0\n        episode_steps = 0\n\n        while True:\n            action = agent.act(state, training=False)\n            state, reward, done, truncated, _ = env.step(action)\n\n            episode_reward += reward\n            episode_steps += 1\n\n            if done or truncated:\n                break\n\n        accuracy = (episode_reward + episode_steps) / (2 * episode_steps)\n        total_rewards.append(episode_reward)\n        total_accuracies.append(accuracy)\n\n    # Restore original epsilon\n    agent.epsilon = original_epsilon\n\n    return {\n        'mean_reward': np.mean(total_rewards),\n        'std_reward': np.std(total_rewards),\n        'mean_accuracy': np.mean(total_accuracies),\n        'std_accuracy': np.std(total_accuracies)\n    }\n\n# Evaluate trained agent\nresults = evaluate_agent(agent, env, num_episodes=50)\nprint(f\"Evaluation Results:\")\nprint(f\"  Mean Accuracy: {results['mean_accuracy']:.2%} \u00b1 {results['std_accuracy']:.2%}\")\nprint(f\"  Mean Reward: {results['mean_reward']:.2f} \u00b1 {results['std_reward']:.2f}\")\n</code></pre>"},{"location":"modules/environments/#environment-properties","title":"Environment Properties","text":""},{"location":"modules/environments/#observation-space","title":"Observation Space","text":"<ul> <li>Type: <code>gymnasium.spaces.Box</code></li> <li>Shape: <code>(n_features,)</code> where <code>n_features</code> is the number of feature columns</li> <li>Data Type: <code>np.float32</code></li> <li>Range: <code>[-inf, inf]</code> (features are typically normalized)</li> </ul>"},{"location":"modules/environments/#action-space","title":"Action Space","text":"<ul> <li>Type: <code>gymnasium.spaces.Discrete</code></li> <li>Range: <code>[0, n_classes-1]</code> where <code>n_classes</code> is the number of unique labels</li> <li>Description: Each action represents predicting a specific class</li> </ul>"},{"location":"modules/environments/#reward-structure","title":"Reward Structure","text":"Condition Reward Description Correct prediction <code>+1</code> Agent correctly classified the sample Incorrect prediction <code>-1</code> Agent misclassified the sample"},{"location":"modules/environments/#episode-termination","title":"Episode Termination","text":"<ul> <li>Natural termination: When all samples in the dataset have been processed</li> <li>Truncation: Not used in this environment</li> <li>Episode length: Varies based on dataset size</li> </ul>"},{"location":"modules/environments/#command-line-interface","title":"Command Line Interface","text":"<p>The environment module also provides CLI commands for testing and validation:</p>"},{"location":"modules/environments/#train_env","title":"<code>train_env</code>","text":"<p>Test the environment with random actions.</p> <pre><code>python -m rl_ids.environments.ids_env train_env \\\n    --data-path data/processed/train.csv \\\n    --feature-cols \"Destination_Port,Flow_Duration,Total_Fwd_Packets\" \\\n    --episodes 10\n</code></pre>"},{"location":"modules/environments/#validate_data","title":"<code>validate_data</code>","text":"<p>Validate dataset format and features.</p> <pre><code>python -m rl_ids.environments.ids_env validate_data \\\n    --data-path data/processed/train.csv \\\n    --feature-cols \"Destination_Port,Flow_Duration,Total_Fwd_Packets\"\n</code></pre>"},{"location":"modules/environments/#see-also_1","title":"See Also","text":"<ul> <li>DQN Agent Module - Reinforcement learning agent</li> <li>Training Module - Training pipelines  </li> <li>Data Processing - Dataset preparation</li> </ul>"},{"location":"modules/make_dataset/","title":"Data Processing Module","text":""},{"location":"modules/make_dataset/#overview","title":"Overview","text":"<p>The data processing module (<code>rl_ids.make_dataset</code>) provides comprehensive data preprocessing capabilities for the CICIDS2017 intrusion detection dataset. It handles data loading, cleaning, normalization, balancing, and train/validation/test splitting with advanced techniques for handling class imbalance and outliers.</p>"},{"location":"modules/make_dataset/#key-features","title":"Key Features","text":"<ul> <li>Multi-file CSV Loading - Automatic detection and combination of multiple CSV files</li> <li>Advanced Data Cleaning - Handles missing values, infinite values, and outliers  </li> <li>Multiple Normalization Methods - Standard, Robust, and MinMax scaling options</li> <li>Class Balancing - SMOTE, SMOTETomek, and undersampling techniques</li> <li>Stratified Splitting - Maintains class distribution across splits</li> <li>Memory Optimization - Efficient data type conversion and memory management</li> <li>Progress Tracking - Visual progress bars for long-running operations</li> </ul>"},{"location":"modules/make_dataset/#classes","title":"Classes","text":""},{"location":"modules/make_dataset/#datagenerator","title":"<code>DataGenerator</code>","text":"<p>Handles loading and initial preprocessing of raw CSV data files.</p> <p>Methods</p>"},{"location":"modules/make_dataset/#load_and_preprocess_datadata_dir-path-raw_data_dir-pddataframe","title":"<code>load_and_preprocess_data(data_dir: Path = RAW_DATA_DIR) -&gt; pd.DataFrame</code>","text":"<p>Loads and preprocesses CSV data files from the specified directory.</p> <p>Parameters</p> Name Type Description <code>data_dir</code> <code>Path</code> Directory containing CSV files (default: <code>RAW_DATA_DIR</code>) <p>Returns - <code>pd.DataFrame</code>: Combined and preprocessed dataset</p> <p>Processing Steps 1. Loads all CSV files from the directory 2. Combines multiple files into single dataset 3. Removes columns with all null values 4. Fills remaining null values with 0 5. Handles infinite values 6. Encodes categorical labels 7. Optimizes data types for memory efficiency</p> <p>Example <pre><code>from rl_ids.make_dataset import DataGenerator\nfrom rl_ids.config import RAW_DATA_DIR\n\n# Initialize data generator\ngenerator = DataGenerator()\n\n# Load and preprocess data\ndata = generator.load_and_preprocess_data(RAW_DATA_DIR)\nprint(f\"Loaded dataset shape: {data.shape}\")\n\n# Get label mapping\nlabel_mapping = generator.get_label_mapping()\nprint(f\"Label mapping: {label_mapping}\")\n</code></pre></p>"},{"location":"modules/make_dataset/#get_label_mapping-dict","title":"<code>get_label_mapping() -&gt; dict</code>","text":"<p>Returns mapping between encoded labels and original label names.</p> <p>Returns - <code>dict</code>: Mapping from encoded integers to original label strings</p>"},{"location":"modules/make_dataset/#save_processed_dataoutput_path-path-data-pddataframe-none-path","title":"<code>save_processed_data(output_path: Path, data: pd.DataFrame = None) -&gt; Path</code>","text":"<p>Saves processed data to specified path.</p> <p>Parameters</p> Name Type Description <code>output_path</code> <code>Path</code> Path to save the processed data <code>data</code> <code>pd.DataFrame</code> Data to save (optional, uses internal data if None) <p>Returns - <code>Path</code>: Path where data was saved</p>"},{"location":"modules/make_dataset/#dataprocessor","title":"<code>DataProcessor</code>","text":"<p>Enhanced data processing with multiple normalization and balancing strategies.</p> <p>Methods</p>"},{"location":"modules/make_dataset/#normalize_datadf-pddataframe-method-str-robust-handle_outliers-bool-true-pddataframe","title":"<code>normalize_data(df: pd.DataFrame, method: str = 'robust', handle_outliers: bool = True) -&gt; pd.DataFrame</code>","text":"<p>Normalizes features using specified scaling method with outlier handling.</p> <p>Parameters</p> Name Type Description <code>df</code> <code>pd.DataFrame</code> Input dataframe to normalize <code>method</code> <code>str</code> Scaling method ('standard', 'robust', 'minmax') <code>handle_outliers</code> <code>bool</code> Whether to handle outliers before normalization <p>Returns - <code>pd.DataFrame</code>: Normalized dataset</p> <p>Normalization Methods - <code>'standard'</code>: StandardScaler - zero mean, unit variance - <code>'robust'</code>: RobustScaler - uses median and IQR, robust to outliers - <code>'minmax'</code>: MinMaxScaler - scales to [0,1] range</p> <p>Example <pre><code>from rl_ids.make_dataset import DataProcessor\n\nprocessor = DataProcessor()\n\n# Robust normalization (recommended)\nnormalized_data = processor.normalize_data(\n    data, \n    method='robust', \n    handle_outliers=True\n)\n\n# Standard normalization\nstandard_data = processor.normalize_data(\n    data, \n    method='standard', \n    handle_outliers=False\n)\n</code></pre></p>"},{"location":"modules/make_dataset/#balance_datadf-pddataframe-method-str-smote-random_state-int-42-pddataframe","title":"<code>balance_data(df: pd.DataFrame, method: str = 'smote', random_state: int = 42) -&gt; pd.DataFrame</code>","text":"<p>Balances dataset using specified method to handle class imbalance.</p> <p>Parameters</p> Name Type Description <code>df</code> <code>pd.DataFrame</code> Input dataframe to balance <code>method</code> <code>str</code> Balancing method ('smote', 'smotetomek', 'undersample') <code>random_state</code> <code>int</code> Random seed for reproducibility <p>Returns - <code>pd.DataFrame</code>: Balanced dataset</p> <p>Balancing Methods - <code>'smote'</code>: SMOTE oversampling - generates synthetic minority samples - <code>'smotetomek'</code>: SMOTE + Tomek links - oversampling + cleaning - <code>'undersample'</code>: Random undersampling of majority classes</p> <p>Example <pre><code># SMOTE balancing (recommended for minority classes)\nbalanced_data = processor.balance_data(\n    normalized_data, \n    method='smote', \n    random_state=42\n)\n\n# Combined SMOTE + Tomek cleaning\nclean_balanced_data = processor.balance_data(\n    normalized_data, \n    method='smotetomek', \n    random_state=42\n)\n</code></pre></p>"},{"location":"modules/make_dataset/#split_datadf-pddataframe-test_size-float-02-val_size-float-02-random_state-int-42-tuplepddataframe-pddataframe-pddataframe","title":"<code>split_data(df: pd.DataFrame, test_size: float = 0.2, val_size: float = 0.2, random_state: int = 42) -&gt; Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]</code>","text":"<p>Splits data into train/validation/test sets using stratified sampling.</p> <p>Parameters</p> Name Type Description <code>df</code> <code>pd.DataFrame</code> Input dataframe to split <code>test_size</code> <code>float</code> Proportion for test set (0.0-1.0) <code>val_size</code> <code>float</code> Proportion for validation set (0.0-1.0) <code>random_state</code> <code>int</code> Random seed for reproducibility <p>Returns - <code>Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]</code>: (train, validation, test) datasets</p> <p>Example <pre><code># Split with 60% train, 20% val, 20% test\ntrain_data, val_data, test_data = processor.split_data(\n    balanced_data,\n    test_size=0.2,\n    val_size=0.2,\n    random_state=42\n)\n\nprint(f\"Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}\")\n</code></pre></p>"},{"location":"modules/make_dataset/#command-line-interface","title":"Command Line Interface","text":"<p>The module provides a CLI for data processing operations:</p> <pre><code># Process data with default settings\npython -m rl_ids.make_dataset\n\n# Custom normalization method\npython -m rl_ids.make_dataset --normalize-method robust\n\n# Custom balancing method  \npython -m rl_ids.make_dataset --balance-method smote\n\n# Custom output directory\npython -m rl_ids.make_dataset --output-dir ./custom_output\n\n# Skip balancing step\npython -m rl_ids.make_dataset --no-balance\n\n# Enable debug logging\npython -m rl_ids.make_dataset --verbose\n</code></pre>"},{"location":"modules/make_dataset/#cli-options","title":"CLI Options","text":"Option Type Description <code>--input-dir</code> <code>Path</code> Input directory with raw CSV files <code>--output-dir</code> <code>Path</code> Output directory for processed files <code>--normalize-method</code> <code>str</code> Normalization method (standard/robust/minmax) <code>--balance-method</code> <code>str</code> Balancing method (smote/smotetomek/undersample) <code>--test-size</code> <code>float</code> Test set proportion <code>--val-size</code> <code>float</code> Validation set proportion <code>--no-balance</code> <code>bool</code> Skip data balancing <code>--random-state</code> <code>int</code> Random seed <code>--verbose</code> <code>bool</code> Enable debug logging"},{"location":"modules/make_dataset/#complete-processing-pipeline","title":"Complete Processing Pipeline","text":""},{"location":"modules/make_dataset/#example-full-data-processing-workflow","title":"Example: Full Data Processing Workflow","text":"<pre><code>from rl_ids.make_dataset import DataGenerator, DataProcessor\nfrom rl_ids.config import RAW_DATA_DIR, PROCESSED_DATA_DIR\nfrom pathlib import Path\n\ndef process_cicids_data():\n    \"\"\"Complete data processing pipeline\"\"\"\n\n    # Step 1: Load and preprocess raw data\n    generator = DataGenerator()\n    raw_data = generator.load_and_preprocess_data(RAW_DATA_DIR)\n\n    # Save initial processed data\n    processed_file = PROCESSED_DATA_DIR / \"cicids2017_processed.csv\"\n    generator.save_processed_data(processed_file, raw_data)\n\n    # Step 2: Advanced processing\n    processor = DataProcessor()\n\n    # Normalize features\n    normalized_data = processor.normalize_data(\n        raw_data, \n        method='robust', \n        handle_outliers=True\n    )\n\n    # Save normalized data\n    normalized_file = PROCESSED_DATA_DIR / \"cicids2017_normalized.csv\"\n    normalized_data.to_csv(normalized_file, index=False)\n\n    # Balance classes\n    balanced_data = processor.balance_data(\n        normalized_data, \n        method='smote', \n        random_state=42\n    )\n\n    # Save balanced data\n    balanced_file = PROCESSED_DATA_DIR / \"cicids2017_balanced.csv\"\n    balanced_data.to_csv(balanced_file, index=False)\n\n    # Split into train/val/test\n    train_data, val_data, test_data = processor.split_data(\n        balanced_data,\n        test_size=0.2,\n        val_size=0.2,\n        random_state=42\n    )\n\n    # Save splits\n    train_data.to_csv(PROCESSED_DATA_DIR / \"train.csv\", index=False)\n    val_data.to_csv(PROCESSED_DATA_DIR / \"val.csv\", index=False)\n    test_data.to_csv(PROCESSED_DATA_DIR / \"test.csv\", index=False)\n\n    # Get label mapping for reference\n    label_mapping = generator.get_label_mapping()\n\n    return {\n        'train_size': len(train_data),\n        'val_size': len(val_data),\n        'test_size': len(test_data),\n        'features': len(processor.feature_columns),\n        'classes': len(label_mapping),\n        'label_mapping': label_mapping\n    }\n\n# Run the pipeline\nresults = process_cicids_data()\nprint(f\"Processing complete: {results}\")\n</code></pre>"},{"location":"modules/make_dataset/#data-quality-and-validation","title":"Data Quality and Validation","text":""},{"location":"modules/make_dataset/#feature-statistics","title":"Feature Statistics","text":"<pre><code>def analyze_data_quality(df: pd.DataFrame):\n    \"\"\"Analyze data quality metrics\"\"\"\n\n    print(f\"Dataset shape: {df.shape}\")\n    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n\n    # Check for missing values\n    missing_values = df.isnull().sum().sum()\n    print(f\"Missing values: {missing_values}\")\n\n    # Check for infinite values\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    inf_values = np.isinf(df[numeric_cols]).sum().sum()\n    print(f\"Infinite values: {inf_values}\")\n\n    # Class distribution\n    if 'Label' in df.columns:\n        class_dist = df['Label'].value_counts().sort_index()\n        print(\"Class distribution:\")\n        for label, count in class_dist.items():\n            percentage = count / len(df) * 100\n            print(f\"  Class {label}: {count:,} ({percentage:.1f}%)\")\n</code></pre>"},{"location":"modules/make_dataset/#data-validation-checks","title":"Data Validation Checks","text":"<pre><code>def validate_processed_data(df: pd.DataFrame) -&gt; bool:\n    \"\"\"Validate processed data meets requirements\"\"\"\n\n    checks = []\n\n    # Check 1: No missing values\n    has_missing = df.isnull().sum().sum() &gt; 0\n    checks.append(('No missing values', not has_missing))\n\n    # Check 2: No infinite values\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    has_infinite = np.isinf(df[numeric_cols]).sum().sum() &gt; 0\n    checks.append(('No infinite values', not has_infinite))\n\n    # Check 3: Features are numeric\n    feature_cols = [col for col in df.columns if col not in ['Label', 'Label_Original']]\n    all_numeric = all(df[col].dtype in ['int64', 'float64', 'float32'] for col in feature_cols)\n    checks.append(('All features numeric', all_numeric))\n\n    # Check 4: Labels are encoded\n    if 'Label' in df.columns:\n        labels_encoded = df['Label'].dtype in ['int64', 'int32']\n        checks.append(('Labels encoded', labels_encoded))\n\n    # Print results\n    for check_name, passed in checks:\n        status = \"\u2705 PASS\" if passed else \"\u274c FAIL\"\n        print(f\"{status} {check_name}\")\n\n    return all(passed for _, passed in checks)\n</code></pre>"},{"location":"modules/make_dataset/#performance-optimization","title":"Performance Optimization","text":""},{"location":"modules/make_dataset/#memory-efficiency","title":"Memory Efficiency","text":"<pre><code>def optimize_memory_usage(df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Optimize dataframe memory usage\"\"\"\n\n    initial_memory = df.memory_usage(deep=True).sum() / 1024**2\n\n    # Optimize numeric columns\n    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n    for col in numeric_cols:\n        if col not in ['Label', 'Label_Original']:\n            # Convert to float32 if possible\n            if df[col].dtype == 'float64':\n                df[col] = df[col].astype('float32')\n            elif df[col].dtype == 'int64':\n                # Check if int32 is sufficient\n                if df[col].min() &gt;= -2147483648 and df[col].max() &lt;= 2147483647:\n                    df[col] = df[col].astype('int32')\n\n    final_memory = df.memory_usage(deep=True).sum() / 1024**2\n    memory_reduction = (initial_memory - final_memory) / initial_memory * 100\n\n    print(f\"Memory optimization: {initial_memory:.1f}MB \u2192 {final_memory:.1f}MB\")\n    print(f\"Reduction: {memory_reduction:.1f}%\")\n\n    return df\n</code></pre>"},{"location":"modules/make_dataset/#batch-processing","title":"Batch Processing","text":"<pre><code>def process_large_dataset_in_chunks(file_path: Path, chunk_size: int = 10000):\n    \"\"\"Process large datasets in chunks to manage memory\"\"\"\n\n    processor = DataProcessor()\n    processed_chunks = []\n\n    # Process data in chunks\n    for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n        # Apply processing to chunk\n        normalized_chunk = processor.normalize_data(chunk, method='robust')\n        processed_chunks.append(normalized_chunk)\n\n    # Combine processed chunks\n    final_data = pd.concat(processed_chunks, ignore_index=True)\n    return final_data\n</code></pre>"},{"location":"modules/make_dataset/#troubleshooting","title":"Troubleshooting","text":""},{"location":"modules/make_dataset/#common-issues","title":"Common Issues","text":"<ol> <li> <p>Memory Errors with Large Datasets <pre><code># Use chunked processing\nchunk_size = 5000  # Reduce if still getting memory errors\ndata = process_large_dataset_in_chunks(data_file, chunk_size)\n</code></pre></p> </li> <li> <p>Infinite Values in Data <pre><code># Check for infinite values before processing\ninf_cols = df.columns[np.isinf(df.select_dtypes(include=[np.number])).any()]\nprint(f\"Columns with infinite values: {inf_cols.tolist()}\")\n\n# Replace infinite values\ndf = df.replace([np.inf, -np.inf], np.nan)\ndf = df.fillna(df.median())\n</code></pre></p> </li> <li> <p>Class Imbalance Issues <pre><code># Check class distribution\nclass_counts = df['Label'].value_counts()\nimbalance_ratio = class_counts.max() / class_counts.min()\n\nif imbalance_ratio &gt; 10:\n    print(f\"High class imbalance detected: {imbalance_ratio:.1f}:1\")\n    # Use SMOTE or SMOTETomek for balancing\n    balanced_data = processor.balance_data(df, method='smotetomek')\n</code></pre></p> </li> <li> <p>Normalization Failures <pre><code># Check for constant features (zero variance)\nconstant_features = df.var() == 0\nif constant_features.any():\n    print(f\"Constant features detected: {constant_features[constant_features].index.tolist()}\")\n    # Remove constant features\n    df = df.loc[:, ~constant_features]\n</code></pre></p> </li> </ol>"},{"location":"modules/make_dataset/#see-also","title":"See Also","text":"<ul> <li>Configuration Module - Path and settings management</li> <li>Environment Module - Using processed data in RL environment</li> <li>Training Module - Training with processed data</li> <li>Getting Started Guide - Complete setup workflow</li> </ul>"},{"location":"modules/modeling/","title":"Training &amp; Evaluation Module","text":""},{"location":"modules/modeling/#overview","title":"Overview","text":"<p>The <code>rl_ids.modeling</code> module provides comprehensive training and evaluation pipelines for the DQN-based intrusion detection system. It includes advanced training features such as curriculum learning, early stopping, and detailed performance analysis.</p>"},{"location":"modules/modeling/#modules","title":"Modules","text":""},{"location":"modules/modeling/#rl_idsmodelingtrain","title":"<code>rl_ids.modeling.train</code>","text":"<p>Advanced DQN training pipeline with optimization techniques.</p>"},{"location":"modules/modeling/#rl_idsmodelingevaluate","title":"<code>rl_ids.modeling.evaluate</code>","text":"<p>Comprehensive model evaluation and performance analysis.</p>"},{"location":"modules/modeling/#training-module-trainpy","title":"Training Module (<code>train.py</code>)","text":""},{"location":"modules/modeling/#main-function","title":"<code>main()</code> Function","text":"<p>Main training function with extensive configuration options.</p> <p>Parameters</p> Parameter Type Default Description <code>train_data_path</code> <code>Path</code> <code>TRAIN_DATA_FILE</code> Path to training data <code>val_data_path</code> <code>Path</code> <code>VAL_DATA_FILE</code> Path to validation data <code>num_episodes</code> <code>int</code> <code>500</code> Number of training episodes <code>target_update_interval</code> <code>int</code> <code>10</code> Target network update frequency <code>lr</code> <code>float</code> <code>1e-4</code> Learning rate <code>lr_scheduler</code> <code>str</code> <code>\"cosine\"</code> LR scheduler type <code>gamma</code> <code>float</code> <code>0.995</code> Discount factor <code>epsilon</code> <code>float</code> <code>1.0</code> Initial exploration rate <code>eps_decay</code> <code>float</code> <code>0.9995</code> Epsilon decay rate <code>eps_min</code> <code>float</code> <code>0.01</code> Minimum epsilon <code>memory_size</code> <code>int</code> <code>100000</code> Replay buffer size <code>batch_size</code> <code>int</code> <code>256</code> Training batch size <code>hidden_dims</code> <code>str</code> <code>\"1024,512,256,128\"</code> Network architecture <code>dropout_rate</code> <code>float</code> <code>0.2</code> Dropout rate <code>use_layer_norm</code> <code>bool</code> <code>True</code> Use layer normalization <code>save_interval</code> <code>int</code> <code>50</code> Model save frequency <code>validation_interval</code> <code>int</code> <code>5</code> Validation frequency <code>early_stopping_patience</code> <code>int</code> <code>30</code> Early stopping patience <code>grad_clip</code> <code>float</code> <code>1.0</code> Gradient clipping value <code>weight_decay</code> <code>float</code> <code>1e-5</code> Weight decay <code>double_dqn</code> <code>bool</code> <code>True</code> Use Double DQN <code>dueling</code> <code>bool</code> <code>True</code> Use Dueling DQN <code>curriculum_learning</code> <code>bool</code> <code>True</code> Use curriculum learning <p>Examples</p> <pre><code># Basic training\npython -m rl_ids.modeling.train\n\n# Advanced training with custom parameters\npython -m rl_ids.modeling.train \\\n    --num-episodes 1000 \\\n    --lr 1e-4 \\\n    --batch-size 256 \\\n    --hidden-dims \"1024,512,256,128\" \\\n    --gamma 0.995 \\\n    --epsilon 1.0 \\\n    --eps-decay 0.9995 \\\n    --memory-size 200000 \\\n    --double-dqn \\\n    --dueling \\\n    --curriculum-learning\n\n# Training with specific data paths\npython -m rl_ids.modeling.train \\\n    --train-data-path data/processed/train.csv \\\n    --val-data-path data/processed/val.csv \\\n    --models-dir models/experiment_1\n</code></pre>"},{"location":"modules/modeling/#advanced-features","title":"Advanced Features","text":""},{"location":"modules/modeling/#curriculum-learning","title":"Curriculum Learning","text":"<p>Progressive training difficulty to improve learning stability.</p> <pre><code># Automatically enabled with --curriculum-learning\n# Stages:\n# 1. Easy samples (high confidence labels)\n# 2. Medium difficulty samples\n# 3. Full dataset including difficult samples\n</code></pre>"},{"location":"modules/modeling/#early-stopping","title":"Early Stopping","text":"<p>Prevents overfitting by monitoring validation performance.</p> <pre><code># Monitors validation accuracy\n# Stops training if no improvement for 'patience' episodes\n# Automatically saves best model\n</code></pre>"},{"location":"modules/modeling/#learning-rate-scheduling","title":"Learning Rate Scheduling","text":"<p>Adaptive learning rate adjustment.</p> Scheduler Description <code>\"cosine\"</code> Cosine annealing <code>\"step\"</code> Step decay <code>\"none\"</code> Fixed learning rate"},{"location":"modules/modeling/#advanced-dqn-techniques","title":"Advanced DQN Techniques","text":"<ul> <li>Double DQN: Reduces overestimation bias</li> <li>Dueling DQN: Separate value and advantage streams</li> <li>Prioritized Replay: Focus on important experiences</li> </ul>"},{"location":"modules/modeling/#evaluation-module-evaluatepy","title":"Evaluation Module (<code>evaluate.py</code>)","text":""},{"location":"modules/modeling/#main-function_1","title":"<code>main()</code> Function","text":"<p>Comprehensive model evaluation with detailed analysis.</p> <p>Parameters</p> Parameter Type Default Description <code>test_data_path</code> <code>Path</code> <code>TEST_DATA_FILE</code> Path to test data <code>model_path</code> <code>Path</code> <code>MODELS_DIR / \"dqn_model_final.pt\"</code> Model to evaluate <code>test_episodes</code> <code>int</code> <code>15</code> Number of test episodes <code>max_steps_per_episode</code> <code>int</code> <code>20000</code> Max steps per episode <code>save_predictions</code> <code>bool</code> <code>True</code> Save detailed predictions <code>use_best_model</code> <code>bool</code> <code>True</code> Use best model vs final <code>detailed_analysis</code> <code>bool</code> <code>True</code> Perform error analysis <code>confidence_threshold</code> <code>float</code> <code>0.8</code> High-confidence threshold <p>Examples</p> <pre><code># Basic evaluation\npython -m rl_ids.modeling.evaluate\n\n# Evaluate specific model\npython -m rl_ids.modeling.evaluate \\\n    --model-path models/dqn_model_best.pt \\\n    --test-episodes 25 \\\n    --detailed-analysis\n\n# Quick evaluation without detailed analysis\npython -m rl_ids.modeling.evaluate \\\n    --test-episodes 5 \\\n    --detailed-analysis false \\\n    --save-predictions false\n</code></pre>"},{"location":"modules/modeling/#generated-reports","title":"Generated Reports","text":"<p>The evaluation generates comprehensive reports in the <code>reports/</code> directory:</p>"},{"location":"modules/modeling/#summary-reports","title":"Summary Reports","text":"<ul> <li><code>evaluation_summary_enhanced.csv</code>: Overall performance metrics</li> <li><code>evaluation_episode_details_enhanced.csv</code>: Per-episode results</li> </ul>"},{"location":"modules/modeling/#detailed-analysis","title":"Detailed Analysis","text":"<ul> <li><code>evaluation_detailed_predictions_enhanced.csv</code>: Individual predictions</li> <li><code>evaluation_classification_report.csv</code>: Per-class metrics</li> <li><code>evaluation_confusion_matrix.csv</code>: Confusion matrix data</li> </ul>"},{"location":"modules/modeling/#visualizations","title":"Visualizations","text":"<ul> <li><code>evaluation_overview.png</code>: Comprehensive performance overview</li> <li><code>class_analysis.png</code>: Per-class performance analysis</li> <li><code>error_analysis.png</code>: Error pattern analysis</li> <li><code>enhanced_confusion_matrix.png</code>: Detailed confusion matrix</li> </ul>"},{"location":"modules/modeling/#usage-examples","title":"Usage Examples","text":""},{"location":"modules/modeling/#complete-training-pipeline","title":"Complete Training Pipeline","text":"<pre><code>from pathlib import Path\nfrom rl_ids.modeling.train import main as train_main\nfrom rl_ids.modeling.evaluate import main as evaluate_main\n\n# Training with custom parameters\ntrain_main(\n    num_episodes=1000,\n    lr=1e-4,\n    batch_size=256,\n    hidden_dims=\"1024,512,256,128\",\n    gamma=0.995,\n    double_dqn=True,\n    dueling=True,\n    curriculum_learning=True,\n    early_stopping_patience=30\n)\n\n# Evaluate the trained model\nevaluate_main(\n    test_episodes=25,\n    detailed_analysis=True,\n    save_predictions=True\n)\n</code></pre>"},{"location":"modules/modeling/#custom-training-loop","title":"Custom Training Loop","text":"<pre><code>import torch\nfrom rl_ids.agents.dqn_agent import DQNAgent, DQNConfig\nfrom rl_ids.environments.ids_env import IDSDetectionEnv\nfrom rl_ids.config import TRAIN_DATA_FILE\n\n# Load data and setup\nfeature_cols = [...] # Your feature columns\nenv = IDSDetectionEnv(\n    data_path=TRAIN_DATA_FILE,\n    feature_cols=feature_cols\n)\n\n# Initialize agent\nconfig = DQNConfig(\n    state_dim=len(feature_cols),\n    action_dim=env.action_space.n,\n    lr=1e-4,\n    gamma=0.995,\n    hidden_dims=[1024, 512, 256, 128]\n)\nagent = DQNAgent(config)\n\n# Training metrics\nepisode_rewards = []\nepisode_accuracies = []\nlosses = []\n\n# Training loop\nnum_episodes = 1000\ntarget_update_interval = 10\n\nfor episode in range(num_episodes):\n    state, _ = env.reset()\n    episode_reward = 0\n    episode_steps = 0\n    episode_losses = []\n\n    while True:\n        # Agent action\n        action = agent.act(state, training=True)\n\n        # Environment step\n        next_state, reward, done, truncated, info = env.step(action)\n\n        # Store experience\n        agent.remember(state, action, reward, next_state, done)\n\n        # Train agent\n        if len(agent.memory) &gt; agent.batch_size:\n            loss = agent.replay()\n            if loss is not None:\n                episode_losses.append(loss)\n\n        state = next_state\n        episode_reward += reward\n        episode_steps += 1\n\n        if done or truncated:\n            break\n\n    # Update target network\n    if episode % target_update_interval == 0:\n        agent.update_target()\n\n    # Calculate metrics\n    accuracy = (episode_reward + episode_steps) / (2 * episode_steps)\n    avg_loss = np.mean(episode_losses) if episode_losses else 0\n\n    episode_rewards.append(episode_reward)\n    episode_accuracies.append(accuracy)\n    losses.append(avg_loss)\n\n    # Logging\n    if episode % 50 == 0:\n        print(f\"Episode {episode}:\")\n        print(f\"  Reward: {episode_reward}\")\n        print(f\"  Accuracy: {accuracy:.2%}\")\n        print(f\"  Avg Loss: {avg_loss:.4f}\")\n        print(f\"  Epsilon: {agent.epsilon:.4f}\")\n\n        # Save model checkpoint\n        agent.save_model(f\"models/episode_{episode}.pt\")\n\n# Save final model\nagent.save_model(\"models/dqn_model_final.pt\")\n</code></pre>"},{"location":"modules/modeling/#validation-during-training","title":"Validation During Training","text":"<pre><code>def validate_agent(agent, val_env, max_steps=5000):\n    \"\"\"Validate agent performance.\"\"\"\n    original_epsilon = agent.epsilon\n    agent.epsilon = 0.0  # Disable exploration\n\n    state, _ = val_env.reset()\n    total_reward = 0\n    step_count = 0\n    correct_predictions = 0\n\n    while step_count &lt; max_steps:\n        action = agent.act(state, training=False)\n        next_state, reward, done, truncated, info = val_env.step(action)\n\n        total_reward += reward\n        step_count += 1\n\n        if reward &gt; 0:\n            correct_predictions += 1\n\n        state = next_state\n\n        if done or truncated:\n            break\n\n    agent.epsilon = original_epsilon\n\n    accuracy = correct_predictions / step_count if step_count &gt; 0 else 0\n    return {\n        'accuracy': accuracy,\n        'total_reward': total_reward,\n        'steps': step_count\n    }\n\n# Use in training loop\nif episode % validation_interval == 0:\n    val_results = validate_agent(agent, val_env)\n    print(f\"Validation - Accuracy: {val_results['accuracy']:.2%}\")\n</code></pre>"},{"location":"modules/modeling/#performance-metrics","title":"Performance Metrics","text":""},{"location":"modules/modeling/#training-metrics","title":"Training Metrics","text":"<ul> <li>Episode Reward: Cumulative reward per episode</li> <li>Accuracy: Percentage of correct classifications</li> <li>Loss: Training loss value</li> <li>Epsilon: Current exploration rate</li> <li>Learning Rate: Current learning rate (if using scheduler)</li> </ul>"},{"location":"modules/modeling/#evaluation-metrics","title":"Evaluation Metrics","text":"<ul> <li>Overall Accuracy: Total correct predictions / total predictions</li> <li>Per-Class Metrics: Precision, recall, F1-score for each class</li> <li>Confidence Analysis: Performance at different confidence levels</li> <li>Confusion Matrix: Detailed classification results</li> <li>Prediction Times: Average inference time per sample</li> </ul>"},{"location":"modules/modeling/#configuration-tips","title":"Configuration Tips","text":""},{"location":"modules/modeling/#memory-management","title":"Memory Management","text":"<pre><code># For limited GPU memory\npython -m rl_ids.modeling.train --batch-size 64 --memory-size 50000\n\n# For high-memory systems\npython -m rl_ids.modeling.train --batch-size 512 --memory-size 500000\n</code></pre>"},{"location":"modules/modeling/#learning-rate-tuning","title":"Learning Rate Tuning","text":"<pre><code># Conservative learning\npython -m rl_ids.modeling.train --lr 5e-5 --lr-scheduler cosine\n\n# Aggressive learning\npython -m rl_ids.modeling.train --lr 1e-3 --lr-scheduler step\n</code></pre>"},{"location":"modules/modeling/#network-architecture","title":"Network Architecture","text":"<pre><code># Lightweight model\npython -m rl_ids.modeling.train --hidden-dims \"256,128\"\n\n# Large model\npython -m rl_ids.modeling.train --hidden-dims \"2048,1024,512,256,128\"\n</code></pre>"},{"location":"modules/modeling/#see-also","title":"See Also","text":"<ul> <li>DQN Agent Module - Reinforcement learning implementation</li> <li>Environment Module - Training environment</li> <li>Visualization Module - Analysis and plotting tools</li> </ul>"},{"location":"modules/plots/","title":"Visualization Module","text":""},{"location":"modules/plots/#overview","title":"Overview","text":"<p>The visualization module (<code>rl_ids.plots</code>) provides comprehensive plotting and analysis tools for the RL-IDS system. It generates publication-quality visualizations for training metrics, evaluation results, class distributions, error analysis, and model performance insights.</p>"},{"location":"modules/plots/#key-features","title":"Key Features","text":"<ul> <li>Training Metrics Visualization - Comprehensive training progress plots</li> <li>Evaluation Analytics - Model performance and confusion matrix analysis</li> <li>Class Distribution Analysis - Detailed class imbalance and prediction patterns</li> <li>Error Analysis - Misclassification patterns and confidence analysis</li> <li>Publication-Quality Output - High-resolution, customizable plots</li> <li>Batch Plot Generation - Automated report generation from CSV files</li> <li>Interactive CLI - Command-line interface for plot generation</li> </ul>"},{"location":"modules/plots/#classes","title":"Classes","text":""},{"location":"modules/plots/#idsplotter","title":"<code>IDSPlotter</code>","text":"<p>Main plotting class providing comprehensive visualization capabilities.</p> <p>Constructor</p> <pre><code>IDSPlotter(figures_dir: Path = FIGURES_DIR, dpi: int = 300)\n</code></pre> <p>Parameters</p> Name Type Description <code>figures_dir</code> <code>Path</code> Directory to save generated figures <code>dpi</code> <code>int</code> Resolution for saved figures (default: 300) <p>Attributes</p> Name Type Description <code>figures_dir</code> <code>Path</code> Output directory for plots <code>dpi</code> <code>int</code> Image resolution <code>colors</code> <code>dict</code> Color scheme for consistent styling <code>class_colors</code> <code>list</code> Color palette for class-based plots"},{"location":"modules/plots/#core-methods","title":"Core Methods","text":""},{"location":"modules/plots/#training-visualization","title":"Training Visualization","text":""},{"location":"modules/plots/#plot_training_metricsmetrics_path-unionstr-path-save_name-str-training_metrics_overview-none","title":"<code>plot_training_metrics(metrics_path: Union[str, Path], save_name: str = \"training_metrics_overview\") -&gt; None</code>","text":"<p>Creates comprehensive training metrics visualization including accuracy, reward, loss, and epsilon decay.</p> <p>Parameters</p> Name Type Description <code>metrics_path</code> <code>Union[str, Path]</code> Path to training metrics CSV file <code>save_name</code> <code>str</code> Base name for saved plot files <p>Generated Plots - Training accuracy progression with mean/max lines - Training reward with moving average - Loss curves (Q-loss, policy loss if available) - Epsilon decay schedule - Learning rate progression - Episode duration analysis</p> <p>Example <pre><code>from rl_ids.plots import IDSPlotter\nfrom rl_ids.config import REPORTS_DIR, FIGURES_DIR\n\nplotter = IDSPlotter(FIGURES_DIR, dpi=300)\n\n# Plot training metrics\nplotter.plot_training_metrics(\n    metrics_path=REPORTS_DIR / \"training_metrics.csv\",\n    save_name=\"dqn_training_overview\"\n)\n</code></pre></p>"},{"location":"modules/plots/#plot_episode_analysismetrics_path-unionstr-path-save_name-str-episode_analysis-none","title":"<code>plot_episode_analysis(metrics_path: Union[str, Path], save_name: str = \"episode_analysis\") -&gt; None</code>","text":"<p>Analyzes episode-level performance patterns and convergence behavior.</p> <p>Generated Plots - Episode reward distribution - Episode length analysis - Convergence detection - Performance stability metrics</p>"},{"location":"modules/plots/#evaluation-visualization","title":"Evaluation Visualization","text":""},{"location":"modules/plots/#plot_evaluation_overviewreports_dir-path-save_name-str-evaluation_overview-none","title":"<code>plot_evaluation_overview(reports_dir: Path, save_name: str = \"evaluation_overview\") -&gt; None</code>","text":"<p>Creates comprehensive evaluation analysis from generated CSV reports.</p> <p>Parameters</p> Name Type Description <code>reports_dir</code> <code>Path</code> Directory containing evaluation CSV files <code>save_name</code> <code>str</code> Base name for saved plot files <p>Required CSV Files - <code>evaluation_summary.csv</code> - Overall performance metrics - <code>evaluation_confusion_matrix.csv</code> - Confusion matrix data - <code>evaluation_detailed_predictions.csv</code> - Per-sample predictions - <code>evaluation_classification_report.csv</code> - Per-class metrics</p> <p>Generated Plots - Overall accuracy and performance metrics - Confusion matrix heatmap - Per-class precision, recall, F1-score - Prediction confidence distribution - ROC curves (if binary classification)</p> <p>Example <pre><code># Generate evaluation overview from reports\nplotter.plot_evaluation_overview(\n    reports_dir=REPORTS_DIR,\n    save_name=\"model_evaluation_complete\"\n)\n</code></pre></p>"},{"location":"modules/plots/#plot_confusion_matrixcm_data-unionnpndarray-pddataframe-class_names-list-none-save_name-str-confusion_matrix-none","title":"<code>plot_confusion_matrix(cm_data: Union[np.ndarray, pd.DataFrame], class_names: list = None, save_name: str = \"confusion_matrix\") -&gt; None</code>","text":"<p>Creates enhanced confusion matrix visualization.</p> <p>Parameters</p> Name Type Description <code>cm_data</code> <code>Union[np.ndarray, pd.DataFrame]</code> Confusion matrix data <code>class_names</code> <code>list</code> List of class names for labels <code>save_name</code> <code>str</code> Name for saved plot file <p>Features - Normalized and raw count versions - Per-class accuracy annotations - Color-coded intensity mapping - Statistical summary overlay</p>"},{"location":"modules/plots/#class-analysis","title":"Class Analysis","text":""},{"location":"modules/plots/#plot_class_analysisreports_dir-path-save_name-str-class_analysis-none","title":"<code>plot_class_analysis(reports_dir: Path, save_name: str = \"class_analysis\") -&gt; None</code>","text":"<p>Analyzes class distribution and prediction patterns.</p> <p>Generated Plots - Class distribution in training/test sets - Per-class prediction accuracy - Class imbalance impact analysis - Misclassification patterns between classes</p>"},{"location":"modules/plots/#plot_class_distributiondata_path-unionstr-path-save_name-str-class_distribution-none","title":"<code>plot_class_distribution(data_path: Union[str, Path], save_name: str = \"class_distribution\") -&gt; None</code>","text":"<p>Visualizes class distribution in the dataset.</p> <p>Parameters</p> Name Type Description <code>data_path</code> <code>Union[str, Path]</code> Path to dataset CSV file <code>save_name</code> <code>str</code> Name for saved plot file <p>Generated Plots - Bar chart of class frequencies - Pie chart of class proportions - Class imbalance ratio analysis - Logarithmic scale view for extreme imbalance</p>"},{"location":"modules/plots/#error-analysis","title":"Error Analysis","text":""},{"location":"modules/plots/#plot_error_analysisreports_dir-path-save_name-str-error_analysis-none","title":"<code>plot_error_analysis(reports_dir: Path, save_name: str = \"error_analysis\") -&gt; None</code>","text":"<p>Performs detailed error analysis and misclassification patterns.</p> <p>Generated Plots - Error distribution by class - Confidence vs. accuracy correlation - Feature importance for errors - Temporal error patterns</p>"},{"location":"modules/plots/#plot_confidence_analysispredictions_path-unionstr-path-save_name-str-confidence_analysis-none","title":"<code>plot_confidence_analysis(predictions_path: Union[str, Path], save_name: str = \"confidence_analysis\") -&gt; None</code>","text":"<p>Analyzes model prediction confidence patterns.</p> <p>Parameters</p> Name Type Description <code>predictions_path</code> <code>Union[str, Path]</code> Path to detailed predictions CSV <code>save_name</code> <code>str</code> Name for saved plot file <p>Generated Plots - Confidence distribution by correctness - Confidence vs. accuracy relationship - Low-confidence prediction analysis - Calibration curves</p>"},{"location":"modules/plots/#comparison-and-benchmarking","title":"Comparison and Benchmarking","text":""},{"location":"modules/plots/#plot_model_comparisonresults_dict-dict-save_name-str-model_comparison-none","title":"<code>plot_model_comparison(results_dict: dict, save_name: str = \"model_comparison\") -&gt; None</code>","text":"<p>Compares multiple model results side-by-side.</p> <p>Parameters</p> Name Type Description <code>results_dict</code> <code>dict</code> Dictionary mapping model names to result paths <code>save_name</code> <code>str</code> Name for saved plot file <p>Example <pre><code>model_results = {\n    'DQN_v1': 'reports/dqn_v1/',\n    'DQN_v2': 'reports/dqn_v2/', \n    'DQN_optimized': 'reports/dqn_final/'\n}\n\nplotter.plot_model_comparison(\n    results_dict=model_results,\n    save_name=\"model_versions_comparison\"\n)\n</code></pre></p>"},{"location":"modules/plots/#utility-methods","title":"Utility Methods","text":""},{"location":"modules/plots/#data-loading-and-processing","title":"Data Loading and Processing","text":""},{"location":"modules/plots/#load_evaluation_datareports_dir-path-dict","title":"<code>load_evaluation_data(reports_dir: Path) -&gt; dict</code>","text":"<p>Loads and validates evaluation data from CSV files.</p> <p>Returns - <code>dict</code>: Dictionary containing loaded DataFrames for each report type</p>"},{"location":"modules/plots/#validate_data_formatdf-pddataframe-expected_columns-list-bool","title":"<code>validate_data_format(df: pd.DataFrame, expected_columns: list) -&gt; bool</code>","text":"<p>Validates CSV data format for plotting compatibility.</p>"},{"location":"modules/plots/#plot-styling-and-customization","title":"Plot Styling and Customization","text":""},{"location":"modules/plots/#apply_plot_styleax-pltaxes-title-str-none-none","title":"<code>apply_plot_style(ax: plt.Axes, title: str = None) -&gt; None</code>","text":"<p>Applies consistent styling to matplotlib axes.</p>"},{"location":"modules/plots/#save_plotfig-pltfigure-filename-str-tight_layout-bool-true-path","title":"<code>save_plot(fig: plt.Figure, filename: str, tight_layout: bool = True) -&gt; Path</code>","text":"<p>Saves plots with consistent formatting and metadata.</p>"},{"location":"modules/plots/#command-line-interface","title":"Command Line Interface","text":"<p>Generate plots directly from the command line:</p> <pre><code># Generate all evaluation plots\npython -m rl_ids.plots evaluation-overview --reports-dir ./reports\n\n# Generate training metrics plots\npython -m rl_ids.plots training-metrics --metrics-file ./reports/training_metrics.csv\n\n# Generate class analysis\npython -m rl_ids.plots class-analysis --reports-dir ./reports\n\n# Generate error analysis\npython -m rl_ids.plots error-analysis --reports-dir ./reports\n\n# Custom output directory and DPI\npython -m rl_ids.plots evaluation-overview \\\n    --reports-dir ./reports \\\n    --output-dir ./custom_figures \\\n    --dpi 600\n\n# Generate specific plot types\npython -m rl_ids.plots confusion-matrix \\\n    --matrix-file ./reports/evaluation_confusion_matrix.csv \\\n    --class-names-file ./reports/class_names.txt\n</code></pre>"},{"location":"modules/plots/#cli-commands","title":"CLI Commands","text":"Command Description Options <code>evaluation-overview</code> Generate complete evaluation analysis <code>--reports-dir</code>, <code>--output-dir</code>, <code>--dpi</code> <code>training-metrics</code> Plot training progress <code>--metrics-file</code>, <code>--output-dir</code>, <code>--dpi</code> <code>class-analysis</code> Analyze class distributions <code>--reports-dir</code>, <code>--data-file</code>, <code>--output-dir</code> <code>error-analysis</code> Error pattern analysis <code>--reports-dir</code>, <code>--predictions-file</code>, <code>--output-dir</code> <code>confusion-matrix</code> Enhanced confusion matrix <code>--matrix-file</code>, <code>--class-names-file</code>, <code>--output-dir</code> <code>confidence-analysis</code> Prediction confidence analysis <code>--predictions-file</code>, <code>--output-dir</code>, <code>--dpi</code>"},{"location":"modules/plots/#complete-visualization-workflow","title":"Complete Visualization Workflow","text":""},{"location":"modules/plots/#example-full-report-generation","title":"Example: Full Report Generation","text":"<pre><code>from rl_ids.plots import IDSPlotter\nfrom rl_ids.config import REPORTS_DIR, FIGURES_DIR\nfrom pathlib import Path\n\ndef generate_complete_report():\n    \"\"\"Generate complete visualization report\"\"\"\n\n    # Initialize plotter\n    plotter = IDSPlotter(FIGURES_DIR, dpi=300)\n\n    # 1. Training Analysis\n    if (REPORTS_DIR / \"training_metrics.csv\").exists():\n        plotter.plot_training_metrics(\n            REPORTS_DIR / \"training_metrics.csv\",\n            save_name=\"training_complete\"\n        )\n\n        plotter.plot_episode_analysis(\n            REPORTS_DIR / \"training_metrics.csv\",\n            save_name=\"episode_analysis\"\n        )\n\n    # 2. Evaluation Analysis\n    plotter.plot_evaluation_overview(\n        REPORTS_DIR,\n        save_name=\"evaluation_complete\"\n    )\n\n    # 3. Class Analysis\n    plotter.plot_class_analysis(\n        REPORTS_DIR,\n        save_name=\"class_analysis_detailed\"\n    )\n\n    # 4. Error Analysis\n    plotter.plot_error_analysis(\n        REPORTS_DIR,\n        save_name=\"error_analysis_detailed\"\n    )\n\n    # 5. Confidence Analysis\n    if (REPORTS_DIR / \"evaluation_detailed_predictions.csv\").exists():\n        plotter.plot_confidence_analysis(\n            REPORTS_DIR / \"evaluation_detailed_predictions.csv\",\n            save_name=\"confidence_analysis\"\n        )\n\n    # 6. Generate summary report\n    generate_summary_report(FIGURES_DIR)\n\n    print(f\"Complete report generated in: {FIGURES_DIR}\")\n\ndef generate_summary_report(figures_dir: Path):\n    \"\"\"Generate HTML summary report with all plots\"\"\"\n\n    html_content = \"\"\"\n    &lt;!DOCTYPE html&gt;\n    &lt;html&gt;\n    &lt;head&gt;\n        &lt;title&gt;RL-IDS Model Analysis Report&lt;/title&gt;\n        &lt;style&gt;\n            body { font-family: Arial, sans-serif; margin: 40px; }\n            .plot-section { margin: 30px 0; }\n            .plot-image { max-width: 100%; height: auto; }\n            h1, h2 { color: #2E86AB; }\n        &lt;/style&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;h1&gt;RL-IDS Model Analysis Report&lt;/h1&gt;\n\n        &lt;h2&gt;Training Analysis&lt;/h2&gt;\n        &lt;div class=\"plot-section\"&gt;\n            &lt;img src=\"training_complete.png\" class=\"plot-image\" alt=\"Training Metrics\"&gt;\n        &lt;/div&gt;\n\n        &lt;h2&gt;Evaluation Results&lt;/h2&gt;\n        &lt;div class=\"plot-section\"&gt;\n            &lt;img src=\"evaluation_complete.png\" class=\"plot-image\" alt=\"Evaluation Overview\"&gt;\n        &lt;/div&gt;\n\n        &lt;h2&gt;Class Analysis&lt;/h2&gt;\n        &lt;div class=\"plot-section\"&gt;\n            &lt;img src=\"class_analysis_detailed.png\" class=\"plot-image\" alt=\"Class Analysis\"&gt;\n        &lt;/div&gt;\n\n        &lt;h2&gt;Error Analysis&lt;/h2&gt;\n        &lt;div class=\"plot-section\"&gt;\n            &lt;img src=\"error_analysis_detailed.png\" class=\"plot-image\" alt=\"Error Analysis\"&gt;\n        &lt;/div&gt;\n\n        &lt;h2&gt;Confidence Analysis&lt;/h2&gt;\n        &lt;div class=\"plot-section\"&gt;\n            &lt;img src=\"confidence_analysis.png\" class=\"plot-image\" alt=\"Confidence Analysis\"&gt;\n        &lt;/div&gt;\n    &lt;/body&gt;\n    &lt;/html&gt;\n    \"\"\"\n\n    with open(figures_dir / \"analysis_report.html\", 'w') as f:\n        f.write(html_content)\n\n# Generate complete report\ngenerate_complete_report()\n</code></pre>"},{"location":"modules/plots/#custom-plot-themes","title":"Custom Plot Themes","text":""},{"location":"modules/plots/#theme-configuration","title":"Theme Configuration","text":"<pre><code># Custom color schemes\ncustom_colors = {\n    'corporate': {\n        'primary': '#003f5c',\n        'secondary': '#58508d', \n        'accent': '#bc5090',\n        'warning': '#ff6361',\n        'success': '#ffa600'\n    },\n    'academic': {\n        'primary': '#1f4e79',\n        'secondary': '#2e8b57',\n        'accent': '#d2691e',\n        'warning': '#dc143c',\n        'success': '#228b22'\n    }\n}\n\n# Apply custom theme\nplotter = IDSPlotter(FIGURES_DIR)\nplotter.colors = custom_colors['academic']\n</code></pre>"},{"location":"modules/plots/#advanced-styling","title":"Advanced Styling","text":"<pre><code>def setup_publication_style():\n    \"\"\"Setup matplotlib for publication-quality plots\"\"\"\n\n    plt.rcParams.update({\n        'font.size': 12,\n        'font.family': 'serif',\n        'font.serif': ['Times New Roman'],\n        'figure.dpi': 300,\n        'savefig.dpi': 300,\n        'text.usetex': False,  # Set to True if LaTeX is available\n        'axes.linewidth': 1.5,\n        'axes.spines.top': False,\n        'axes.spines.right': False,\n        'xtick.direction': 'in',\n        'ytick.direction': 'in',\n        'legend.frameon': False\n    })\n\n# Apply before plotting\nsetup_publication_style()\nplotter = IDSPlotter(FIGURES_DIR, dpi=600)\n</code></pre>"},{"location":"modules/plots/#performance-optimization","title":"Performance Optimization","text":""},{"location":"modules/plots/#large-dataset-visualization","title":"Large Dataset Visualization","text":"<pre><code>def plot_large_dataset_sample(data_path: Path, sample_size: int = 10000):\n    \"\"\"Plot visualization for large datasets using sampling\"\"\"\n\n    # Load data in chunks and sample\n    sample_data = pd.read_csv(data_path, nrows=sample_size)\n\n    plotter = IDSPlotter(FIGURES_DIR)\n    plotter.plot_class_distribution(sample_data, save_name=\"sampled_distribution\")\n</code></pre>"},{"location":"modules/plots/#memory-efficient-plotting","title":"Memory-Efficient Plotting","text":"<pre><code>def memory_efficient_plotting(data_path: Path):\n    \"\"\"Generate plots with minimal memory usage\"\"\"\n\n    plotter = IDSPlotter(FIGURES_DIR)\n\n    # Process data in chunks\n    chunk_size = 5000\n    for chunk in pd.read_csv(data_path, chunksize=chunk_size):\n        # Generate incremental plots\n        plotter.plot_chunk_analysis(chunk)\n\n        # Clear matplotlib cache\n        plt.clf()\n        plt.close('all')\n</code></pre>"},{"location":"modules/plots/#troubleshooting","title":"Troubleshooting","text":""},{"location":"modules/plots/#common-issues","title":"Common Issues","text":"<ol> <li> <p>Memory Errors with Large Plots <pre><code># Reduce DPI or use sampling\nplotter = IDSPlotter(FIGURES_DIR, dpi=150)  # Lower DPI\n\n# Or sample large datasets\nlarge_data = pd.read_csv(data_file)\nsample_data = large_data.sample(n=10000, random_state=42)\n</code></pre></p> </li> <li> <p>Missing Font Issues <pre><code># Use basic fonts\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans']\n</code></pre></p> </li> <li> <p>Plot Not Saving <pre><code># Ensure directory exists\nfigures_dir = Path(\"./figures\")\nfigures_dir.mkdir(parents=True, exist_ok=True)\n\n# Check permissions\nimport os\nprint(f\"Directory writable: {os.access(figures_dir, os.W_OK)}\")\n</code></pre></p> </li> <li> <p>Color Palette Issues <pre><code># Reset to default seaborn palette\nimport seaborn as sns\nsns.reset_defaults()\nsns.set_palette(\"husl\")\n</code></pre></p> </li> </ol>"},{"location":"modules/plots/#integration-examples","title":"Integration Examples","text":""},{"location":"modules/plots/#with-training-pipeline","title":"With Training Pipeline","text":"<pre><code>from rl_ids.modeling.train import DQNTrainer\nfrom rl_ids.plots import IDSPlotter\n\nclass VisualizingTrainer(DQNTrainer):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.plotter = IDSPlotter()\n\n    def on_episode_end(self, episode: int, metrics: dict):\n        # Generate plots every 50 episodes\n        if episode % 50 == 0:\n            self.plotter.plot_training_metrics(\n                self.metrics_file,\n                save_name=f\"training_episode_{episode}\"\n            )\n</code></pre>"},{"location":"modules/plots/#with-api-service","title":"With API Service","text":"<pre><code>from fastapi import FastAPI\nfrom rl_ids.plots import IDSPlotter\n\napp = FastAPI()\nplotter = IDSPlotter()\n\n@app.get(\"/api/plots/confusion-matrix\")\nasync def generate_confusion_matrix():\n    \"\"\"Generate and return confusion matrix plot\"\"\"\n\n    plotter.plot_confusion_matrix(\n        confusion_data,\n        save_name=\"api_confusion_matrix\"\n    )\n\n    return {\"plot_url\": \"/figures/api_confusion_matrix.png\"}\n</code></pre>"},{"location":"modules/plots/#see-also","title":"See Also","text":"<ul> <li>Training Module - Generate metrics data for plotting</li> <li>Evaluation Module - Generate evaluation data for analysis</li> <li>Configuration Module - Path configuration for figures</li> <li>Getting Started Guide - Basic plotting workflow</li> </ul>"},{"location":"tutorials/","title":"Tutorials","text":""},{"location":"tutorials/#overview","title":"Overview","text":"<p>This section provides step-by-step tutorials for common tasks with the RL-IDS system, from basic usage to advanced deployment scenarios.</p>"},{"location":"tutorials/#available-tutorials","title":"Available Tutorials","text":""},{"location":"tutorials/#getting-started","title":"Getting Started","text":"<ul> <li>Basic Training Tutorial - Train your first DQN model</li> <li>Data Preparation Guide - Process CICIDS2017 dataset</li> <li>Quick API Usage - Make predictions via REST API</li> </ul>"},{"location":"tutorials/#advanced-topics","title":"Advanced Topics","text":"<ul> <li>Custom Training Pipeline - Advanced training techniques</li> <li>Model Optimization - Hyperparameter tuning and optimization</li> <li>Production Deployment - Deploy API service to production</li> </ul>"},{"location":"tutorials/#integration","title":"Integration","text":"<ul> <li>Real-time Monitoring - Integrate with monitoring systems</li> <li>Custom Environments - Create custom training environments</li> <li>Batch Processing - Process large datasets efficiently</li> </ul>"},{"location":"tutorials/#prerequisites","title":"Prerequisites","text":"<p>Before starting the tutorials, ensure you have:</p> <ol> <li>Python 3.13+ installed</li> <li>CUDA-compatible GPU (recommended for training)</li> <li>RL-IDS repository cloned and set up</li> <li>Dependencies installed via <code>pip install -r requirements.txt</code></li> <li>Raw dataset placed in <code>data/raw/</code> directory</li> </ol>"},{"location":"tutorials/#quick-setup","title":"Quick Setup","text":"<pre><code># Clone and setup\ngit clone &lt;repository-url&gt;\ncd rl_ids\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\npip install -r requirements.txt\npip install -e .\n\n# Prepare data\npython -m rl_ids.make_dataset\n\n# Verify setup\npython -c \"import rl_ids; print('Setup successful!')\"\n</code></pre>"},{"location":"tutorials/#tutorial-structure","title":"Tutorial Structure","text":"<p>Each tutorial follows a consistent structure:</p> <ol> <li>Objective - What you'll learn</li> <li>Prerequisites - Required knowledge/setup</li> <li>Step-by-step Instructions - Detailed walkthrough</li> <li>Code Examples - Working code snippets</li> <li>Expected Output - What to expect</li> <li>Troubleshooting - Common issues and solutions</li> <li>Next Steps - Related tutorials</li> </ol>"},{"location":"tutorials/#support","title":"Support","text":"<p>If you encounter issues while following the tutorials:</p> <ol> <li>Check the FAQ for common solutions</li> <li>Review the API Reference for detailed documentation</li> <li>Examine the Module Reference for implementation details</li> </ol>"},{"location":"tutorials/#contributing","title":"Contributing","text":"<p>Help improve these tutorials by:</p> <ul> <li>Reporting unclear instructions</li> <li>Suggesting additional examples</li> <li>Contributing new tutorial topics</li> <li>Fixing errors or typos</li> </ul>"},{"location":"tutorials/advanced_training/","title":"Advanced Training Tutorial","text":""},{"location":"tutorials/advanced_training/#overview","title":"Overview","text":"<p>This tutorial covers advanced training techniques for the RL-IDS system, including hyperparameter optimization, curriculum learning, transfer learning, and multi-objective training strategies.</p>"},{"location":"tutorials/advanced_training/#prerequisites","title":"Prerequisites","text":"<ul> <li>Completed Getting Started Guide</li> <li>Basic understanding of reinforcement learning concepts</li> <li>Familiarity with the RL-IDS environment and agent</li> </ul>"},{"location":"tutorials/advanced_training/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this tutorial, you will:</p> <ol> <li>Master advanced DQN training techniques</li> <li>Implement curriculum learning for improved convergence</li> <li>Optimize hyperparameters systematically</li> <li>Set up multi-stage training pipelines</li> <li>Monitor and debug training issues</li> </ol>"},{"location":"tutorials/advanced_training/#1-advanced-dqn-configuration","title":"1. Advanced DQN Configuration","text":""},{"location":"tutorials/advanced_training/#custom-agent-configuration","title":"Custom Agent Configuration","text":"<p>Start with a comprehensive DQN configuration:</p> <pre><code>from rl_ids.agents.dqn_agent import DQNConfig, DQNAgent\nfrom rl_ids.environments.ids_env import IDSDetectionEnv\nfrom rl_ids.config import TRAIN_DATA_FILE\n\n# Advanced DQN configuration\nconfig = DQNConfig(\n    state_dim=77,              # Feature dimension\n    action_dim=15,             # Number of attack classes\n\n    # Network architecture\n    hidden_dims=[512, 256, 128, 64],\n    activation='relu',\n    dropout_rate=0.1,\n\n    # Learning parameters\n    learning_rate=1e-4,\n    lr_scheduler='cosine',      # Learning rate scheduling\n    lr_patience=10,\n    lr_factor=0.5,\n\n    # Experience replay\n    memory_size=100000,\n    batch_size=64,\n    min_memory_size=1000,\n\n    # Exploration strategy\n    epsilon_start=1.0,\n    epsilon_end=0.01,\n    epsilon_decay=0.995,\n    epsilon_decay_schedule='exponential',  # 'linear' or 'exponential'\n\n    # Target network updates\n    target_update_frequency=100,\n    soft_target_update=True,\n    tau=0.005,                  # Soft update parameter\n\n    # Advanced features\n    double_dqn=True,\n    dueling_dqn=True,\n    prioritized_replay=True,\n    noisy_networks=False,\n\n    # Training stability\n    gradient_clipping=1.0,\n    reward_scaling=1.0,\n\n    # Device settings\n    device='auto'  # 'cpu', 'cuda', or 'auto'\n)\n\nprint(f\"Configuration: {config}\")\n</code></pre>"},{"location":"tutorials/advanced_training/#environment-configuration","title":"Environment Configuration","text":"<p>Configure the environment with advanced features:</p> <pre><code># Advanced environment setup\nenv = IDSDetectionEnv(\n    data_path=TRAIN_DATA_FILE,\n    feature_cols=None,  # Auto-detect\n\n    # Reward shaping\n    reward_shaping='adaptive',     # 'fixed', 'adaptive', 'curriculum'\n    attack_penalty=-1.0,\n    benign_reward=0.1,\n    correct_reward=1.0,\n    wrong_penalty=-0.5,\n\n    # Episode configuration\n    max_episode_steps=1000,\n    episode_termination='confidence',  # 'fixed', 'confidence', 'adaptive'\n    confidence_threshold=0.95,\n\n    # Data sampling\n    sampling_strategy='balanced',      # 'sequential', 'random', 'balanced'\n    class_weights='auto',\n\n    # Difficulty progression\n    curriculum_mode=True,\n    difficulty_ramp=0.1,\n\n    # Observation space\n    observation_normalization=True,\n    add_noise=False,\n    noise_std=0.01\n)\n\nprint(f\"Environment configured with {env.observation_space.shape[0]} features\")\n</code></pre>"},{"location":"tutorials/advanced_training/#2-curriculum-learning-implementation","title":"2. Curriculum Learning Implementation","text":""},{"location":"tutorials/advanced_training/#progressive-difficulty-training","title":"Progressive Difficulty Training","text":"<p>Implement curriculum learning to improve training stability:</p> <pre><code>import numpy as np\nfrom typing import Dict, List\nfrom loguru import logger\n\nclass CurriculumTrainer:\n    \"\"\"Implements curriculum learning for RL-IDS training\"\"\"\n\n    def __init__(self, agent: DQNAgent, env: IDSDetectionEnv):\n        self.agent = agent\n        self.env = env\n        self.curriculum_stages = []\n        self.current_stage = 0\n        self.stage_episodes = 0\n        self.stage_performance = []\n\n    def define_curriculum(self):\n        \"\"\"Define curriculum stages with increasing difficulty\"\"\"\n\n        self.curriculum_stages = [\n            {\n                'name': 'Basic Binary Classification',\n                'classes': ['BENIGN', 'DDoS'],\n                'episodes': 200,\n                'success_threshold': 0.85,\n                'reward_multiplier': 1.0\n            },\n            {\n                'name': 'Common Attack Types',\n                'classes': ['BENIGN', 'DDoS', 'PortScan', 'Bot'],\n                'episodes': 300,\n                'success_threshold': 0.80,\n                'reward_multiplier': 1.2\n            },\n            {\n                'name': 'Web Attack Classification',\n                'classes': ['BENIGN', 'Web Attack \u2013 Brute Force', \n                           'Web Attack \u2013 XSS', 'Web Attack \u2013 Sql Injection'],\n                'episodes': 250,\n                'success_threshold': 0.75,\n                'reward_multiplier': 1.5\n            },\n            {\n                'name': 'Advanced Infiltration',\n                'classes': ['BENIGN', 'Infiltration', 'Heartbleed'],\n                'episodes': 200,\n                'success_threshold': 0.70,\n                'reward_multiplier': 2.0\n            },\n            {\n                'name': 'Full Multi-class',\n                'classes': 'all',  # All 15 classes\n                'episodes': 500,\n                'success_threshold': 0.65,\n                'reward_multiplier': 1.0\n            }\n        ]\n\n        logger.info(f\"Curriculum defined with {len(self.curriculum_stages)} stages\")\n\n    def setup_stage(self, stage_idx: int):\n        \"\"\"Setup environment for specific curriculum stage\"\"\"\n\n        if stage_idx &gt;= len(self.curriculum_stages):\n            logger.info(\"Curriculum completed!\")\n            return False\n\n        stage = self.curriculum_stages[stage_idx]\n        logger.info(f\"Starting curriculum stage {stage_idx + 1}: {stage['name']}\")\n\n        # Configure environment for this stage\n        if stage['classes'] == 'all':\n            self.env.set_active_classes(None)  # All classes\n        else:\n            self.env.set_active_classes(stage['classes'])\n\n        # Adjust reward scaling\n        self.env.reward_multiplier = stage['reward_multiplier']\n\n        # Reset stage tracking\n        self.stage_episodes = 0\n        self.stage_performance = []\n\n        return True\n\n    def train_stage(self, stage_idx: int) -&gt; bool:\n        \"\"\"Train on a specific curriculum stage\"\"\"\n\n        stage = self.curriculum_stages[stage_idx]\n        target_episodes = stage['episodes']\n        success_threshold = stage['success_threshold']\n\n        stage_metrics = {\n            'episode_rewards': [],\n            'episode_accuracies': [],\n            'stage_losses': []\n        }\n\n        for episode in range(target_episodes):\n            # Standard training episode\n            episode_reward, episode_accuracy, loss = self.train_episode()\n\n            # Track stage metrics\n            stage_metrics['episode_rewards'].append(episode_reward)\n            stage_metrics['episode_accuracies'].append(episode_accuracy)\n            if loss is not None:\n                stage_metrics['stage_losses'].append(loss)\n\n            # Check stage completion criteria\n            if episode &gt;= 50:  # Minimum episodes before evaluation\n                recent_accuracy = np.mean(stage_metrics['episode_accuracies'][-20:])\n\n                if recent_accuracy &gt;= success_threshold:\n                    logger.success(\n                        f\"Stage {stage_idx + 1} completed! \"\n                        f\"Accuracy: {recent_accuracy:.3f} &gt;= {success_threshold:.3f}\"\n                    )\n                    return True\n\n            # Progress logging\n            if episode % 50 == 0:\n                avg_reward = np.mean(stage_metrics['episode_rewards'][-50:])\n                avg_accuracy = np.mean(stage_metrics['episode_accuracies'][-50:])\n                logger.info(\n                    f\"Stage {stage_idx + 1}, Episode {episode}: \"\n                    f\"Avg Reward: {avg_reward:.3f}, Avg Accuracy: {avg_accuracy:.3f}\"\n                )\n\n        # Stage completed by episode limit\n        final_accuracy = np.mean(stage_metrics['episode_accuracies'][-20:])\n        if final_accuracy &gt;= success_threshold:\n            logger.success(\n                f\"Stage {stage_idx + 1} completed by episode limit! \"\n                f\"Final accuracy: {final_accuracy:.3f}\"\n            )\n            return True\n        else:\n            logger.warning(\n                f\"Stage {stage_idx + 1} completed with suboptimal performance: \"\n                f\"{final_accuracy:.3f} &lt; {success_threshold:.3f}\"\n            )\n            return False\n\n    def train_episode(self) -&gt; tuple:\n        \"\"\"Train a single episode and return metrics\"\"\"\n\n        state, _ = self.env.reset()\n        episode_reward = 0\n        episode_steps = 0\n        correct_predictions = 0\n        total_predictions = 0\n        loss = None\n\n        while True:\n            # Agent action\n            action = self.agent.act(state, training=True)\n\n            # Environment step\n            next_state, reward, done, truncated, info = self.env.step(action)\n\n            # Store experience\n            self.agent.remember(state, action, reward, next_state, done)\n\n            # Train agent\n            if len(self.agent.memory) &gt; self.agent.config.batch_size:\n                loss = self.agent.replay()\n\n            # Update metrics\n            episode_reward += reward\n            episode_steps += 1\n\n            # Track accuracy\n            if 'correct' in info:\n                total_predictions += 1\n                if info['correct']:\n                    correct_predictions += 1\n\n            if done or truncated:\n                break\n\n            state = next_state\n\n        # Calculate episode accuracy\n        episode_accuracy = correct_predictions / max(total_predictions, 1)\n\n        return episode_reward, episode_accuracy, loss\n\n    def run_curriculum(self):\n        \"\"\"Execute the complete curriculum training\"\"\"\n\n        self.define_curriculum()\n\n        for stage_idx in range(len(self.curriculum_stages)):\n            if not self.setup_stage(stage_idx):\n                break\n\n            success = self.train_stage(stage_idx)\n\n            # Save stage checkpoint\n            stage_name = self.curriculum_stages[stage_idx]['name'].replace(' ', '_')\n            checkpoint_path = f\"models/dqn_curriculum_stage_{stage_idx + 1}_{stage_name}.pt\"\n            self.agent.save_model(checkpoint_path)\n\n            if not success:\n                logger.warning(f\"Consider extending training for stage {stage_idx + 1}\")\n\n        logger.success(\"Curriculum training completed!\")\n\n# Run curriculum training\ncurriculum_trainer = CurriculumTrainer(agent, env)\ncurriculum_trainer.run_curriculum()\n</code></pre>"},{"location":"tutorials/advanced_training/#3-hyperparameter-optimization","title":"3. Hyperparameter Optimization","text":""},{"location":"tutorials/advanced_training/#automated-hyperparameter-search","title":"Automated Hyperparameter Search","text":"<p>Implement systematic hyperparameter optimization:</p> <pre><code>import itertools\nimport json\nfrom pathlib import Path\nfrom typing import Dict, Any, List, Tuple\n\nclass HyperparameterOptimizer:\n    \"\"\"Systematic hyperparameter optimization for DQN agent\"\"\"\n\n    def __init__(self, base_config: DQNConfig):\n        self.base_config = base_config\n        self.search_space = {}\n        self.results = []\n\n    def define_search_space(self):\n        \"\"\"Define hyperparameter search space\"\"\"\n\n        self.search_space = {\n            'learning_rate': [1e-5, 5e-5, 1e-4, 5e-4, 1e-3],\n            'batch_size': [32, 64, 128, 256],\n            'memory_size': [50000, 100000, 200000],\n            'epsilon_decay': [0.99, 0.995, 0.999],\n            'target_update_frequency': [50, 100, 200],\n            'hidden_dims': [\n                [256, 128],\n                [512, 256, 128],\n                [512, 256, 128, 64],\n                [1024, 512, 256, 128]\n            ],\n            'double_dqn': [True, False],\n            'dueling_dqn': [True, False],\n            'prioritized_replay': [True, False]\n        }\n\n    def grid_search(self, max_combinations: int = 50) -&gt; List[Dict]:\n        \"\"\"Perform grid search over hyperparameter space\"\"\"\n\n        self.define_search_space()\n\n        # Generate all combinations\n        keys = list(self.search_space.keys())\n        values = list(self.search_space.values())\n\n        all_combinations = list(itertools.product(*values))\n\n        # Limit combinations if too many\n        if len(all_combinations) &gt; max_combinations:\n            # Random sampling of combinations\n            import random\n            combinations = random.sample(all_combinations, max_combinations)\n            logger.info(f\"Randomly sampling {max_combinations} from {len(all_combinations)} combinations\")\n        else:\n            combinations = all_combinations\n            logger.info(f\"Testing all {len(combinations)} combinations\")\n\n        results = []\n\n        for i, combination in enumerate(combinations):\n            logger.info(f\"Testing combination {i + 1}/{len(combinations)}\")\n\n            # Create configuration\n            config_dict = dict(zip(keys, combination))\n            config = self.create_config(config_dict)\n\n            # Train and evaluate\n            performance = self.evaluate_configuration(config, trial_episodes=100)\n\n            # Store results\n            result = {\n                'config': config_dict,\n                'performance': performance,\n                'trial': i + 1\n            }\n            results.append(result)\n\n            # Log intermediate result\n            logger.info(\n                f\"Trial {i + 1} - Accuracy: {performance['accuracy']:.3f}, \"\n                f\"Reward: {performance['avg_reward']:.3f}\"\n            )\n\n            # Save intermediate results\n            self.save_results(results, f\"hyperopt_intermediate_{i + 1}.json\")\n\n        # Sort by performance\n        results.sort(key=lambda x: x['performance']['accuracy'], reverse=True)\n\n        # Save final results\n        self.save_results(results, \"hyperopt_final_results.json\")\n\n        return results\n\n    def create_config(self, config_dict: Dict[str, Any]) -&gt; DQNConfig:\n        \"\"\"Create DQNConfig from hyperparameter dictionary\"\"\"\n\n        # Start with base config\n        config = DQNConfig(\n            state_dim=self.base_config.state_dim,\n            action_dim=self.base_config.action_dim\n        )\n\n        # Update with search parameters\n        for key, value in config_dict.items():\n            setattr(config, key, value)\n\n        return config\n\n    def evaluate_configuration(self, config: DQNConfig, trial_episodes: int = 100) -&gt; Dict[str, float]:\n        \"\"\"Evaluate a configuration with limited training\"\"\"\n\n        # Create agent and environment\n        agent = DQNAgent(config)\n        env = IDSDetectionEnv(data_path=TRAIN_DATA_FILE)\n\n        episode_rewards = []\n        episode_accuracies = []\n\n        for episode in range(trial_episodes):\n            state, _ = env.reset()\n            episode_reward = 0\n            correct_predictions = 0\n            total_predictions = 0\n\n            while True:\n                action = agent.act(state, training=True)\n                next_state, reward, done, truncated, info = env.step(action)\n\n                agent.remember(state, action, reward, next_state, done)\n\n                if len(agent.memory) &gt; config.batch_size:\n                    agent.replay()\n\n                episode_reward += reward\n\n                if 'correct' in info:\n                    total_predictions += 1\n                    if info['correct']:\n                        correct_predictions += 1\n\n                if done or truncated:\n                    break\n\n                state = next_state\n\n            episode_accuracy = correct_predictions / max(total_predictions, 1)\n            episode_rewards.append(episode_reward)\n            episode_accuracies.append(episode_accuracy)\n\n        # Calculate performance metrics\n        performance = {\n            'accuracy': np.mean(episode_accuracies),\n            'accuracy_std': np.std(episode_accuracies),\n            'avg_reward': np.mean(episode_rewards),\n            'reward_std': np.std(episode_rewards),\n            'final_epsilon': agent.epsilon,\n            'convergence_episodes': self.detect_convergence(episode_accuracies)\n        }\n\n        return performance\n\n    def detect_convergence(self, accuracies: List[float], window: int = 20) -&gt; int:\n        \"\"\"Detect convergence point in training\"\"\"\n\n        if len(accuracies) &lt; window * 2:\n            return len(accuracies)\n\n        for i in range(window, len(accuracies) - window):\n            early_mean = np.mean(accuracies[i-window:i])\n            late_mean = np.mean(accuracies[i:i+window])\n\n            # Check if improvement is minimal\n            if abs(late_mean - early_mean) &lt; 0.01:\n                return i\n\n        return len(accuracies)\n\n    def save_results(self, results: List[Dict], filename: str):\n        \"\"\"Save optimization results to JSON\"\"\"\n\n        results_path = Path(\"hyperopt_results\") / filename\n        results_path.parent.mkdir(exist_ok=True)\n\n        with open(results_path, 'w') as f:\n            json.dump(results, f, indent=2, default=str)\n\n        logger.info(f\"Results saved to {results_path}\")\n\n    def get_best_configuration(self, results: List[Dict]) -&gt; DQNConfig:\n        \"\"\"Get the best performing configuration\"\"\"\n\n        best_result = max(results, key=lambda x: x['performance']['accuracy'])\n        best_config = self.create_config(best_result['config'])\n\n        logger.success(\n            f\"Best configuration - Accuracy: {best_result['performance']['accuracy']:.3f}\"\n        )\n\n        return best_config\n\n# Run hyperparameter optimization\nbase_config = DQNConfig(state_dim=77, action_dim=15)\noptimizer = HyperparameterOptimizer(base_config)\n\n# Perform optimization\nresults = optimizer.grid_search(max_combinations=30)\n\n# Get best configuration\nbest_config = optimizer.get_best_configuration(results)\n</code></pre>"},{"location":"tutorials/advanced_training/#4-multi-objective-training","title":"4. Multi-Objective Training","text":""},{"location":"tutorials/advanced_training/#balancing-multiple-objectives","title":"Balancing Multiple Objectives","text":"<p>Implement multi-objective training for improved performance:</p> <pre><code>from typing import Dict, List, Tuple\nimport numpy as np\n\nclass MultiObjectiveTrainer:\n    \"\"\"Multi-objective training for RL-IDS with balanced performance\"\"\"\n\n    def __init__(self, agent: DQNAgent, env: IDSDetectionEnv):\n        self.agent = agent\n        self.env = env\n        self.objectives = {}\n        self.objective_weights = {}\n        self.performance_history = []\n\n    def define_objectives(self):\n        \"\"\"Define training objectives and their weights\"\"\"\n\n        self.objectives = {\n            'accuracy': {\n                'description': 'Overall classification accuracy',\n                'target': 0.90,\n                'weight': 0.4,\n                'maximize': True\n            },\n            'precision': {\n                'description': 'Precision for attack detection',\n                'target': 0.85,\n                'weight': 0.3,\n                'maximize': True\n            },\n            'recall': {\n                'description': 'Recall for attack detection',\n                'target': 0.85,\n                'weight': 0.2,\n                'maximize': True\n            },\n            'false_positive_rate': {\n                'description': 'False positive rate for benign traffic',\n                'target': 0.05,\n                'weight': 0.1,\n                'maximize': False\n            }\n        }\n\n        logger.info(f\"Defined {len(self.objectives)} training objectives\")\n\n    def compute_multi_objective_reward(self, metrics: Dict[str, float]) -&gt; float:\n        \"\"\"Compute combined reward from multiple objectives\"\"\"\n\n        total_reward = 0.0\n        objective_rewards = {}\n\n        for obj_name, obj_config in self.objectives.items():\n            if obj_name in metrics:\n                value = metrics[obj_name]\n                target = obj_config['target']\n                weight = obj_config['weight']\n                maximize = obj_config['maximize']\n\n                # Compute objective-specific reward\n                if maximize:\n                    # Reward for exceeding target\n                    obj_reward = max(0, (value - target) / target)\n                else:\n                    # Penalty for exceeding target (for metrics like FPR)\n                    obj_reward = max(0, (target - value) / target)\n\n                weighted_reward = obj_reward * weight\n                objective_rewards[obj_name] = weighted_reward\n                total_reward += weighted_reward\n\n        return total_reward, objective_rewards\n\n    def train_episode_multi_objective(self) -&gt; Dict[str, float]:\n        \"\"\"Train episode with multi-objective evaluation\"\"\"\n\n        state, _ = self.env.reset()\n        episode_metrics = {\n            'reward': 0,\n            'steps': 0,\n            'correct_predictions': 0,\n            'total_predictions': 0,\n            'true_positives': 0,\n            'false_positives': 0,\n            'true_negatives': 0,\n            'false_negatives': 0\n        }\n\n        while True:\n            action = self.agent.act(state, training=True)\n            next_state, reward, done, truncated, info = self.env.step(action)\n\n            # Standard RL update\n            self.agent.remember(state, action, reward, next_state, done)\n\n            if len(self.agent.memory) &gt; self.agent.config.batch_size:\n                self.agent.replay()\n\n            # Collect detailed metrics\n            episode_metrics['reward'] += reward\n            episode_metrics['steps'] += 1\n\n            if 'true_label' in info and 'predicted_label' in info:\n                true_label = info['true_label']\n                pred_label = info['predicted_label']\n\n                episode_metrics['total_predictions'] += 1\n\n                # Binary classification metrics (attack vs benign)\n                is_attack_true = true_label != 0  # Assuming 0 is benign\n                is_attack_pred = pred_label != 0\n\n                if is_attack_true and is_attack_pred:\n                    episode_metrics['true_positives'] += 1\n                    episode_metrics['correct_predictions'] += 1\n                elif not is_attack_true and not is_attack_pred:\n                    episode_metrics['true_negatives'] += 1\n                    episode_metrics['correct_predictions'] += 1\n                elif not is_attack_true and is_attack_pred:\n                    episode_metrics['false_positives'] += 1\n                else:  # is_attack_true and not is_attack_pred\n                    episode_metrics['false_negatives'] += 1\n\n            if done or truncated:\n                break\n\n            state = next_state\n\n        # Compute derived metrics\n        tp = episode_metrics['true_positives']\n        fp = episode_metrics['false_positives']\n        tn = episode_metrics['true_negatives']\n        fn = episode_metrics['false_negatives']\n\n        # Calculate objective metrics\n        accuracy = episode_metrics['correct_predictions'] / max(episode_metrics['total_predictions'], 1)\n        precision = tp / max(tp + fp, 1)\n        recall = tp / max(tp + fn, 1)\n        fpr = fp / max(fp + tn, 1)\n\n        performance_metrics = {\n            'accuracy': accuracy,\n            'precision': precision,\n            'recall': recall,\n            'false_positive_rate': fpr,\n            'episode_reward': episode_metrics['reward'],\n            'episode_steps': episode_metrics['steps']\n        }\n\n        # Compute multi-objective reward\n        mo_reward, obj_rewards = self.compute_multi_objective_reward(performance_metrics)\n        performance_metrics['multi_objective_reward'] = mo_reward\n        performance_metrics['objective_rewards'] = obj_rewards\n\n        return performance_metrics\n\n    def train_multi_objective(self, episodes: int = 1000):\n        \"\"\"Main multi-objective training loop\"\"\"\n\n        self.define_objectives()\n        episode_history = []\n\n        for episode in range(episodes):\n            # Train episode\n            metrics = self.train_episode_multi_objective()\n            episode_history.append(metrics)\n\n            # Adaptive objective weighting\n            if episode &gt; 50 and episode % 100 == 0:\n                self.adapt_objective_weights(episode_history[-100:])\n\n            # Progress logging\n            if episode % 50 == 0:\n                recent_metrics = episode_history[-50:] if len(episode_history) &gt;= 50 else episode_history\n                avg_metrics = self.compute_average_metrics(recent_metrics)\n\n                logger.info(\n                    f\"Episode {episode}: \"\n                    f\"Acc: {avg_metrics['accuracy']:.3f}, \"\n                    f\"Prec: {avg_metrics['precision']:.3f}, \"\n                    f\"Rec: {avg_metrics['recall']:.3f}, \"\n                    f\"FPR: {avg_metrics['false_positive_rate']:.3f}, \"\n                    f\"MO Reward: {avg_metrics['multi_objective_reward']:.3f}\"\n                )\n\n        self.performance_history = episode_history\n        return episode_history\n\n    def adapt_objective_weights(self, recent_history: List[Dict[str, float]]):\n        \"\"\"Adaptively adjust objective weights based on performance\"\"\"\n\n        avg_metrics = self.compute_average_metrics(recent_history)\n\n        for obj_name, obj_config in self.objectives.items():\n            if obj_name in avg_metrics:\n                current_value = avg_metrics[obj_name]\n                target_value = obj_config['target']\n                current_weight = obj_config['weight']\n\n                # Increase weight for underperforming objectives\n                if obj_config['maximize']:\n                    if current_value &lt; target_value * 0.9:  # Performing below 90% of target\n                        obj_config['weight'] = min(current_weight * 1.1, 0.5)\n                else:\n                    if current_value &gt; target_value * 1.1:  # Performing above 110% of target\n                        obj_config['weight'] = min(current_weight * 1.1, 0.5)\n\n        # Normalize weights\n        total_weight = sum(obj['weight'] for obj in self.objectives.values())\n        for obj_config in self.objectives.values():\n            obj_config['weight'] /= total_weight\n\n        logger.debug(f\"Updated objective weights: {[(k, v['weight']) for k, v in self.objectives.items()]}\")\n\n    def compute_average_metrics(self, history: List[Dict[str, float]]) -&gt; Dict[str, float]:\n        \"\"\"Compute average metrics over episode history\"\"\"\n\n        if not history:\n            return {}\n\n        metrics = {}\n        for key in history[0].keys():\n            if key != 'objective_rewards' and isinstance(history[0][key], (int, float)):\n                metrics[key] = np.mean([episode[key] for episode in history])\n\n        return metrics\n\n# Run multi-objective training\nmo_trainer = MultiObjectiveTrainer(agent, env)\ntraining_history = mo_trainer.train_multi_objective(episodes=1000)\n</code></pre>"},{"location":"tutorials/advanced_training/#5-advanced-monitoring-and-debugging","title":"5. Advanced Monitoring and Debugging","text":""},{"location":"tutorials/advanced_training/#comprehensive-training-monitoring","title":"Comprehensive Training Monitoring","text":"<p>Set up advanced monitoring for training diagnostics:</p> <pre><code>import wandb\nfrom tensorboard import program\nimport matplotlib.pyplot as plt\nfrom typing import Dict, Any\n\nclass AdvancedTrainingMonitor:\n    \"\"\"Comprehensive training monitoring with multiple backends\"\"\"\n\n    def __init__(self, project_name: str = \"rl-ids-advanced\"):\n        self.project_name = project_name\n        self.metrics_history = []\n        self.setup_monitoring()\n\n    def setup_monitoring(self):\n        \"\"\"Setup monitoring backends\"\"\"\n\n        # Weights &amp; Biases setup\n        try:\n            wandb.init(project=self.project_name, reinit=True)\n            self.use_wandb = True\n            logger.info(\"W&amp;B monitoring enabled\")\n        except Exception as e:\n            logger.warning(f\"W&amp;B setup failed: {e}\")\n            self.use_wandb = False\n\n        # TensorBoard setup\n        try:\n            from torch.utils.tensorboard import SummaryWriter\n            self.tb_writer = SummaryWriter(log_dir=f\"runs/{self.project_name}\")\n            self.use_tensorboard = True\n            logger.info(\"TensorBoard monitoring enabled\")\n        except Exception as e:\n            logger.warning(f\"TensorBoard setup failed: {e}\")\n            self.use_tensorboard = False\n\n    def log_training_step(self, episode: int, metrics: Dict[str, Any]):\n        \"\"\"Log training metrics to all monitoring backends\"\"\"\n\n        # Store locally\n        metrics['episode'] = episode\n        self.metrics_history.append(metrics.copy())\n\n        # W&amp;B logging\n        if self.use_wandb:\n            try:\n                wandb.log(metrics, step=episode)\n            except Exception as e:\n                logger.warning(f\"W&amp;B logging failed: {e}\")\n\n        # TensorBoard logging\n        if self.use_tensorboard:\n            try:\n                for key, value in metrics.items():\n                    if isinstance(value, (int, float)):\n                        self.tb_writer.add_scalar(key, value, episode)\n            except Exception as e:\n                logger.warning(f\"TensorBoard logging failed: {e}\")\n\n    def log_network_analysis(self, agent: DQNAgent, episode: int):\n        \"\"\"Log detailed network analysis\"\"\"\n\n        # Gradient analysis\n        total_norm = 0\n        param_count = 0\n        for param in agent.model.parameters():\n            if param.grad is not None:\n                param_norm = param.grad.data.norm(2)\n                total_norm += param_norm.item() ** 2\n                param_count += param.numel()\n\n        total_norm = total_norm ** (1. / 2)\n\n        # Weight analysis\n        weight_stats = {}\n        for name, param in agent.model.named_parameters():\n            weight_stats[f'weight_mean_{name}'] = param.data.mean().item()\n            weight_stats[f'weight_std_{name}'] = param.data.std().item()\n            weight_stats[f'weight_norm_{name}'] = param.data.norm().item()\n\n        # Q-value analysis\n        if hasattr(agent, 'last_q_values') and agent.last_q_values is not None:\n            q_values = agent.last_q_values.detach().cpu().numpy()\n            q_stats = {\n                'q_values_mean': np.mean(q_values),\n                'q_values_std': np.std(q_values),\n                'q_values_max': np.max(q_values),\n                'q_values_min': np.min(q_values)\n            }\n        else:\n            q_stats = {}\n\n        analysis_metrics = {\n            'gradient_norm': total_norm,\n            'parameter_count': param_count,\n            'learning_rate': agent.optimizer.param_groups[0]['lr'],\n            'epsilon': agent.epsilon,\n            **weight_stats,\n            **q_stats\n        }\n\n        self.log_training_step(episode, analysis_metrics)\n\n    def log_hyperparameters(self, config: DQNConfig):\n        \"\"\"Log hyperparameters for experiment tracking\"\"\"\n\n        config_dict = {\n            'learning_rate': config.learning_rate,\n            'batch_size': config.batch_size,\n            'memory_size': config.memory_size,\n            'epsilon_decay': config.epsilon_decay,\n            'target_update_frequency': config.target_update_frequency,\n            'hidden_dims': str(config.hidden_dims),\n            'double_dqn': config.double_dqn,\n            'dueling_dqn': config.dueling_dqn,\n            'prioritized_replay': config.prioritized_replay\n        }\n\n        if self.use_wandb:\n            wandb.config.update(config_dict)\n\n        logger.info(f\"Logged hyperparameters: {config_dict}\")\n\n    def generate_training_report(self, save_path: str = \"training_report.html\"):\n        \"\"\"Generate comprehensive training report\"\"\"\n\n        if not self.metrics_history:\n            logger.warning(\"No metrics history available for report\")\n            return\n\n        df = pd.DataFrame(self.metrics_history)\n\n        # Create comprehensive plots\n        fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n        fig.suptitle('Advanced Training Analysis Report', fontsize=16)\n\n        # Accuracy trend\n        if 'accuracy' in df.columns:\n            axes[0, 0].plot(df['episode'], df['accuracy'])\n            axes[0, 0].set_title('Training Accuracy')\n            axes[0, 0].set_xlabel('Episode')\n            axes[0, 0].set_ylabel('Accuracy')\n\n        # Reward trend\n        if 'episode_reward' in df.columns:\n            axes[0, 1].plot(df['episode'], df['episode_reward'])\n            axes[0, 1].set_title('Episode Reward')\n            axes[0, 1].set_xlabel('Episode')\n            axes[0, 1].set_ylabel('Reward')\n\n        # Loss trend\n        if 'loss' in df.columns:\n            axes[1, 0].plot(df['episode'], df['loss'])\n            axes[1, 0].set_title('Training Loss')\n            axes[1, 0].set_xlabel('Episode')\n            axes[1, 0].set_ylabel('Loss')\n\n        # Epsilon decay\n        if 'epsilon' in df.columns:\n            axes[1, 1].plot(df['episode'], df['epsilon'])\n            axes[1, 1].set_title('Epsilon Decay')\n            axes[1, 1].set_xlabel('Episode')\n            axes[1, 1].set_ylabel('Epsilon')\n\n        # Gradient norm\n        if 'gradient_norm' in df.columns:\n            axes[2, 0].plot(df['episode'], df['gradient_norm'])\n            axes[2, 0].set_title('Gradient Norm')\n            axes[2, 0].set_xlabel('Episode')\n            axes[2, 0].set_ylabel('Gradient Norm')\n\n        # Learning rate\n        if 'learning_rate' in df.columns:\n            axes[2, 1].plot(df['episode'], df['learning_rate'])\n            axes[2, 1].set_title('Learning Rate')\n            axes[2, 1].set_xlabel('Episode')\n            axes[2, 1].set_ylabel('Learning Rate')\n\n        plt.tight_layout()\n        plt.savefig(save_path.replace('.html', '.png'), dpi=300, bbox_inches='tight')\n        plt.close()\n\n        # Generate HTML report\n        html_content = f\"\"\"\n        &lt;!DOCTYPE html&gt;\n        &lt;html&gt;\n        &lt;head&gt;\n            &lt;title&gt;RL-IDS Advanced Training Report&lt;/title&gt;\n            &lt;style&gt;\n                body {{ font-family: Arial, sans-serif; margin: 40px; }}\n                .metric {{ margin: 20px 0; }}\n                .plot {{ text-align: center; margin: 30px 0; }}\n                h1, h2 {{ color: #2E86AB; }}\n                table {{ border-collapse: collapse; width: 100%; }}\n                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n                th {{ background-color: #f2f2f2; }}\n            &lt;/style&gt;\n        &lt;/head&gt;\n        &lt;body&gt;\n            &lt;h1&gt;RL-IDS Advanced Training Report&lt;/h1&gt;\n\n            &lt;h2&gt;Training Summary&lt;/h2&gt;\n            &lt;table&gt;\n                &lt;tr&gt;&lt;th&gt;Metric&lt;/th&gt;&lt;th&gt;Final Value&lt;/th&gt;&lt;th&gt;Best Value&lt;/th&gt;&lt;th&gt;Mean Value&lt;/th&gt;&lt;/tr&gt;\n                &lt;tr&gt;&lt;td&gt;Accuracy&lt;/td&gt;&lt;td&gt;{df['accuracy'].iloc[-1]:.4f}&lt;/td&gt;&lt;td&gt;{df['accuracy'].max():.4f}&lt;/td&gt;&lt;td&gt;{df['accuracy'].mean():.4f}&lt;/td&gt;&lt;/tr&gt;\n                &lt;tr&gt;&lt;td&gt;Reward&lt;/td&gt;&lt;td&gt;{df['episode_reward'].iloc[-1]:.2f}&lt;/td&gt;&lt;td&gt;{df['episode_reward'].max():.2f}&lt;/td&gt;&lt;td&gt;{df['episode_reward'].mean():.2f}&lt;/td&gt;&lt;/tr&gt;\n                &lt;tr&gt;&lt;td&gt;Episodes&lt;/td&gt;&lt;td&gt;{len(df)}&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;/tr&gt;\n            &lt;/table&gt;\n\n            &lt;div class=\"plot\"&gt;\n                &lt;img src=\"{save_path.replace('.html', '.png')}\" alt=\"Training Analysis Plots\" style=\"max-width: 100%;\"&gt;\n            &lt;/div&gt;\n\n            &lt;h2&gt;Performance Analysis&lt;/h2&gt;\n            &lt;p&gt;The training completed {len(df)} episodes with final accuracy of {df['accuracy'].iloc[-1]:.4f}.&lt;/p&gt;\n            &lt;p&gt;Best performance achieved: {df['accuracy'].max():.4f} accuracy at episode {df.loc[df['accuracy'].idxmax(), 'episode']}.&lt;/p&gt;\n\n        &lt;/body&gt;\n        &lt;/html&gt;\n        \"\"\"\n\n        with open(save_path, 'w') as f:\n            f.write(html_content)\n\n        logger.success(f\"Training report generated: {save_path}\")\n\n# Setup advanced monitoring\nmonitor = AdvancedTrainingMonitor(\"rl-ids-advanced-training\")\nmonitor.log_hyperparameters(config)\n\n# Enhanced training loop with monitoring\nfor episode in range(1000):\n    # Train episode\n    metrics = train_episode()  # Your training function\n\n    # Log basic metrics\n    monitor.log_training_step(episode, metrics)\n\n    # Detailed network analysis every 10 episodes\n    if episode % 10 == 0:\n        monitor.log_network_analysis(agent, episode)\n\n    # Generate intermediate reports\n    if episode % 200 == 0 and episode &gt; 0:\n        monitor.generate_training_report(f\"training_report_episode_{episode}.html\")\n\n# Final report\nmonitor.generate_training_report(\"final_training_report.html\")\n</code></pre>"},{"location":"tutorials/advanced_training/#6-next-steps","title":"6. Next Steps","text":"<p>After completing this advanced training tutorial:</p> <ol> <li>Experiment with different curriculum strategies</li> <li>Implement custom reward shaping techniques</li> <li>Explore ensemble methods and model averaging</li> <li>Set up automated hyperparameter optimization pipelines</li> <li>Deploy trained models to production environments</li> </ol>"},{"location":"tutorials/advanced_training/#see-also","title":"See Also","text":"<ul> <li>Model Evaluation Tutorial - Comprehensive model evaluation</li> <li>API Deployment Tutorial - Production deployment strategies</li> <li>Custom Environment Tutorial - Creating custom training environments</li> <li>Performance Optimization Guide - Advanced performance tuning</li> </ul>"},{"location":"tutorials/api_usage/","title":"API Usage Tutorial","text":""},{"location":"tutorials/api_usage/#overview","title":"Overview","text":"<p>This comprehensive tutorial covers advanced usage patterns for the RL-IDS FastAPI service, including authentication, batch processing, monitoring, integration patterns, and production deployment strategies.</p>"},{"location":"tutorials/api_usage/#prerequisites","title":"Prerequisites","text":"<ul> <li>Completed Getting Started Guide</li> <li>Trained RL-IDS model available</li> <li>Basic understanding of REST APIs and HTTP</li> </ul>"},{"location":"tutorials/api_usage/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this tutorial, you will:</p> <ol> <li>Master all API endpoints and their advanced features</li> <li>Implement efficient batch processing workflows</li> <li>Set up comprehensive monitoring and alerting</li> <li>Integrate the API with various systems and frameworks</li> <li>Deploy and scale the API in production environments</li> </ol>"},{"location":"tutorials/api_usage/#1-api-service-setup-and-configuration","title":"1. API Service Setup and Configuration","text":""},{"location":"tutorials/api_usage/#advanced-configuration","title":"Advanced Configuration","text":"<p>Start with a comprehensive API configuration:</p> <pre><code>from api.config import APISettings\nfrom pathlib import Path\nimport os\n\n# Advanced API configuration\nsettings = APISettings(\n    # Basic settings\n    app_name=\"RL-IDS Production API\",\n    app_version=\"2.0.0\",\n    debug=False,\n\n    # Server configuration\n    host=\"0.0.0.0\",\n    port=8000,\n    workers=4,  # Scale based on CPU cores\n\n    # Model settings\n    model_path=Path(\"models/dqn_model_best.pt\"),\n    model_backup_path=Path(\"models/dqn_model_backup.pt\"),\n\n    # Performance optimization\n    max_batch_size=500,\n    prediction_timeout=30.0,\n    enable_model_caching=True,\n    cache_size=1000,\n\n    # Monitoring\n    log_level=\"INFO\",\n    enable_metrics=True,\n    metrics_port=9090,\n\n    # Security\n    enable_cors=True,\n    cors_origins=[\"https://your-frontend.com\"],\n    cors_methods=[\"GET\", \"POST\"],\n\n    # Rate limiting\n    rate_limit_enabled=True,\n    rate_limit_requests_per_minute=1000,\n    rate_limit_burst=50,\n\n    # Health checks\n    health_check_interval=30,\n    model_health_check=True\n)\n\nprint(f\"API Configuration: {settings}\")\n</code></pre>"},{"location":"tutorials/api_usage/#environment-specific-configuration","title":"Environment-Specific Configuration","text":"<p>Set up different configurations for different environments:</p> <pre><code># .env.development\nRLIDS_API_DEBUG=true\nRLIDS_API_LOG_LEVEL=DEBUG\nRLIDS_API_WORKERS=1\nRLIDS_API_RATE_LIMIT_ENABLED=false\n\n# .env.production\nRLIDS_API_DEBUG=false\nRLIDS_API_LOG_LEVEL=INFO\nRLIDS_API_WORKERS=8\nRLIDS_API_RATE_LIMIT_ENABLED=true\nRLIDS_API_MAX_BATCH_SIZE=1000\nRLIDS_API_CORS_ORIGINS=[\"https://production-app.com\"]\n\n# .env.testing\nRLIDS_API_DEBUG=true\nRLIDS_API_LOG_LEVEL=DEBUG\nRLIDS_API_WORKERS=1\nRLIDS_API_MODEL_PATH=/tmp/test_model.pt\n</code></pre>"},{"location":"tutorials/api_usage/#starting-the-api-service","title":"Starting the API Service","text":"<pre><code># Development mode with auto-reload\npython run_api.py --reload --log-level debug\n\n# Production mode with multiple workers\npython run_api.py --host 0.0.0.0 --port 8000 --workers 4\n\n# Using Gunicorn for production\ngunicorn api.main:app \\\n    --bind 0.0.0.0:8000 \\\n    --workers 4 \\\n    --worker-class uvicorn.workers.UvicornWorker \\\n    --access-logfile - \\\n    --error-logfile - \\\n    --log-level info\n\n# Docker deployment\ndocker run -p 8000:8000 \\\n    -v $(pwd)/models:/app/models \\\n    -e RLIDS_API_WORKERS=4 \\\n    rl-ids-api:latest\n</code></pre>"},{"location":"tutorials/api_usage/#2-comprehensive-api-client-usage","title":"2. Comprehensive API Client Usage","text":""},{"location":"tutorials/api_usage/#advanced-python-client","title":"Advanced Python Client","text":"<p>Create a robust Python client with advanced features:</p> <pre><code>import asyncio\nimport aiohttp\nimport json\nimport time\nfrom typing import List, Dict, Optional, Union\nfrom dataclasses import dataclass\nfrom loguru import logger\nimport numpy as np\nimport pandas as pd\n\n@dataclass\nclass PredictionResult:\n    \"\"\"Structured prediction result\"\"\"\n    predicted_class: int\n    predicted_class_name: str\n    confidence: float\n    is_attack: bool\n    processing_time_ms: float\n    model_version: str\n    raw_probabilities: List[float]\n\nclass AdvancedIDSAPIClient:\n    \"\"\"Advanced API client with connection pooling, retries, and monitoring\"\"\"\n\n    def __init__(self, base_url: str = \"http://localhost:8000\", \n                 timeout: int = 30, max_retries: int = 3):\n        self.base_url = base_url.rstrip('/')\n        self.timeout = timeout\n        self.max_retries = max_retries\n        self.session = None\n        self.request_stats = {\n            'total_requests': 0,\n            'successful_requests': 0,\n            'failed_requests': 0,\n            'total_response_time': 0.0\n        }\n\n    async def __aenter__(self):\n        \"\"\"Async context manager entry\"\"\"\n        connector = aiohttp.TCPConnector(\n            limit=100,  # Connection pool size\n            limit_per_host=30,\n            keepalive_timeout=30,\n            enable_cleanup_closed=True\n        )\n\n        timeout = aiohttp.ClientTimeout(total=self.timeout)\n\n        self.session = aiohttp.ClientSession(\n            connector=connector,\n            timeout=timeout,\n            headers={'User-Agent': 'RL-IDS Advanced Client v2.0'}\n        )\n\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Async context manager exit\"\"\"\n        if self.session:\n            await self.session.close()\n\n    async def _make_request(self, method: str, endpoint: str, \n                           json_data: Dict = None, retry_count: int = 0) -&gt; Dict:\n        \"\"\"Make HTTP request with retry logic\"\"\"\n\n        url = f\"{self.base_url}{endpoint}\"\n        start_time = time.time()\n\n        try:\n            self.request_stats['total_requests'] += 1\n\n            async with self.session.request(method, url, json=json_data) as response:\n                response_time = (time.time() - start_time) * 1000\n                self.request_stats['total_response_time'] += response_time\n\n                if response.status == 200:\n                    self.request_stats['successful_requests'] += 1\n                    return await response.json()\n                elif response.status == 429:  # Rate limited\n                    if retry_count &lt; self.max_retries:\n                        wait_time = 2 ** retry_count  # Exponential backoff\n                        logger.warning(f\"Rate limited, waiting {wait_time}s before retry\")\n                        await asyncio.sleep(wait_time)\n                        return await self._make_request(method, endpoint, json_data, retry_count + 1)\n                else:\n                    error_text = await response.text()\n                    raise aiohttp.ClientError(f\"HTTP {response.status}: {error_text}\")\n\n        except asyncio.TimeoutError:\n            if retry_count &lt; self.max_retries:\n                logger.warning(f\"Request timeout, retrying... ({retry_count + 1}/{self.max_retries})\")\n                return await self._make_request(method, endpoint, json_data, retry_count + 1)\n            else:\n                self.request_stats['failed_requests'] += 1\n                raise\n        except Exception as e:\n            self.request_stats['failed_requests'] += 1\n            if retry_count &lt; self.max_retries:\n                logger.warning(f\"Request failed: {e}, retrying... ({retry_count + 1}/{self.max_retries})\")\n                await asyncio.sleep(1)\n                return await self._make_request(method, endpoint, json_data, retry_count + 1)\n            else:\n                raise\n\n    async def health_check(self) -&gt; Dict:\n        \"\"\"Comprehensive health check\"\"\"\n        return await self._make_request('GET', '/health')\n\n    async def get_model_info(self) -&gt; Dict:\n        \"\"\"Get detailed model information\"\"\"\n        return await self._make_request('GET', '/model/info')\n\n    async def predict_single(self, features: List[float]) -&gt; PredictionResult:\n        \"\"\"Single prediction with structured result\"\"\"\n\n        response = await self._make_request('POST', '/predict', \n                                          {'features': features})\n\n        return PredictionResult(\n            predicted_class=response['predicted_class'],\n            predicted_class_name=response['predicted_class_name'],\n            confidence=response['confidence'],\n            is_attack=response['is_attack'],\n            processing_time_ms=response['processing_time_ms'],\n            model_version=response['model_version'],\n            raw_probabilities=response.get('probabilities', [])\n        )\n\n    async def predict_batch(self, features_list: List[List[float]], \n                           batch_size: int = 100) -&gt; List[PredictionResult]:\n        \"\"\"Efficient batch prediction with chunking\"\"\"\n\n        all_results = []\n\n        # Process in chunks to respect API limits\n        for i in range(0, len(features_list), batch_size):\n            chunk = features_list[i:i + batch_size]\n            chunk_requests = [{'features': features} for features in chunk]\n\n            response = await self._make_request('POST', '/predict/batch', \n                                              chunk_requests)\n\n            # Convert to structured results\n            chunk_results = [\n                PredictionResult(\n                    predicted_class=pred['predicted_class'],\n                    predicted_class_name=pred['predicted_class_name'],\n                    confidence=pred['confidence'],\n                    is_attack=pred['is_attack'],\n                    processing_time_ms=pred['processing_time_ms'],\n                    model_version=pred['model_version'],\n                    raw_probabilities=pred.get('probabilities', [])\n                )\n                for pred in response\n            ]\n\n            all_results.extend(chunk_results)\n\n            # Progress logging\n            logger.info(f\"Processed batch {i//batch_size + 1}, \"\n                       f\"total predictions: {len(all_results)}\")\n\n        return all_results\n\n    async def predict_dataframe(self, df: pd.DataFrame, \n                               feature_columns: List[str] = None,\n                               batch_size: int = 100) -&gt; pd.DataFrame:\n        \"\"\"Predict on pandas DataFrame with results integration\"\"\"\n\n        if feature_columns is None:\n            # Assume all numeric columns except labels\n            feature_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n            feature_columns = [col for col in feature_columns \n                             if not col.lower().startswith('label')]\n\n        # Extract features\n        features_list = df[feature_columns].values.tolist()\n\n        # Get predictions\n        predictions = await self.predict_batch(features_list, batch_size)\n\n        # Add results to DataFrame\n        result_df = df.copy()\n        result_df['predicted_class'] = [p.predicted_class for p in predictions]\n        result_df['predicted_class_name'] = [p.predicted_class_name for p in predictions]\n        result_df['confidence'] = [p.confidence for p in predictions]\n        result_df['is_attack'] = [p.is_attack for p in predictions]\n        result_df['processing_time_ms'] = [p.processing_time_ms for p in predictions]\n\n        return result_df\n\n    async def stream_predictions(self, features_stream, \n                                prediction_callback=None) -&gt; None:\n        \"\"\"Stream predictions for real-time processing\"\"\"\n\n        async for features in features_stream:\n            try:\n                prediction = await self.predict_single(features)\n\n                if prediction_callback:\n                    await prediction_callback(features, prediction)\n                else:\n                    logger.info(f\"Prediction: {prediction.predicted_class_name} \"\n                               f\"(confidence: {prediction.confidence:.3f})\")\n\n            except Exception as e:\n                logger.error(f\"Stream prediction error: {e}\")\n\n    def get_stats(self) -&gt; Dict:\n        \"\"\"Get client performance statistics\"\"\"\n\n        stats = self.request_stats.copy()\n\n        if stats['total_requests'] &gt; 0:\n            stats['success_rate'] = stats['successful_requests'] / stats['total_requests']\n            stats['average_response_time_ms'] = stats['total_response_time'] / stats['total_requests']\n        else:\n            stats['success_rate'] = 0.0\n            stats['average_response_time_ms'] = 0.0\n\n        return stats\n\n# Example usage\nasync def advanced_client_example():\n    \"\"\"Comprehensive client usage example\"\"\"\n\n    async with AdvancedIDSAPIClient(\"http://localhost:8000\") as client:\n        # Health check\n        health = await client.health_check()\n        logger.info(f\"Service health: {health['status']}\")\n\n        # Model info\n        model_info = await client.get_model_info()\n        logger.info(f\"Model: {model_info['model_name']} v{model_info['model_version']}\")\n\n        # Single prediction\n        features = [0.1] * 77  # Example features\n        prediction = await client.predict_single(features)\n        logger.info(f\"Single prediction: {prediction}\")\n\n        # Batch prediction\n        batch_features = [[0.1] * 77 for _ in range(100)]\n        batch_predictions = await client.predict_batch(batch_features, batch_size=50)\n        logger.info(f\"Batch predictions completed: {len(batch_predictions)} samples\")\n\n        # DataFrame prediction\n        df = pd.DataFrame(np.random.rand(200, 77))\n        result_df = await client.predict_dataframe(df)\n        logger.info(f\"DataFrame prediction completed: {len(result_df)} rows\")\n\n        # Performance stats\n        stats = client.get_stats()\n        logger.info(f\"Client stats: {stats}\")\n\n# Run the example\nasyncio.run(advanced_client_example())\n</code></pre>"},{"location":"tutorials/api_usage/#javascripttypescript-client","title":"JavaScript/TypeScript Client","text":"<p>Create a robust JavaScript client for web applications:</p> <pre><code>/**\n * Advanced RL-IDS API Client for JavaScript/TypeScript\n */\nclass AdvancedIDSAPIClient {\n    constructor(baseUrl = 'http://localhost:8000', options = {}) {\n        this.baseUrl = baseUrl.replace(/\\/$/, '');\n        this.timeout = options.timeout || 30000;\n        this.maxRetries = options.maxRetries || 3;\n        this.apiKey = options.apiKey || null;\n\n        this.stats = {\n            totalRequests: 0,\n            successfulRequests: 0,\n            failedRequests: 0,\n            totalResponseTime: 0\n        };\n    }\n\n    /**\n     * Make HTTP request with retry logic\n     */\n    async makeRequest(method, endpoint, data = null, retryCount = 0) {\n        const url = `${this.baseUrl}${endpoint}`;\n        const startTime = performance.now();\n\n        const headers = {\n            'Content-Type': 'application/json',\n            'User-Agent': 'RL-IDS JS Client v2.0'\n        };\n\n        if (this.apiKey) {\n            headers['Authorization'] = `Bearer ${this.apiKey}`;\n        }\n\n        const config = {\n            method,\n            headers,\n            signal: AbortSignal.timeout(this.timeout)\n        };\n\n        if (data) {\n            config.body = JSON.stringify(data);\n        }\n\n        try {\n            this.stats.totalRequests++;\n\n            const response = await fetch(url, config);\n            const responseTime = performance.now() - startTime;\n            this.stats.totalResponseTime += responseTime;\n\n            if (response.ok) {\n                this.stats.successfulRequests++;\n                return await response.json();\n            } else if (response.status === 429 &amp;&amp; retryCount &lt; this.maxRetries) {\n                // Rate limited - exponential backoff\n                const waitTime = Math.pow(2, retryCount) * 1000;\n                console.warn(`Rate limited, waiting ${waitTime}ms before retry`);\n                await this.sleep(waitTime);\n                return this.makeRequest(method, endpoint, data, retryCount + 1);\n            } else {\n                const errorText = await response.text();\n                throw new Error(`HTTP ${response.status}: ${errorText}`);\n            }\n        } catch (error) {\n            this.stats.failedRequests++;\n\n            if (retryCount &lt; this.maxRetries &amp;&amp; \n                (error.name === 'TimeoutError' || error.name === 'NetworkError')) {\n                console.warn(`Request failed: ${error.message}, retrying...`);\n                await this.sleep(1000);\n                return this.makeRequest(method, endpoint, data, retryCount + 1);\n            } else {\n                throw error;\n            }\n        }\n    }\n\n    /**\n     * Utility function for delays\n     */\n    sleep(ms) {\n        return new Promise(resolve =&gt; setTimeout(resolve, ms));\n    }\n\n    /**\n     * Health check endpoint\n     */\n    async healthCheck() {\n        return this.makeRequest('GET', '/health');\n    }\n\n    /**\n     * Get model information\n     */\n    async getModelInfo() {\n        return this.makeRequest('GET', '/model/info');\n    }\n\n    /**\n     * Single prediction\n     */\n    async predict(features) {\n        return this.makeRequest('POST', '/predict', { features });\n    }\n\n    /**\n     * Batch prediction with chunking\n     */\n    async predictBatch(featuresList, batchSize = 100) {\n        const allResults = [];\n\n        for (let i = 0; i &lt; featuresList.length; i += batchSize) {\n            const chunk = featuresList.slice(i, i + batchSize);\n            const chunkRequests = chunk.map(features =&gt; ({ features }));\n\n            const response = await this.makeRequest('POST', '/predict/batch', chunkRequests);\n            allResults.push(...response);\n\n            console.log(`Processed batch ${Math.floor(i / batchSize) + 1}, total predictions: ${allResults.length}`);\n        }\n\n        return allResults;\n    }\n\n    /**\n     * Real-time prediction stream\n     */\n    async *streamPredictions(featuresGenerator) {\n        for await (const features of featuresGenerator) {\n            try {\n                const prediction = await this.predict(features);\n                yield { features, prediction };\n            } catch (error) {\n                console.error('Stream prediction error:', error);\n                yield { features, error };\n            }\n        }\n    }\n\n    /**\n     * Monitor API performance\n     */\n    getStats() {\n        const stats = { ...this.stats };\n\n        if (stats.totalRequests &gt; 0) {\n            stats.successRate = stats.successfulRequests / stats.totalRequests;\n            stats.averageResponseTime = stats.totalResponseTime / stats.totalRequests;\n        } else {\n            stats.successRate = 0;\n            stats.averageResponseTime = 0;\n        }\n\n        return stats;\n    }\n}\n\n// Example usage in web application\nasync function webAppExample() {\n    const client = new AdvancedIDSAPIClient('http://localhost:8000');\n\n    try {\n        // Check service health\n        const health = await client.healthCheck();\n        console.log('Service status:', health.status);\n\n        // Get model information\n        const modelInfo = await client.getModelInfo();\n        console.log(`Model: ${modelInfo.model_name} v${modelInfo.model_version}`);\n\n        // Real-time prediction example\n        const features = Array(77).fill(0).map(() =&gt; Math.random());\n        const prediction = await client.predict(features);\n\n        console.log(`Prediction: ${prediction.predicted_class_name}`);\n        console.log(`Confidence: ${(prediction.confidence * 100).toFixed(1)}%`);\n        console.log(`Is Attack: ${prediction.is_attack}`);\n\n        // Display in UI\n        updateUI(prediction);\n\n    } catch (error) {\n        console.error('API error:', error);\n        showErrorMessage(error.message);\n    }\n}\n\nfunction updateUI(prediction) {\n    // Update web UI with prediction results\n    const resultElement = document.getElementById('prediction-result');\n    const confidenceElement = document.getElementById('confidence-bar');\n\n    resultElement.textContent = prediction.predicted_class_name;\n    resultElement.className = prediction.is_attack ? 'alert-danger' : 'alert-success';\n\n    confidenceElement.style.width = `${prediction.confidence * 100}%`;\n    confidenceElement.textContent = `${(prediction.confidence * 100).toFixed(1)}%`;\n}\n\nfunction showErrorMessage(message) {\n    const errorElement = document.getElementById('error-message');\n    errorElement.textContent = `Error: ${message}`;\n    errorElement.style.display = 'block';\n}\n</code></pre>"},{"location":"tutorials/api_usage/#3-integration-patterns","title":"3. Integration Patterns","text":""},{"location":"tutorials/api_usage/#integration-with-monitoring-systems","title":"Integration with Monitoring Systems","text":""},{"location":"tutorials/api_usage/#prometheus-metrics-integration","title":"Prometheus Metrics Integration","text":"<pre><code>from prometheus_client import Counter, Histogram, Gauge, start_http_server\nimport time\n\nclass PrometheusMetrics:\n    \"\"\"Prometheus metrics for API monitoring\"\"\"\n\n    def __init__(self):\n        # Request metrics\n        self.request_count = Counter('rlids_api_requests_total', \n                                   'Total API requests', ['method', 'endpoint', 'status'])\n        self.request_duration = Histogram('rlids_api_request_duration_seconds',\n                                        'Request duration in seconds', ['method', 'endpoint'])\n\n        # Prediction metrics\n        self.prediction_count = Counter('rlids_predictions_total',\n                                      'Total predictions made', ['predicted_class'])\n        self.prediction_confidence = Histogram('rlids_prediction_confidence',\n                                             'Prediction confidence scores')\n\n        # Model metrics\n        self.model_load_time = Gauge('rlids_model_load_time_seconds',\n                                   'Model load time in seconds')\n        self.model_memory_usage = Gauge('rlids_model_memory_usage_bytes',\n                                      'Model memory usage in bytes')\n\n        # Start metrics server\n        start_http_server(9090)\n\n    def record_request(self, method: str, endpoint: str, status: str, duration: float):\n        \"\"\"Record request metrics\"\"\"\n        self.request_count.labels(method=method, endpoint=endpoint, status=status).inc()\n        self.request_duration.labels(method=method, endpoint=endpoint).observe(duration)\n\n    def record_prediction(self, predicted_class: str, confidence: float):\n        \"\"\"Record prediction metrics\"\"\"\n        self.prediction_count.labels(predicted_class=predicted_class).inc()\n        self.prediction_confidence.observe(confidence)\n\n# Integrate with FastAPI\nfrom fastapi import Request\nimport time\n\nmetrics = PrometheusMetrics()\n\n@app.middleware(\"http\")\nasync def add_metrics_middleware(request: Request, call_next):\n    start_time = time.time()\n\n    response = await call_next(request)\n\n    process_time = time.time() - start_time\n    metrics.record_request(\n        method=request.method,\n        endpoint=request.url.path,\n        status=str(response.status_code),\n        duration=process_time\n    )\n\n    return response\n</code></pre>"},{"location":"tutorials/api_usage/#elk-stack-integration","title":"ELK Stack Integration","text":"<pre><code>import json\nimport logging\nfrom datetime import datetime\nfrom loguru import logger\n\nclass ELKLogger:\n    \"\"\"Structured logging for ELK stack\"\"\"\n\n    def __init__(self):\n        # Configure structured logging\n        logger.configure(\n            handlers=[\n                {\n                    \"sink\": \"logs/rlids_api.json\",\n                    \"format\": \"{time:YYYY-MM-DD HH:mm:ss} | {level} | {extra[request_id]} | {message}\",\n                    \"serialize\": True,\n                    \"rotation\": \"1 day\",\n                    \"retention\": \"30 days\"\n                }\n            ]\n        )\n\n    def log_prediction(self, request_id: str, features: list, prediction: dict, \n                      processing_time: float):\n        \"\"\"Log prediction event for ELK analysis\"\"\"\n\n        log_entry = {\n            \"event_type\": \"prediction\",\n            \"request_id\": request_id,\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"prediction\": {\n                \"class\": prediction[\"predicted_class\"],\n                \"class_name\": prediction[\"predicted_class_name\"],\n                \"confidence\": prediction[\"confidence\"],\n                \"is_attack\": prediction[\"is_attack\"]\n            },\n            \"performance\": {\n                \"processing_time_ms\": processing_time,\n                \"feature_count\": len(features)\n            },\n            \"metadata\": {\n                \"model_version\": prediction.get(\"model_version\"),\n                \"api_version\": \"2.0.0\"\n            }\n        }\n\n        logger.bind(request_id=request_id).info(json.dumps(log_entry))\n\n    def log_error(self, request_id: str, error: str, context: dict = None):\n        \"\"\"Log error event\"\"\"\n\n        log_entry = {\n            \"event_type\": \"error\",\n            \"request_id\": request_id,\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"error\": {\n                \"message\": str(error),\n                \"type\": type(error).__name__\n            },\n            \"context\": context or {}\n        }\n\n        logger.bind(request_id=request_id).error(json.dumps(log_entry))\n\nelk_logger = ELKLogger()\n</code></pre>"},{"location":"tutorials/api_usage/#database-integration-for-prediction-storage","title":"Database Integration for Prediction Storage","text":"<pre><code>import asyncpg\nimport sqlalchemy as sa\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\nfrom sqlalchemy.orm import declarative_base, sessionmaker\nfrom datetime import datetime\nfrom typing import Optional\n\nBase = declarative_base()\n\nclass PredictionRecord(Base):\n    \"\"\"Database model for storing predictions\"\"\"\n\n    __tablename__ = 'predictions'\n\n    id = sa.Column(sa.Integer, primary_key=True)\n    request_id = sa.Column(sa.String, nullable=False, index=True)\n    timestamp = sa.Column(sa.DateTime, default=datetime.utcnow, index=True)\n\n    # Input features (stored as JSON)\n    features = sa.Column(sa.JSON)\n    feature_hash = sa.Column(sa.String, index=True)  # For deduplication\n\n    # Prediction results\n    predicted_class = sa.Column(sa.Integer, nullable=False)\n    predicted_class_name = sa.Column(sa.String, nullable=False)\n    confidence = sa.Column(sa.Float, nullable=False)\n    is_attack = sa.Column(sa.Boolean, nullable=False)\n    probabilities = sa.Column(sa.JSON)\n\n    # Performance metrics\n    processing_time_ms = sa.Column(sa.Float)\n    model_version = sa.Column(sa.String)\n\n    # Optional ground truth for model monitoring\n    true_label = sa.Column(sa.Integer, nullable=True)\n    is_correct = sa.Column(sa.Boolean, nullable=True)\n\nclass PredictionStorage:\n    \"\"\"Database storage for predictions\"\"\"\n\n    def __init__(self, database_url: str):\n        self.engine = create_async_engine(database_url)\n        self.SessionLocal = sessionmaker(\n            self.engine, class_=AsyncSession, expire_on_commit=False\n        )\n\n    async def store_prediction(self, request_id: str, features: list, \n                             prediction: dict, processing_time: float) -&gt; int:\n        \"\"\"Store prediction in database\"\"\"\n\n        async with self.SessionLocal() as session:\n            # Calculate feature hash for deduplication\n            feature_hash = hashlib.md5(str(features).encode()).hexdigest()\n\n            record = PredictionRecord(\n                request_id=request_id,\n                features=features,\n                feature_hash=feature_hash,\n                predicted_class=prediction['predicted_class'],\n                predicted_class_name=prediction['predicted_class_name'],\n                confidence=prediction['confidence'],\n                is_attack=prediction['is_attack'],\n                probabilities=prediction.get('probabilities'),\n                processing_time_ms=processing_time,\n                model_version=prediction.get('model_version')\n            )\n\n            session.add(record)\n            await session.commit()\n\n            return record.id\n\n    async def get_prediction_stats(self, hours: int = 24) -&gt; dict:\n        \"\"\"Get prediction statistics for the last N hours\"\"\"\n\n        async with self.SessionLocal() as session:\n            since = datetime.utcnow() - timedelta(hours=hours)\n\n            # Total predictions\n            total_query = sa.select(sa.func.count(PredictionRecord.id)).where(\n                PredictionRecord.timestamp &gt;= since\n            )\n            total_result = await session.execute(total_query)\n            total_predictions = total_result.scalar()\n\n            # Attack predictions\n            attack_query = sa.select(sa.func.count(PredictionRecord.id)).where(\n                sa.and_(\n                    PredictionRecord.timestamp &gt;= since,\n                    PredictionRecord.is_attack == True\n                )\n            )\n            attack_result = await session.execute(attack_query)\n            attack_predictions = attack_result.scalar()\n\n            # Average confidence\n            confidence_query = sa.select(sa.func.avg(PredictionRecord.confidence)).where(\n                PredictionRecord.timestamp &gt;= since\n            )\n            confidence_result = await session.execute(confidence_query)\n            avg_confidence = confidence_result.scalar() or 0.0\n\n            return {\n                'total_predictions': total_predictions,\n                'attack_predictions': attack_predictions,\n                'benign_predictions': total_predictions - attack_predictions,\n                'attack_rate': attack_predictions / max(total_predictions, 1),\n                'average_confidence': float(avg_confidence)\n            }\n\n# Integration with API\nprediction_storage = PredictionStorage(\"postgresql+asyncpg://user:pass@localhost/rlids\")\n\n@app.post(\"/predict\")\nasync def predict_with_storage(request: IDSPredictionRequest):\n    # ... existing prediction logic ...\n\n    # Store prediction\n    await prediction_storage.store_prediction(\n        request_id=str(uuid.uuid4()),\n        features=request.features,\n        prediction=result,\n        processing_time=processing_time\n    )\n\n    return result\n</code></pre>"},{"location":"tutorials/api_usage/#4-performance-optimization-and-scaling","title":"4. Performance Optimization and Scaling","text":""},{"location":"tutorials/api_usage/#connection-pooling-and-load-balancing","title":"Connection Pooling and Load Balancing","text":"<pre><code># docker-compose.yml for load balanced setup\nversion: '3.8'\n\nservices:\n  nginx:\n    image: nginx:alpine\n    ports:\n      - \"80:80\"\n    volumes:\n      - ./nginx.conf:/etc/nginx/nginx.conf\n    depends_on:\n      - api-1\n      - api-2\n      - api-3\n\n  api-1:\n    build: .\n    environment:\n      - RLIDS_API_WORKERS=4\n      - RLIDS_API_PORT=8000\n    volumes:\n      - ./models:/app/models\n\n  api-2:\n    build: .\n    environment:\n      - RLIDS_API_WORKERS=4\n      - RLIDS_API_PORT=8000\n    volumes:\n      - ./models:/app/models\n\n  api-3:\n    build: .\n    environment:\n      - RLIDS_API_WORKERS=4\n      - RLIDS_API_PORT=8000\n    volumes:\n      - ./models:/app/models\n\n  redis:\n    image: redis:alpine\n    ports:\n      - \"6379:6379\"\n\n  postgresql:\n    image: postgres:13\n    environment:\n      POSTGRES_DB: rlids\n      POSTGRES_USER: rlids\n      POSTGRES_PASSWORD: password\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n\nvolumes:\n  postgres_data:\n</code></pre> <pre><code># nginx.conf\nevents {\n    worker_connections 1024;\n}\n\nhttp {\n    upstream rlids_api {\n        server api-1:8000;\n        server api-2:8000;\n        server api-3:8000;\n    }\n\n    server {\n        listen 80;\n\n        location / {\n            proxy_pass http://rlids_api;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n\n            # Connection pooling\n            proxy_http_version 1.1;\n            proxy_set_header Connection \"\";\n\n            # Timeouts\n            proxy_connect_timeout 5s;\n            proxy_send_timeout 60s;\n            proxy_read_timeout 60s;\n        }\n\n        location /health {\n            access_log off;\n            proxy_pass http://rlids_api;\n        }\n    }\n}\n</code></pre>"},{"location":"tutorials/api_usage/#redis-caching-integration","title":"Redis Caching Integration","text":"<pre><code>import redis.asyncio as redis\nimport json\nimport hashlib\nfrom typing import Optional\n\nclass RedisCacheManager:\n    \"\"\"Redis-based caching for API responses\"\"\"\n\n    def __init__(self, redis_url: str = \"redis://localhost:6379\"):\n        self.redis = redis.from_url(redis_url, decode_responses=True)\n        self.default_ttl = 3600  # 1 hour\n\n    async def get_cached_prediction(self, features: list) -&gt; Optional[dict]:\n        \"\"\"Get cached prediction if available\"\"\"\n\n        # Create cache key from features\n        feature_str = json.dumps(features, sort_keys=True)\n        cache_key = f\"prediction:{hashlib.md5(feature_str.encode()).hexdigest()}\"\n\n        cached_result = await self.redis.get(cache_key)\n        if cached_result:\n            return json.loads(cached_result)\n\n        return None\n\n    async def cache_prediction(self, features: list, prediction: dict, ttl: int = None):\n        \"\"\"Cache prediction result\"\"\"\n\n        feature_str = json.dumps(features, sort_keys=True)\n        cache_key = f\"prediction:{hashlib.md5(feature_str.encode()).hexdigest()}\"\n\n        await self.redis.setex(\n            cache_key, \n            ttl or self.default_ttl,\n            json.dumps(prediction)\n        )\n\n    async def get_model_stats(self) -&gt; dict:\n        \"\"\"Get cached model statistics\"\"\"\n\n        stats = await self.redis.hgetall(\"model:stats\")\n        return {k: json.loads(v) for k, v in stats.items()}\n\n    async def update_model_stats(self, stats: dict):\n        \"\"\"Update model statistics cache\"\"\"\n\n        pipeline = self.redis.pipeline()\n        for key, value in stats.items():\n            pipeline.hset(\"model:stats\", key, json.dumps(value))\n        await pipeline.execute()\n\n# Integration with API\ncache_manager = RedisCacheManager()\n\n@app.post(\"/predict\")\nasync def predict_with_cache(request: IDSPredictionRequest):\n    # Check cache first\n    cached_result = await cache_manager.get_cached_prediction(request.features)\n    if cached_result:\n        logger.info(\"Returning cached prediction\")\n        return cached_result\n\n    # Compute prediction\n    result = await prediction_service.predict(request.features)\n\n    # Cache result\n    await cache_manager.cache_prediction(request.features, result)\n\n    return result\n</code></pre>"},{"location":"tutorials/api_usage/#5-security-and-authentication","title":"5. Security and Authentication","text":""},{"location":"tutorials/api_usage/#jwt-authentication","title":"JWT Authentication","text":"<pre><code>from fastapi import Depends, HTTPException, status\nfrom fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\nimport jwt\nfrom datetime import datetime, timedelta\nfrom typing import Optional\n\nclass JWTAuthManager:\n    \"\"\"JWT-based authentication for API\"\"\"\n\n    def __init__(self, secret_key: str, algorithm: str = \"HS256\"):\n        self.secret_key = secret_key\n        self.algorithm = algorithm\n        self.token_expiry = timedelta(hours=24)\n\n    def create_access_token(self, user_id: str, permissions: list = None) -&gt; str:\n        \"\"\"Create JWT access token\"\"\"\n\n        payload = {\n            \"user_id\": user_id,\n            \"permissions\": permissions or [],\n            \"exp\": datetime.utcnow() + self.token_expiry,\n            \"iat\": datetime.utcnow()\n        }\n\n        return jwt.encode(payload, self.secret_key, algorithm=self.algorithm)\n\n    def verify_token(self, token: str) -&gt; dict:\n        \"\"\"Verify and decode JWT token\"\"\"\n\n        try:\n            payload = jwt.decode(token, self.secret_key, algorithms=[self.algorithm])\n            return payload\n        except jwt.ExpiredSignatureError:\n            raise HTTPException(\n                status_code=status.HTTP_401_UNAUTHORIZED,\n                detail=\"Token has expired\"\n            )\n        except jwt.JWTError:\n            raise HTTPException(\n                status_code=status.HTTP_401_UNAUTHORIZED,\n                detail=\"Invalid token\"\n            )\n\n# Setup authentication\nauth_manager = JWTAuthManager(secret_key=\"your-secret-key\")\nsecurity = HTTPBearer()\n\nasync def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):\n    \"\"\"Dependency to get current authenticated user\"\"\"\n\n    payload = auth_manager.verify_token(credentials.credentials)\n    return payload\n\nasync def require_permission(permission: str):\n    \"\"\"Dependency to require specific permission\"\"\"\n\n    def permission_checker(user: dict = Depends(get_current_user)):\n        if permission not in user.get(\"permissions\", []):\n            raise HTTPException(\n                status_code=status.HTTP_403_FORBIDDEN,\n                detail=f\"Permission '{permission}' required\"\n            )\n        return user\n\n    return permission_checker\n\n# Protected endpoints\n@app.post(\"/predict\")\nasync def predict_protected(\n    request: IDSPredictionRequest,\n    user: dict = Depends(get_current_user)\n):\n    logger.info(f\"Prediction request from user: {user['user_id']}\")\n    return await prediction_service.predict(request.features)\n\n@app.get(\"/admin/stats\")\nasync def admin_stats(\n    user: dict = Depends(require_permission(\"admin\"))\n):\n    return await get_comprehensive_stats()\n</code></pre>"},{"location":"tutorials/api_usage/#rate-limiting-with-redis","title":"Rate Limiting with Redis","text":"<pre><code>import time\nfrom fastapi import Request, HTTPException\nimport redis.asyncio as redis\n\nclass RateLimiter:\n    \"\"\"Redis-based rate limiting\"\"\"\n\n    def __init__(self, redis_url: str):\n        self.redis = redis.from_url(redis_url)\n\n    async def check_rate_limit(self, key: str, limit: int, window: int) -&gt; bool:\n        \"\"\"Check if request is within rate limit\"\"\"\n\n        current_time = int(time.time())\n        window_start = current_time - window\n\n        pipeline = self.redis.pipeline()\n\n        # Remove old entries\n        pipeline.zremrangebyscore(key, 0, window_start)\n\n        # Count current requests\n        pipeline.zcard(key)\n\n        # Add current request\n        pipeline.zadd(key, {str(current_time): current_time})\n\n        # Set expiry\n        pipeline.expire(key, window)\n\n        results = await pipeline.execute()\n        request_count = results[1]\n\n        return request_count &lt; limit\n\nrate_limiter = RateLimiter(\"redis://localhost:6379\")\n\n@app.middleware(\"http\")\nasync def rate_limit_middleware(request: Request, call_next):\n    # Skip rate limiting for health checks\n    if request.url.path == \"/health\":\n        return await call_next(request)\n\n    # Create rate limit key\n    client_ip = request.client.host\n    rate_key = f\"rate_limit:{client_ip}\"\n\n    # Check rate limit (100 requests per minute)\n    if not await rate_limiter.check_rate_limit(rate_key, 100, 60):\n        raise HTTPException(\n            status_code=429,\n            detail=\"Rate limit exceeded\"\n        )\n\n    return await call_next(request)\n</code></pre>"},{"location":"tutorials/api_usage/#6-comprehensive-monitoring-and-alerting","title":"6. Comprehensive Monitoring and Alerting","text":""},{"location":"tutorials/api_usage/#health-check-system","title":"Health Check System","text":"<pre><code>import psutil\nimport torch\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List\n\nclass HealthChecker:\n    \"\"\"Comprehensive health monitoring\"\"\"\n\n    def __init__(self, prediction_service):\n        self.prediction_service = prediction_service\n        self.health_history = []\n\n    async def comprehensive_health_check(self) -&gt; Dict:\n        \"\"\"Perform comprehensive system health check\"\"\"\n\n        health_status = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"overall_status\": \"healthy\",\n            \"checks\": {}\n        }\n\n        # API responsiveness\n        api_check = await self._check_api_responsiveness()\n        health_status[\"checks\"][\"api\"] = api_check\n\n        # Model health\n        model_check = await self._check_model_health()\n        health_status[\"checks\"][\"model\"] = model_check\n\n        # System resources\n        resource_check = self._check_system_resources()\n        health_status[\"checks\"][\"resources\"] = resource_check\n\n        # Database connectivity\n        db_check = await self._check_database_health()\n        health_status[\"checks\"][\"database\"] = db_check\n\n        # Cache connectivity\n        cache_check = await self._check_cache_health()\n        health_status[\"checks\"][\"cache\"] = cache_check\n\n        # Determine overall status\n        failed_checks = [k for k, v in health_status[\"checks\"].items() \n                        if v[\"status\"] != \"healthy\"]\n\n        if failed_checks:\n            health_status[\"overall_status\"] = \"unhealthy\"\n            health_status[\"failed_checks\"] = failed_checks\n\n        # Store health history\n        self.health_history.append(health_status)\n        if len(self.health_history) &gt; 100:\n            self.health_history.pop(0)\n\n        return health_status\n\n    async def _check_api_responsiveness(self) -&gt; Dict:\n        \"\"\"Test API responsiveness with dummy prediction\"\"\"\n\n        start_time = time.time()\n        try:\n            # Test prediction with dummy data\n            dummy_features = [0.1] * 77\n            result = await self.prediction_service.predict(dummy_features)\n\n            response_time = (time.time() - start_time) * 1000\n\n            return {\n                \"status\": \"healthy\",\n                \"response_time_ms\": response_time,\n                \"prediction_successful\": True\n            }\n        except Exception as e:\n            return {\n                \"status\": \"unhealthy\",\n                \"error\": str(e),\n                \"response_time_ms\": (time.time() - start_time) * 1000\n            }\n\n    async def _check_model_health(self) -&gt; Dict:\n        \"\"\"Check model loading and inference capability\"\"\"\n\n        try:\n            # Check if model is loaded\n            if not hasattr(self.prediction_service, 'model') or self.prediction_service.model is None:\n                return {\n                    \"status\": \"unhealthy\",\n                    \"error\": \"Model not loaded\"\n                }\n\n            # Check model parameters\n            param_count = sum(p.numel() for p in self.prediction_service.model.parameters())\n\n            # Check GPU availability if using CUDA\n            gpu_available = torch.cuda.is_available()\n            gpu_memory = torch.cuda.get_device_properties(0).total_memory if gpu_available else 0\n\n            return {\n                \"status\": \"healthy\",\n                \"model_parameters\": param_count,\n                \"gpu_available\": gpu_available,\n                \"gpu_memory_gb\": gpu_memory / (1024**3) if gpu_available else 0\n            }\n        except Exception as e:\n            return {\n                \"status\": \"unhealthy\",\n                \"error\": str(e)\n            }\n\n    def _check_system_resources(self) -&gt; Dict:\n        \"\"\"Check system resource usage\"\"\"\n\n        cpu_percent = psutil.cpu_percent(interval=1)\n        memory = psutil.virtual_memory()\n        disk = psutil.disk_usage('/')\n\n        # Determine health based on thresholds\n        status = \"healthy\"\n        if cpu_percent &gt; 90 or memory.percent &gt; 90 or disk.percent &gt; 90:\n            status = \"unhealthy\"\n        elif cpu_percent &gt; 80 or memory.percent &gt; 80 or disk.percent &gt; 80:\n            status = \"warning\"\n\n        return {\n            \"status\": status,\n            \"cpu_percent\": cpu_percent,\n            \"memory_percent\": memory.percent,\n            \"memory_available_gb\": memory.available / (1024**3),\n            \"disk_percent\": disk.percent,\n            \"disk_free_gb\": disk.free / (1024**3)\n        }\n\n    async def _check_database_health(self) -&gt; Dict:\n        \"\"\"Check database connectivity and performance\"\"\"\n\n        try:\n            # Test database connection\n            start_time = time.time()\n            stats = await prediction_storage.get_prediction_stats(hours=1)\n            query_time = (time.time() - start_time) * 1000\n\n            return {\n                \"status\": \"healthy\",\n                \"query_time_ms\": query_time,\n                \"recent_predictions\": stats.get(\"total_predictions\", 0)\n            }\n        except Exception as e:\n            return {\n                \"status\": \"unhealthy\",\n                \"error\": str(e)\n            }\n\n    async def _check_cache_health(self) -&gt; Dict:\n        \"\"\"Check cache connectivity and performance\"\"\"\n\n        try:\n            start_time = time.time()\n            await cache_manager.redis.ping()\n            ping_time = (time.time() - start_time) * 1000\n\n            # Get cache statistics\n            info = await cache_manager.redis.info()\n\n            return {\n                \"status\": \"healthy\",\n                \"ping_time_ms\": ping_time,\n                \"connected_clients\": info.get(\"connected_clients\", 0),\n                \"used_memory_mb\": info.get(\"used_memory\", 0) / (1024**2)\n            }\n        except Exception as e:\n            return {\n                \"status\": \"unhealthy\",\n                \"error\": str(e)\n            }\n\n# Enhanced health endpoint\nhealth_checker = HealthChecker(prediction_service)\n\n@app.get(\"/health/comprehensive\")\nasync def comprehensive_health():\n    \"\"\"Comprehensive health check endpoint\"\"\"\n    return await health_checker.comprehensive_health_check()\n\n@app.get(\"/health/history\")\nasync def health_history():\n    \"\"\"Get health check history\"\"\"\n    return health_checker.health_history[-10:]  # Last 10 checks\n</code></pre>"},{"location":"tutorials/api_usage/#7-next-steps-and-best-practices","title":"7. Next Steps and Best Practices","text":""},{"location":"tutorials/api_usage/#production-deployment-checklist","title":"Production Deployment Checklist","text":"<pre><code># Production deployment checklist\n\n# 1. Environment Configuration\nexport RLIDS_API_DEBUG=false\nexport RLIDS_API_LOG_LEVEL=INFO\nexport RLIDS_API_WORKERS=8\nexport RLIDS_API_MAX_BATCH_SIZE=1000\n\n# 2. Security Setup\nexport RLIDS_API_SECRET_KEY=\"your-secure-secret-key\"\nexport RLIDS_API_CORS_ORIGINS='[\"https://your-domain.com\"]'\nexport RLIDS_API_RATE_LIMIT_ENABLED=true\n\n# 3. Database Configuration\nexport DATABASE_URL=\"postgresql://user:pass@db-host:5432/rlids\"\nexport REDIS_URL=\"redis://redis-host:6379\"\n\n# 4. Monitoring Setup\nexport PROMETHEUS_ENABLED=true\nexport PROMETHEUS_PORT=9090\nexport LOG_LEVEL=INFO\n\n# 5. SSL/TLS Certificate\nexport SSL_CERT_PATH=\"/path/to/cert.pem\"\nexport SSL_KEY_PATH=\"/path/to/key.pem\"\n\n# 6. Start production server\ngunicorn api.main:app \\\n    --bind 0.0.0.0:8000 \\\n    --workers 8 \\\n    --worker-class uvicorn.workers.UvicornWorker \\\n    --access-logfile access.log \\\n    --error-logfile error.log \\\n    --log-level info \\\n    --preload \\\n    --max-requests 1000 \\\n    --max-requests-jitter 100\n</code></pre>"},{"location":"tutorials/api_usage/#performance-monitoring-setup","title":"Performance Monitoring Setup","text":"<pre><code># monitoring/dashboard.py\nimport asyncio\nimport json\nfrom datetime import datetime, timedelta\n\nclass PerformanceDashboard:\n    \"\"\"Real-time performance monitoring dashboard\"\"\"\n\n    def __init__(self):\n        self.metrics = {\n            'requests_per_second': 0,\n            'average_response_time': 0,\n            'error_rate': 0,\n            'active_connections': 0,\n            'model_predictions_per_hour': 0,\n            'system_resources': {}\n        }\n\n    async def collect_metrics(self):\n        \"\"\"Collect real-time metrics\"\"\"\n        while True:\n            try:\n                # Collect API metrics\n                api_stats = await self.get_api_statistics()\n\n                # Collect system metrics\n                system_stats = await self.get_system_statistics()\n\n                # Update dashboard\n                self.metrics.update({\n                    **api_stats,\n                    'system_resources': system_stats,\n                    'last_updated': datetime.utcnow().isoformat()\n                })\n\n                # Send to monitoring systems\n                await self.send_to_monitoring()\n\n            except Exception as e:\n                logger.error(f\"Metrics collection error: {e}\")\n\n            await asyncio.sleep(30)  # Collect every 30 seconds\n\n    async def generate_performance_report(self) -&gt; dict:\n        \"\"\"Generate comprehensive performance report\"\"\"\n\n        # Get historical data\n        historical_data = await self.get_historical_metrics(days=7)\n\n        # Calculate trends\n        trends = self.calculate_trends(historical_data)\n\n        # Generate recommendations\n        recommendations = self.generate_recommendations(self.metrics, trends)\n\n        return {\n            'current_metrics': self.metrics,\n            'trends': trends,\n            'recommendations': recommendations,\n            'report_generated': datetime.utcnow().isoformat()\n        }\n\n# Start monitoring dashboard\ndashboard = PerformanceDashboard()\nasyncio.create_task(dashboard.collect_metrics())\n</code></pre> <p>This tutorial provides a comprehensive foundation for advanced API usage patterns. Continue with the deployment tutorial for production-ready setups and scaling strategies.</p>"},{"location":"tutorials/api_usage/#see-also","title":"See Also","text":"<ul> <li>Getting Started Guide - Basic API setup</li> <li>Deployment Tutorial - Production deployment strategies</li> <li>Monitoring Tutorial - Advanced monitoring and alerting</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"tutorials/training/","title":"Basic Training Tutorial","text":""},{"location":"tutorials/training/#objective","title":"Objective","text":"<p>Learn how to train a DQN model for intrusion detection from scratch, understand the training process, and evaluate model performance.</p>"},{"location":"tutorials/training/#prerequisites","title":"Prerequisites","text":"<ul> <li>RL-IDS system installed and configured</li> <li>CICIDS2017 dataset prepared (see Data Preparation Guide)</li> <li>Basic understanding of reinforcement learning concepts</li> </ul>"},{"location":"tutorials/training/#step-1-verify-data-preparation","title":"Step 1: Verify Data Preparation","text":"<p>First, ensure your data is properly prepared:</p> <pre><code># Check if processed data exists\nls data/processed/\n# Should show: train.csv, val.csv, test.csv\n\n# If not, process the raw data\npython -m rl_ids.make_dataset\n</code></pre> <p>Expected Output: <pre><code>\ud83d\uddc2\ufe0f  Starting data loading from directory: data/raw\n\ud83d\udcc4 Found 8 CSV files to process\n\ud83d\udd17 Concatenating data frames...\n\ud83e\uddf9 Starting data preprocessing...\n\u2705 Data loading and preprocessing complete! Final shape: (2830743, 79)\n</code></pre></p>"},{"location":"tutorials/training/#step-2-basic-training","title":"Step 2: Basic Training","text":"<p>Start with a basic training session using default parameters:</p> <pre><code># Basic training (recommended for first run)\npython -m rl_ids.modeling.train \\\n    --num-episodes 100 \\\n    --batch-size 128 \\\n    --save-interval 25\n</code></pre> <p>Expected Output: <pre><code>\ud83d\ude80 Starting Enhanced DQN training for IDS Detection\n\ud83d\udcc2 Loading training data from data/processed/train.csv\n\ud83c\udf0d Initializing training environment...\n\ud83e\udd16 Initializing Enhanced DQN Agent...\n\ud83c\udfaf Starting training loop...\n\nEpisode 1/100: Reward=1234, Accuracy=67.8%, Loss=0.0234, \u03b5=0.995\nEpisode 25/100: Reward=2341, Accuracy=78.9%, Loss=0.0156, \u03b5=0.876\nEpisode 50/100: Reward=3456, Accuracy=85.2%, Loss=0.0098, \u03b5=0.678\nEpisode 75/100: Reward=4123, Accuracy=89.1%, Loss=0.0067, \u03b5=0.543\nEpisode 100/100: Reward=4567, Accuracy=91.3%, Loss=0.0045, \u03b5=0.432\n\n\u2705 Training completed successfully!\n\ud83d\udcca Best model saved to: models/dqn_model_best.pt\n\ud83d\udcca Final model saved to: models/dqn_model_final.pt\n</code></pre></p>"},{"location":"tutorials/training/#step-3-monitor-training-progress","title":"Step 3: Monitor Training Progress","text":"<p>During training, several files are created to track progress:</p>"},{"location":"tutorials/training/#model-checkpoints","title":"Model Checkpoints","text":"<pre><code>ls models/\n# Output:\n# dqn_model_best.pt      - Best performing model\n# dqn_model_final.pt     - Final model after all episodes\n# episodes/              - Directory with episode checkpoints\n#   dqn_model_episode_25.pt\n#   dqn_model_episode_50.pt\n#   dqn_model_episode_75.pt\n#   dqn_model_episode_100.pt\n</code></pre>"},{"location":"tutorials/training/#training-reports","title":"Training Reports","text":"<pre><code>ls reports/\n# Output:\n# training_metrics.csv   - Detailed training metrics\n</code></pre>"},{"location":"tutorials/training/#step-4-evaluate-your-model","title":"Step 4: Evaluate Your Model","text":"<p>After training, evaluate the model performance:</p> <pre><code># Evaluate the best model\npython -m rl_ids.modeling.evaluate \\\n    --test-episodes 10 \\\n    --use-best-model\n</code></pre> <p>Expected Output: <pre><code>\ud83e\uddea Starting Enhanced DQN Agent Evaluation\n\ud83e\udd16 Loading trained model from models/dqn_model_best.pt\n\ud83c\udf0d Initializing test environment...\n\nEpisode 1/10: Accuracy=91.2%, Reward=4532, Steps=2234\nEpisode 5/10: Accuracy=92.1%, Reward=4651, Steps=2189\nEpisode 10/10: Accuracy=91.8%, Reward=4598, Steps=2201\n\n\ud83d\udcca Evaluation Results:\n  Overall Accuracy: 91.73% \u00b1 0.34%\n  Average Reward: 4596.3 \u00b1 45.2\n  Average Steps: 2208.1 \u00b1 18.7\n  High-Confidence Accuracy: 95.21%\n\n\ud83d\udcc8 Reports generated in: reports/\n\ud83d\udcca Visualizations saved in: reports/figures/\n</code></pre></p>"},{"location":"tutorials/training/#step-5-view-training-results","title":"Step 5: View Training Results","text":"<p>Examine the generated reports and visualizations:</p>"},{"location":"tutorials/training/#key-files-generated","title":"Key Files Generated","text":"<pre><code>ls reports/\nevaluation_summary_enhanced.csv\nevaluation_episode_details_enhanced.csv\nevaluation_detailed_predictions_enhanced.csv\nevaluation_classification_report.csv\n\nls reports/figures/\nevaluation_overview.png\nclass_analysis.png\nerror_analysis.png\nenhanced_confusion_matrix.png\n</code></pre>"},{"location":"tutorials/training/#interpreting-results","title":"Interpreting Results","text":"<ol> <li><code>evaluation_overview.png</code>: Comprehensive performance overview</li> <li>Episode performance trends</li> <li>Confidence score distribution</li> <li>Confusion matrix visualization</li> <li> <p>Class-wise accuracy metrics</p> </li> <li> <p><code>class_analysis.png</code>: Per-class performance analysis</p> </li> <li>Precision, recall, F1-score by class</li> <li>Class distribution analysis</li> <li> <p>Confidence analysis by class</p> </li> <li> <p><code>error_analysis.png</code>: Error pattern analysis</p> </li> <li>Common misclassification patterns</li> <li>Error distribution by confidence level</li> <li>Most problematic class pairs</li> </ol>"},{"location":"tutorials/training/#step-6-advanced-training-configuration","title":"Step 6: Advanced Training Configuration","text":"<p>Once you're comfortable with basic training, try advanced configurations:</p> <pre><code># Advanced training with optimizations\npython -m rl_ids.modeling.train \\\n    --num-episodes 500 \\\n    --lr 1e-4 \\\n    --batch-size 256 \\\n    --hidden-dims \"1024,512,256,128\" \\\n    --gamma 0.995 \\\n    --eps-decay 0.9995 \\\n    --memory-size 200000 \\\n    --double-dqn \\\n    --dueling \\\n    --curriculum-learning \\\n    --early-stopping-patience 50 \\\n    --validation-interval 10\n</code></pre>"},{"location":"tutorials/training/#parameter-explanation","title":"Parameter Explanation","text":"Parameter Purpose Recommended Values <code>--num-episodes</code> Training duration 500-1000 for good models <code>--lr</code> Learning rate 1e-4 to 1e-5 <code>--batch-size</code> Training batch size 128-512 (based on GPU memory) <code>--hidden-dims</code> Network architecture \"512,256,128\" to \"2048,1024,512,256\" <code>--gamma</code> Discount factor 0.99-0.999 <code>--eps-decay</code> Exploration decay 0.995-0.9999 <code>--memory-size</code> Replay buffer size 50000-500000 <code>--double-dqn</code> Use Double DQN Recommended <code>--dueling</code> Use Dueling DQN Recommended <code>--curriculum-learning</code> Progressive difficulty Recommended"},{"location":"tutorials/training/#step-7-compare-different-configurations","title":"Step 7: Compare Different Configurations","text":"<p>Train multiple models with different configurations:</p> <pre><code># Experiment 1: Conservative learning\npython -m rl_ids.modeling.train \\\n    --num-episodes 300 \\\n    --lr 5e-5 \\\n    --batch-size 128 \\\n    --models-dir models/conservative \\\n    --reports-dir reports/conservative\n\n# Experiment 2: Aggressive learning  \npython -m rl_ids.modeling.train \\\n    --num-episodes 300 \\\n    --lr 1e-3 \\\n    --batch-size 512 \\\n    --models-dir models/aggressive \\\n    --reports-dir reports/aggressive\n\n# Evaluate both models\npython -m rl_ids.modeling.evaluate \\\n    --model-path models/conservative/dqn_model_best.pt \\\n    --reports-dir reports/conservative_eval\n\npython -m rl_ids.modeling.evaluate \\\n    --model-path models/aggressive/dqn_model_best.pt \\\n    --reports-dir reports/aggressive_eval\n</code></pre>"},{"location":"tutorials/training/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/training/#common-issues","title":"Common Issues","text":""},{"location":"tutorials/training/#1-cuda-out-of-memory","title":"1. CUDA Out of Memory","text":"<pre><code># Reduce batch size\npython -m rl_ids.modeling.train --batch-size 64\n\n# Or use CPU only\nexport CUDA_VISIBLE_DEVICES=\"\"\npython -m rl_ids.modeling.train\n</code></pre>"},{"location":"tutorials/training/#2-poor-training-performance","title":"2. Poor Training Performance","text":"<pre><code># Check data distribution\npython -c \"\nimport pandas as pd\ndf = pd.read_csv('data/processed/train.csv')\nprint(df['Label'].value_counts())\n\"\n\n# If imbalanced, regenerate with balancing\npython -m rl_ids.make_dataset --balance-classes\n</code></pre>"},{"location":"tutorials/training/#3-training-stucknot-improving","title":"3. Training Stuck/Not Improving","text":"<pre><code># Try curriculum learning\npython -m rl_ids.modeling.train \\\n    --curriculum-learning \\\n    --curriculum-stages 3\n\n# Or adjust learning rate\npython -m rl_ids.modeling.train \\\n    --lr 1e-5 \\\n    --lr-scheduler cosine\n</code></pre>"},{"location":"tutorials/training/#4-model-not-saving","title":"4. Model Not Saving","text":"<pre><code># Check permissions\nls -la models/\nmkdir -p models episodes\n\n# Verify disk space\ndf -h\n</code></pre>"},{"location":"tutorials/training/#expected-training-times","title":"Expected Training Times","text":"Configuration Episodes Estimated Time Basic (CPU) 100 30-60 minutes Basic (GPU) 100 10-20 minutes Advanced (GPU) 500 1-3 hours Full Training (GPU) 1000 3-6 hours"},{"location":"tutorials/training/#next-steps","title":"Next Steps","text":"<p>After completing basic training:</p> <ol> <li>API Usage Tutorial - Deploy your model as a REST API</li> <li>Advanced Training - Learn hyperparameter optimization</li> <li>Custom Environments - Create custom training scenarios</li> <li>Production Deployment - Deploy to production systems</li> </ol>"},{"location":"tutorials/training/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Start with basic training to understand the process</li> <li>Monitor training metrics to detect issues early</li> <li>Use evaluation reports to understand model performance</li> <li>Experiment with different configurations</li> <li>Save and compare multiple model versions</li> <li>Use GPU acceleration for faster training</li> </ul> <p>The trained model will be ready for deployment via the API service or further optimization based on your specific requirements.</p>"}]}